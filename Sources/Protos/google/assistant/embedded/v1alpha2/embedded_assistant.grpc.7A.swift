//
// DO NOT EDIT.
//
// Generated by the protocol buffer compiler.
// Source: google/assistant/embedded/v1alpha2/embedded_assistant.proto
//

//
// Copyright 2018, gRPC Authors All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
import GRPC
import NIO
import SwiftProtobuf


/// Usage: instantiate Google_Assistant_Embedded_V1alpha2_EmbeddedAssistantClient, then call methods of this protocol to make API calls.
public protocol Google_Assistant_Embedded_V1alpha2_EmbeddedAssistantClientProtocol: GRPCClient {
  func assist(
    callOptions: CallOptions?,
    handler: @escaping (Google_Assistant_Embedded_V1alpha2_AssistResponse) -> Void
  ) -> BidirectionalStreamingCall<Google_Assistant_Embedded_V1alpha2_AssistRequest, Google_Assistant_Embedded_V1alpha2_AssistResponse>

}

extension Google_Assistant_Embedded_V1alpha2_EmbeddedAssistantClientProtocol {

  /// Initiates or continues a conversation with the embedded Assistant Service.
  /// Each call performs one round-trip, sending an audio request to the service
  /// and receiving the audio response. Uses bidirectional streaming to receive
  /// results, such as the `END_OF_UTTERANCE` event, while sending audio.
  ///
  /// A conversation is one or more gRPC connections, each consisting of several
  /// streamed requests and responses.
  /// For example, the user says *Add to my shopping list* and the Assistant
  /// responds *What do you want to add?*. The sequence of streamed requests and
  /// responses in the first gRPC message could be:
  ///
  /// *   AssistRequest.config
  /// *   AssistRequest.audio_in
  /// *   AssistRequest.audio_in
  /// *   AssistRequest.audio_in
  /// *   AssistRequest.audio_in
  /// *   AssistResponse.event_type.END_OF_UTTERANCE
  /// *   AssistResponse.speech_results.transcript "add to my shopping list"
  /// *   AssistResponse.dialog_state_out.microphone_mode.DIALOG_FOLLOW_ON
  /// *   AssistResponse.audio_out
  /// *   AssistResponse.audio_out
  /// *   AssistResponse.audio_out
  ///
  ///
  /// The user then says *bagels* and the Assistant responds
  /// *OK, I've added bagels to your shopping list*. This is sent as another gRPC
  /// connection call to the `Assist` method, again with streamed requests and
  /// responses, such as:
  ///
  /// *   AssistRequest.config
  /// *   AssistRequest.audio_in
  /// *   AssistRequest.audio_in
  /// *   AssistRequest.audio_in
  /// *   AssistResponse.event_type.END_OF_UTTERANCE
  /// *   AssistResponse.dialog_state_out.microphone_mode.CLOSE_MICROPHONE
  /// *   AssistResponse.audio_out
  /// *   AssistResponse.audio_out
  /// *   AssistResponse.audio_out
  /// *   AssistResponse.audio_out
  ///
  /// Although the precise order of responses is not guaranteed, sequential
  /// `AssistResponse.audio_out` messages will always contain sequential portions
  /// of audio.
  ///
  /// Callers should use the `send` method on the returned object to send messages
  /// to the server. The caller should send an `.end` after the final message has been sent.
  ///
  /// - Parameters:
  ///   - callOptions: Call options.
  ///   - handler: A closure called when each response is received from the server.
  /// - Returns: A `ClientStreamingCall` with futures for the metadata and status.
  public func assist(
    callOptions: CallOptions? = nil,
    handler: @escaping (Google_Assistant_Embedded_V1alpha2_AssistResponse) -> Void
  ) -> BidirectionalStreamingCall<Google_Assistant_Embedded_V1alpha2_AssistRequest, Google_Assistant_Embedded_V1alpha2_AssistResponse> {
    return self.makeBidirectionalStreamingCall(
      path: "/google.assistant.embedded.v1alpha2.EmbeddedAssistant/Assist",
      callOptions: callOptions ?? self.defaultCallOptions,
      handler: handler
    )
  }
}

public final class Google_Assistant_Embedded_V1alpha2_EmbeddedAssistantClient: Google_Assistant_Embedded_V1alpha2_EmbeddedAssistantClientProtocol {
  public let channel: GRPCChannel
  public var defaultCallOptions: CallOptions

  /// Creates a client for the google.assistant.embedded.v1alpha2.EmbeddedAssistant service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  public init(channel: GRPCChannel, defaultCallOptions: CallOptions = CallOptions()) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
  }
}

/// To build a server, implement a class that conforms to this protocol.
public protocol Google_Assistant_Embedded_V1alpha2_EmbeddedAssistantProvider: CallHandlerProvider {
  /// Initiates or continues a conversation with the embedded Assistant Service.
  /// Each call performs one round-trip, sending an audio request to the service
  /// and receiving the audio response. Uses bidirectional streaming to receive
  /// results, such as the `END_OF_UTTERANCE` event, while sending audio.
  ///
  /// A conversation is one or more gRPC connections, each consisting of several
  /// streamed requests and responses.
  /// For example, the user says *Add to my shopping list* and the Assistant
  /// responds *What do you want to add?*. The sequence of streamed requests and
  /// responses in the first gRPC message could be:
  ///
  /// *   AssistRequest.config
  /// *   AssistRequest.audio_in
  /// *   AssistRequest.audio_in
  /// *   AssistRequest.audio_in
  /// *   AssistRequest.audio_in
  /// *   AssistResponse.event_type.END_OF_UTTERANCE
  /// *   AssistResponse.speech_results.transcript "add to my shopping list"
  /// *   AssistResponse.dialog_state_out.microphone_mode.DIALOG_FOLLOW_ON
  /// *   AssistResponse.audio_out
  /// *   AssistResponse.audio_out
  /// *   AssistResponse.audio_out
  ///
  ///
  /// The user then says *bagels* and the Assistant responds
  /// *OK, I've added bagels to your shopping list*. This is sent as another gRPC
  /// connection call to the `Assist` method, again with streamed requests and
  /// responses, such as:
  ///
  /// *   AssistRequest.config
  /// *   AssistRequest.audio_in
  /// *   AssistRequest.audio_in
  /// *   AssistRequest.audio_in
  /// *   AssistResponse.event_type.END_OF_UTTERANCE
  /// *   AssistResponse.dialog_state_out.microphone_mode.CLOSE_MICROPHONE
  /// *   AssistResponse.audio_out
  /// *   AssistResponse.audio_out
  /// *   AssistResponse.audio_out
  /// *   AssistResponse.audio_out
  ///
  /// Although the precise order of responses is not guaranteed, sequential
  /// `AssistResponse.audio_out` messages will always contain sequential portions
  /// of audio.
  func assist(context: StreamingResponseCallContext<Google_Assistant_Embedded_V1alpha2_AssistResponse>) -> EventLoopFuture<(StreamEvent<Google_Assistant_Embedded_V1alpha2_AssistRequest>) -> Void>
}

extension Google_Assistant_Embedded_V1alpha2_EmbeddedAssistantProvider {
  public var serviceName: Substring { return "google.assistant.embedded.v1alpha2.EmbeddedAssistant" }

  /// Determines, calls and returns the appropriate request handler, depending on the request's method.
  /// Returns nil for methods not handled by this service.
  public func handleMethod(_ methodName: Substring, callHandlerContext: CallHandlerContext) -> GRPCCallHandler? {
    switch methodName {
    case "Assist":
      return CallHandlerFactory.makeBidirectionalStreaming(callHandlerContext: callHandlerContext) { context in
        return self.assist(context: context)
      }

    default: return nil
    }
  }
}

