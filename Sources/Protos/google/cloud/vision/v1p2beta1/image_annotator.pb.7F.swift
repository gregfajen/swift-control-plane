// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/vision/v1p2beta1/image_annotator.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2019 Google LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// A bucketized representation of likelihood, which is intended to give clients
/// highly stable results across model upgrades.
public enum Google_Cloud_Vision_V1p2beta1_Likelihood: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// Unknown likelihood.
  case unknown // = 0

  /// It is very unlikely that the image belongs to the specified vertical.
  case veryUnlikely // = 1

  /// It is unlikely that the image belongs to the specified vertical.
  case unlikely // = 2

  /// It is possible that the image belongs to the specified vertical.
  case possible // = 3

  /// It is likely that the image belongs to the specified vertical.
  case likely // = 4

  /// It is very likely that the image belongs to the specified vertical.
  case veryLikely // = 5
  case UNRECOGNIZED(Int)

  public init() {
    self = .unknown
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unknown
    case 1: self = .veryUnlikely
    case 2: self = .unlikely
    case 3: self = .possible
    case 4: self = .likely
    case 5: self = .veryLikely
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .unknown: return 0
    case .veryUnlikely: return 1
    case .unlikely: return 2
    case .possible: return 3
    case .likely: return 4
    case .veryLikely: return 5
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Google_Cloud_Vision_V1p2beta1_Likelihood: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Vision_V1p2beta1_Likelihood] = [
    .unknown,
    .veryUnlikely,
    .unlikely,
    .possible,
    .likely,
    .veryLikely,
  ]
}

#endif  // swift(>=4.2)

/// The type of Google Cloud Vision API detection to perform, and the maximum
/// number of results to return for that type. Multiple `Feature` objects can
/// be specified in the `features` list.
public struct Google_Cloud_Vision_V1p2beta1_Feature {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The feature type.
  public var type: Google_Cloud_Vision_V1p2beta1_Feature.TypeEnum = .unspecified

  /// Maximum number of results of this type. Does not apply to
  /// `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`.
  public var maxResults: Int32 = 0

  /// Model to use for the feature.
  /// Supported values: "builtin/stable" (the default if unset) and
  /// "builtin/latest".
  public var model: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Type of Google Cloud Vision API feature to be extracted.
  public enum TypeEnum: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Unspecified feature type.
    case unspecified // = 0

    /// Run face detection.
    case faceDetection // = 1

    /// Run landmark detection.
    case landmarkDetection // = 2

    /// Run logo detection.
    case logoDetection // = 3

    /// Run label detection.
    case labelDetection // = 4

    /// Run text detection / optical character recognition (OCR). Text detection
    /// is optimized for areas of text within a larger image; if the image is
    /// a document, use `DOCUMENT_TEXT_DETECTION` instead.
    case textDetection // = 5

    /// Run dense text document OCR. Takes precedence when both
    /// `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.
    case documentTextDetection // = 11

    /// Run Safe Search to detect potentially unsafe
    /// or undesirable content.
    case safeSearchDetection // = 6

    /// Compute a set of image properties, such as the
    /// image's dominant colors.
    case imageProperties // = 7

    /// Run crop hints.
    case cropHints // = 9

    /// Run web detection.
    case webDetection // = 10
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .faceDetection
      case 2: self = .landmarkDetection
      case 3: self = .logoDetection
      case 4: self = .labelDetection
      case 5: self = .textDetection
      case 6: self = .safeSearchDetection
      case 7: self = .imageProperties
      case 9: self = .cropHints
      case 10: self = .webDetection
      case 11: self = .documentTextDetection
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .faceDetection: return 1
      case .landmarkDetection: return 2
      case .logoDetection: return 3
      case .labelDetection: return 4
      case .textDetection: return 5
      case .safeSearchDetection: return 6
      case .imageProperties: return 7
      case .cropHints: return 9
      case .webDetection: return 10
      case .documentTextDetection: return 11
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}
}

#if swift(>=4.2)

extension Google_Cloud_Vision_V1p2beta1_Feature.TypeEnum: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Vision_V1p2beta1_Feature.TypeEnum] = [
    .unspecified,
    .faceDetection,
    .landmarkDetection,
    .logoDetection,
    .labelDetection,
    .textDetection,
    .documentTextDetection,
    .safeSearchDetection,
    .imageProperties,
    .cropHints,
    .webDetection,
  ]
}

#endif  // swift(>=4.2)

/// External image source (Google Cloud Storage or web URL image location).
public struct Google_Cloud_Vision_V1p2beta1_ImageSource {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// **Use `image_uri` instead.**
  ///
  /// The Google Cloud Storage  URI of the form
  /// `gs://bucket_name/object_name`. Object versioning is not supported. See
  /// [Google Cloud Storage Request
  /// URIs](https://cloud.google.com/storage/docs/reference-uris) for more info.
  public var gcsImageUri: String = String()

  /// The URI of the source image. Can be either:
  ///
  /// 1. A Google Cloud Storage URI of the form
  ///    `gs://bucket_name/object_name`. Object versioning is not supported. See
  ///    [Google Cloud Storage Request
  ///    URIs](https://cloud.google.com/storage/docs/reference-uris) for more
  ///    info.
  ///
  /// 2. A publicly-accessible image HTTP/HTTPS URL. When fetching images from
  ///    HTTP/HTTPS URLs, Google cannot guarantee that the request will be
  ///    completed. Your request may fail if the specified host denies the
  ///    request (e.g. due to request throttling or DOS prevention), or if Google
  ///    throttles requests to the site for abuse prevention. You should not
  ///    depend on externally-hosted images for production applications.
  ///
  /// When both `gcs_image_uri` and `image_uri` are specified, `image_uri` takes
  /// precedence.
  public var imageUri: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Client image to perform Google Cloud Vision API tasks over.
public struct Google_Cloud_Vision_V1p2beta1_Image {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Image content, represented as a stream of bytes.
  /// Note: As with all `bytes` fields, protobuffers use a pure binary
  /// representation, whereas JSON representations use base64.
  public var content: Data = Data()

  /// Google Cloud Storage image location, or publicly-accessible image
  /// URL. If both `content` and `source` are provided for an image, `content`
  /// takes precedence and is used to perform the image annotation request.
  public var source: Google_Cloud_Vision_V1p2beta1_ImageSource {
    get {return _source ?? Google_Cloud_Vision_V1p2beta1_ImageSource()}
    set {_source = newValue}
  }
  /// Returns true if `source` has been explicitly set.
  public var hasSource: Bool {return self._source != nil}
  /// Clears the value of `source`. Subsequent reads from it will return its default value.
  public mutating func clearSource() {self._source = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _source: Google_Cloud_Vision_V1p2beta1_ImageSource? = nil
}

/// A face annotation object contains the results of face detection.
public struct Google_Cloud_Vision_V1p2beta1_FaceAnnotation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The bounding polygon around the face. The coordinates of the bounding box
  /// are in the original image's scale, as returned in `ImageParams`.
  /// The bounding box is computed to "frame" the face in accordance with human
  /// expectations. It is based on the landmarker results.
  /// Note that one or more x and/or y coordinates may not be generated in the
  /// `BoundingPoly` (the polygon will be unbounded) if only a partial face
  /// appears in the image to be annotated.
  public var boundingPoly: Google_Cloud_Vision_V1p2beta1_BoundingPoly {
    get {return _storage._boundingPoly ?? Google_Cloud_Vision_V1p2beta1_BoundingPoly()}
    set {_uniqueStorage()._boundingPoly = newValue}
  }
  /// Returns true if `boundingPoly` has been explicitly set.
  public var hasBoundingPoly: Bool {return _storage._boundingPoly != nil}
  /// Clears the value of `boundingPoly`. Subsequent reads from it will return its default value.
  public mutating func clearBoundingPoly() {_uniqueStorage()._boundingPoly = nil}

  /// The `fd_bounding_poly` bounding polygon is tighter than the
  /// `boundingPoly`, and encloses only the skin part of the face. Typically, it
  /// is used to eliminate the face from any image analysis that detects the
  /// "amount of skin" visible in an image. It is not based on the
  /// landmarker results, only on the initial face detection, hence
  /// the <code>fd</code> (face detection) prefix.
  public var fdBoundingPoly: Google_Cloud_Vision_V1p2beta1_BoundingPoly {
    get {return _storage._fdBoundingPoly ?? Google_Cloud_Vision_V1p2beta1_BoundingPoly()}
    set {_uniqueStorage()._fdBoundingPoly = newValue}
  }
  /// Returns true if `fdBoundingPoly` has been explicitly set.
  public var hasFdBoundingPoly: Bool {return _storage._fdBoundingPoly != nil}
  /// Clears the value of `fdBoundingPoly`. Subsequent reads from it will return its default value.
  public mutating func clearFdBoundingPoly() {_uniqueStorage()._fdBoundingPoly = nil}

  /// Detected face landmarks.
  public var landmarks: [Google_Cloud_Vision_V1p2beta1_FaceAnnotation.Landmark] {
    get {return _storage._landmarks}
    set {_uniqueStorage()._landmarks = newValue}
  }

  /// Roll angle, which indicates the amount of clockwise/anti-clockwise rotation
  /// of the face relative to the image vertical about the axis perpendicular to
  /// the face. Range [-180,180].
  public var rollAngle: Float {
    get {return _storage._rollAngle}
    set {_uniqueStorage()._rollAngle = newValue}
  }

  /// Yaw angle, which indicates the leftward/rightward angle that the face is
  /// pointing relative to the vertical plane perpendicular to the image. Range
  /// [-180,180].
  public var panAngle: Float {
    get {return _storage._panAngle}
    set {_uniqueStorage()._panAngle = newValue}
  }

  /// Pitch angle, which indicates the upwards/downwards angle that the face is
  /// pointing relative to the image's horizontal plane. Range [-180,180].
  public var tiltAngle: Float {
    get {return _storage._tiltAngle}
    set {_uniqueStorage()._tiltAngle = newValue}
  }

  /// Detection confidence. Range [0, 1].
  public var detectionConfidence: Float {
    get {return _storage._detectionConfidence}
    set {_uniqueStorage()._detectionConfidence = newValue}
  }

  /// Face landmarking confidence. Range [0, 1].
  public var landmarkingConfidence: Float {
    get {return _storage._landmarkingConfidence}
    set {_uniqueStorage()._landmarkingConfidence = newValue}
  }

  /// Joy likelihood.
  public var joyLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood {
    get {return _storage._joyLikelihood}
    set {_uniqueStorage()._joyLikelihood = newValue}
  }

  /// Sorrow likelihood.
  public var sorrowLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood {
    get {return _storage._sorrowLikelihood}
    set {_uniqueStorage()._sorrowLikelihood = newValue}
  }

  /// Anger likelihood.
  public var angerLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood {
    get {return _storage._angerLikelihood}
    set {_uniqueStorage()._angerLikelihood = newValue}
  }

  /// Surprise likelihood.
  public var surpriseLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood {
    get {return _storage._surpriseLikelihood}
    set {_uniqueStorage()._surpriseLikelihood = newValue}
  }

  /// Under-exposed likelihood.
  public var underExposedLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood {
    get {return _storage._underExposedLikelihood}
    set {_uniqueStorage()._underExposedLikelihood = newValue}
  }

  /// Blurred likelihood.
  public var blurredLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood {
    get {return _storage._blurredLikelihood}
    set {_uniqueStorage()._blurredLikelihood = newValue}
  }

  /// Headwear likelihood.
  public var headwearLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood {
    get {return _storage._headwearLikelihood}
    set {_uniqueStorage()._headwearLikelihood = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// A face-specific landmark (for example, a face feature).
  public struct Landmark {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Face landmark type.
    public var type: Google_Cloud_Vision_V1p2beta1_FaceAnnotation.Landmark.TypeEnum = .unknownLandmark

    /// Face landmark position.
    public var position: Google_Cloud_Vision_V1p2beta1_Position {
      get {return _position ?? Google_Cloud_Vision_V1p2beta1_Position()}
      set {_position = newValue}
    }
    /// Returns true if `position` has been explicitly set.
    public var hasPosition: Bool {return self._position != nil}
    /// Clears the value of `position`. Subsequent reads from it will return its default value.
    public mutating func clearPosition() {self._position = nil}

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Face landmark (feature) type.
    /// Left and right are defined from the vantage of the viewer of the image
    /// without considering mirror projections typical of photos. So, `LEFT_EYE`,
    /// typically, is the person's right eye.
    public enum TypeEnum: SwiftProtobuf.Enum {
      public typealias RawValue = Int

      /// Unknown face landmark detected. Should not be filled.
      case unknownLandmark // = 0

      /// Left eye.
      case leftEye // = 1

      /// Right eye.
      case rightEye // = 2

      /// Left of left eyebrow.
      case leftOfLeftEyebrow // = 3

      /// Right of left eyebrow.
      case rightOfLeftEyebrow // = 4

      /// Left of right eyebrow.
      case leftOfRightEyebrow // = 5

      /// Right of right eyebrow.
      case rightOfRightEyebrow // = 6

      /// Midpoint between eyes.
      case midpointBetweenEyes // = 7

      /// Nose tip.
      case noseTip // = 8

      /// Upper lip.
      case upperLip // = 9

      /// Lower lip.
      case lowerLip // = 10

      /// Mouth left.
      case mouthLeft // = 11

      /// Mouth right.
      case mouthRight // = 12

      /// Mouth center.
      case mouthCenter // = 13

      /// Nose, bottom right.
      case noseBottomRight // = 14

      /// Nose, bottom left.
      case noseBottomLeft // = 15

      /// Nose, bottom center.
      case noseBottomCenter // = 16

      /// Left eye, top boundary.
      case leftEyeTopBoundary // = 17

      /// Left eye, right corner.
      case leftEyeRightCorner // = 18

      /// Left eye, bottom boundary.
      case leftEyeBottomBoundary // = 19

      /// Left eye, left corner.
      case leftEyeLeftCorner // = 20

      /// Right eye, top boundary.
      case rightEyeTopBoundary // = 21

      /// Right eye, right corner.
      case rightEyeRightCorner // = 22

      /// Right eye, bottom boundary.
      case rightEyeBottomBoundary // = 23

      /// Right eye, left corner.
      case rightEyeLeftCorner // = 24

      /// Left eyebrow, upper midpoint.
      case leftEyebrowUpperMidpoint // = 25

      /// Right eyebrow, upper midpoint.
      case rightEyebrowUpperMidpoint // = 26

      /// Left ear tragion.
      case leftEarTragion // = 27

      /// Right ear tragion.
      case rightEarTragion // = 28

      /// Left eye pupil.
      case leftEyePupil // = 29

      /// Right eye pupil.
      case rightEyePupil // = 30

      /// Forehead glabella.
      case foreheadGlabella // = 31

      /// Chin gnathion.
      case chinGnathion // = 32

      /// Chin left gonion.
      case chinLeftGonion // = 33

      /// Chin right gonion.
      case chinRightGonion // = 34
      case UNRECOGNIZED(Int)

      public init() {
        self = .unknownLandmark
      }

      public init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unknownLandmark
        case 1: self = .leftEye
        case 2: self = .rightEye
        case 3: self = .leftOfLeftEyebrow
        case 4: self = .rightOfLeftEyebrow
        case 5: self = .leftOfRightEyebrow
        case 6: self = .rightOfRightEyebrow
        case 7: self = .midpointBetweenEyes
        case 8: self = .noseTip
        case 9: self = .upperLip
        case 10: self = .lowerLip
        case 11: self = .mouthLeft
        case 12: self = .mouthRight
        case 13: self = .mouthCenter
        case 14: self = .noseBottomRight
        case 15: self = .noseBottomLeft
        case 16: self = .noseBottomCenter
        case 17: self = .leftEyeTopBoundary
        case 18: self = .leftEyeRightCorner
        case 19: self = .leftEyeBottomBoundary
        case 20: self = .leftEyeLeftCorner
        case 21: self = .rightEyeTopBoundary
        case 22: self = .rightEyeRightCorner
        case 23: self = .rightEyeBottomBoundary
        case 24: self = .rightEyeLeftCorner
        case 25: self = .leftEyebrowUpperMidpoint
        case 26: self = .rightEyebrowUpperMidpoint
        case 27: self = .leftEarTragion
        case 28: self = .rightEarTragion
        case 29: self = .leftEyePupil
        case 30: self = .rightEyePupil
        case 31: self = .foreheadGlabella
        case 32: self = .chinGnathion
        case 33: self = .chinLeftGonion
        case 34: self = .chinRightGonion
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      public var rawValue: Int {
        switch self {
        case .unknownLandmark: return 0
        case .leftEye: return 1
        case .rightEye: return 2
        case .leftOfLeftEyebrow: return 3
        case .rightOfLeftEyebrow: return 4
        case .leftOfRightEyebrow: return 5
        case .rightOfRightEyebrow: return 6
        case .midpointBetweenEyes: return 7
        case .noseTip: return 8
        case .upperLip: return 9
        case .lowerLip: return 10
        case .mouthLeft: return 11
        case .mouthRight: return 12
        case .mouthCenter: return 13
        case .noseBottomRight: return 14
        case .noseBottomLeft: return 15
        case .noseBottomCenter: return 16
        case .leftEyeTopBoundary: return 17
        case .leftEyeRightCorner: return 18
        case .leftEyeBottomBoundary: return 19
        case .leftEyeLeftCorner: return 20
        case .rightEyeTopBoundary: return 21
        case .rightEyeRightCorner: return 22
        case .rightEyeBottomBoundary: return 23
        case .rightEyeLeftCorner: return 24
        case .leftEyebrowUpperMidpoint: return 25
        case .rightEyebrowUpperMidpoint: return 26
        case .leftEarTragion: return 27
        case .rightEarTragion: return 28
        case .leftEyePupil: return 29
        case .rightEyePupil: return 30
        case .foreheadGlabella: return 31
        case .chinGnathion: return 32
        case .chinLeftGonion: return 33
        case .chinRightGonion: return 34
        case .UNRECOGNIZED(let i): return i
        }
      }

    }

    public init() {}

    fileprivate var _position: Google_Cloud_Vision_V1p2beta1_Position? = nil
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

#if swift(>=4.2)

extension Google_Cloud_Vision_V1p2beta1_FaceAnnotation.Landmark.TypeEnum: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Vision_V1p2beta1_FaceAnnotation.Landmark.TypeEnum] = [
    .unknownLandmark,
    .leftEye,
    .rightEye,
    .leftOfLeftEyebrow,
    .rightOfLeftEyebrow,
    .leftOfRightEyebrow,
    .rightOfRightEyebrow,
    .midpointBetweenEyes,
    .noseTip,
    .upperLip,
    .lowerLip,
    .mouthLeft,
    .mouthRight,
    .mouthCenter,
    .noseBottomRight,
    .noseBottomLeft,
    .noseBottomCenter,
    .leftEyeTopBoundary,
    .leftEyeRightCorner,
    .leftEyeBottomBoundary,
    .leftEyeLeftCorner,
    .rightEyeTopBoundary,
    .rightEyeRightCorner,
    .rightEyeBottomBoundary,
    .rightEyeLeftCorner,
    .leftEyebrowUpperMidpoint,
    .rightEyebrowUpperMidpoint,
    .leftEarTragion,
    .rightEarTragion,
    .leftEyePupil,
    .rightEyePupil,
    .foreheadGlabella,
    .chinGnathion,
    .chinLeftGonion,
    .chinRightGonion,
  ]
}

#endif  // swift(>=4.2)

/// Detected entity location information.
public struct Google_Cloud_Vision_V1p2beta1_LocationInfo {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// lat/long location coordinates.
  public var latLng: Google_Type_LatLng {
    get {return _latLng ?? Google_Type_LatLng()}
    set {_latLng = newValue}
  }
  /// Returns true if `latLng` has been explicitly set.
  public var hasLatLng: Bool {return self._latLng != nil}
  /// Clears the value of `latLng`. Subsequent reads from it will return its default value.
  public mutating func clearLatLng() {self._latLng = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _latLng: Google_Type_LatLng? = nil
}

/// A `Property` consists of a user-supplied name/value pair.
public struct Google_Cloud_Vision_V1p2beta1_Property {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Name of the property.
  public var name: String = String()

  /// Value of the property.
  public var value: String = String()

  /// Value of numeric properties.
  public var uint64Value: UInt64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Set of detected entity features.
public struct Google_Cloud_Vision_V1p2beta1_EntityAnnotation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Opaque entity ID. Some IDs may be available in
  /// [Google Knowledge Graph Search
  /// API](https://developers.google.com/knowledge-graph/).
  public var mid: String = String()

  /// The language code for the locale in which the entity textual
  /// `description` is expressed.
  public var locale: String = String()

  /// Entity textual description, expressed in its `locale` language.
  public var description_p: String = String()

  /// Overall score of the result. Range [0, 1].
  public var score: Float = 0

  /// **Deprecated. Use `score` instead.**
  /// The accuracy of the entity detection in an image.
  /// For example, for an image in which the "Eiffel Tower" entity is detected,
  /// this field represents the confidence that there is a tower in the query
  /// image. Range [0, 1].
  public var confidence: Float = 0

  /// The relevancy of the ICA (Image Content Annotation) label to the
  /// image. For example, the relevancy of "tower" is likely higher to an image
  /// containing the detected "Eiffel Tower" than to an image containing a
  /// detected distant towering building, even though the confidence that
  /// there is a tower in each image may be the same. Range [0, 1].
  public var topicality: Float = 0

  /// Image region to which this entity belongs. Not produced
  /// for `LABEL_DETECTION` features.
  public var boundingPoly: Google_Cloud_Vision_V1p2beta1_BoundingPoly {
    get {return _boundingPoly ?? Google_Cloud_Vision_V1p2beta1_BoundingPoly()}
    set {_boundingPoly = newValue}
  }
  /// Returns true if `boundingPoly` has been explicitly set.
  public var hasBoundingPoly: Bool {return self._boundingPoly != nil}
  /// Clears the value of `boundingPoly`. Subsequent reads from it will return its default value.
  public mutating func clearBoundingPoly() {self._boundingPoly = nil}

  /// The location information for the detected entity. Multiple
  /// `LocationInfo` elements can be present because one location may
  /// indicate the location of the scene in the image, and another location
  /// may indicate the location of the place where the image was taken.
  /// Location information is usually present for landmarks.
  public var locations: [Google_Cloud_Vision_V1p2beta1_LocationInfo] = []

  /// Some entities may have optional user-supplied `Property` (name/value)
  /// fields, such a score or string that qualifies the entity.
  public var properties: [Google_Cloud_Vision_V1p2beta1_Property] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _boundingPoly: Google_Cloud_Vision_V1p2beta1_BoundingPoly? = nil
}

/// Set of features pertaining to the image, computed by computer vision
/// methods over safe-search verticals (for example, adult, spoof, medical,
/// violence).
public struct Google_Cloud_Vision_V1p2beta1_SafeSearchAnnotation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Represents the adult content likelihood for the image. Adult content may
  /// contain elements such as nudity, pornographic images or cartoons, or
  /// sexual activities.
  public var adult: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown

  /// Spoof likelihood. The likelihood that an modification
  /// was made to the image's canonical version to make it appear
  /// funny or offensive.
  public var spoof: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown

  /// Likelihood that this is a medical image.
  public var medical: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown

  /// Likelihood that this image contains violent content.
  public var violence: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown

  /// Likelihood that the request image contains racy content. Racy content may
  /// include (but is not limited to) skimpy or sheer clothing, strategically
  /// covered nudity, lewd or provocative poses, or close-ups of sensitive
  /// body areas.
  public var racy: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Rectangle determined by min and max `LatLng` pairs.
public struct Google_Cloud_Vision_V1p2beta1_LatLongRect {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Min lat/long pair.
  public var minLatLng: Google_Type_LatLng {
    get {return _minLatLng ?? Google_Type_LatLng()}
    set {_minLatLng = newValue}
  }
  /// Returns true if `minLatLng` has been explicitly set.
  public var hasMinLatLng: Bool {return self._minLatLng != nil}
  /// Clears the value of `minLatLng`. Subsequent reads from it will return its default value.
  public mutating func clearMinLatLng() {self._minLatLng = nil}

  /// Max lat/long pair.
  public var maxLatLng: Google_Type_LatLng {
    get {return _maxLatLng ?? Google_Type_LatLng()}
    set {_maxLatLng = newValue}
  }
  /// Returns true if `maxLatLng` has been explicitly set.
  public var hasMaxLatLng: Bool {return self._maxLatLng != nil}
  /// Clears the value of `maxLatLng`. Subsequent reads from it will return its default value.
  public mutating func clearMaxLatLng() {self._maxLatLng = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _minLatLng: Google_Type_LatLng? = nil
  fileprivate var _maxLatLng: Google_Type_LatLng? = nil
}

/// Color information consists of RGB channels, score, and the fraction of
/// the image that the color occupies in the image.
public struct Google_Cloud_Vision_V1p2beta1_ColorInfo {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// RGB components of the color.
  public var color: Google_Type_Color {
    get {return _color ?? Google_Type_Color()}
    set {_color = newValue}
  }
  /// Returns true if `color` has been explicitly set.
  public var hasColor: Bool {return self._color != nil}
  /// Clears the value of `color`. Subsequent reads from it will return its default value.
  public mutating func clearColor() {self._color = nil}

  /// Image-specific score for this color. Value in range [0, 1].
  public var score: Float = 0

  /// The fraction of pixels the color occupies in the image.
  /// Value in range [0, 1].
  public var pixelFraction: Float = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _color: Google_Type_Color? = nil
}

/// Set of dominant colors and their corresponding scores.
public struct Google_Cloud_Vision_V1p2beta1_DominantColorsAnnotation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// RGB color values with their score and pixel fraction.
  public var colors: [Google_Cloud_Vision_V1p2beta1_ColorInfo] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Stores image properties, such as dominant colors.
public struct Google_Cloud_Vision_V1p2beta1_ImageProperties {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// If present, dominant colors completed successfully.
  public var dominantColors: Google_Cloud_Vision_V1p2beta1_DominantColorsAnnotation {
    get {return _dominantColors ?? Google_Cloud_Vision_V1p2beta1_DominantColorsAnnotation()}
    set {_dominantColors = newValue}
  }
  /// Returns true if `dominantColors` has been explicitly set.
  public var hasDominantColors: Bool {return self._dominantColors != nil}
  /// Clears the value of `dominantColors`. Subsequent reads from it will return its default value.
  public mutating func clearDominantColors() {self._dominantColors = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _dominantColors: Google_Cloud_Vision_V1p2beta1_DominantColorsAnnotation? = nil
}

/// Single crop hint that is used to generate a new crop when serving an image.
public struct Google_Cloud_Vision_V1p2beta1_CropHint {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The bounding polygon for the crop region. The coordinates of the bounding
  /// box are in the original image's scale, as returned in `ImageParams`.
  public var boundingPoly: Google_Cloud_Vision_V1p2beta1_BoundingPoly {
    get {return _boundingPoly ?? Google_Cloud_Vision_V1p2beta1_BoundingPoly()}
    set {_boundingPoly = newValue}
  }
  /// Returns true if `boundingPoly` has been explicitly set.
  public var hasBoundingPoly: Bool {return self._boundingPoly != nil}
  /// Clears the value of `boundingPoly`. Subsequent reads from it will return its default value.
  public mutating func clearBoundingPoly() {self._boundingPoly = nil}

  /// Confidence of this being a salient region.  Range [0, 1].
  public var confidence: Float = 0

  /// Fraction of importance of this salient region with respect to the original
  /// image.
  public var importanceFraction: Float = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _boundingPoly: Google_Cloud_Vision_V1p2beta1_BoundingPoly? = nil
}

/// Set of crop hints that are used to generate new crops when serving images.
public struct Google_Cloud_Vision_V1p2beta1_CropHintsAnnotation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Crop hint results.
  public var cropHints: [Google_Cloud_Vision_V1p2beta1_CropHint] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Parameters for crop hints annotation request.
public struct Google_Cloud_Vision_V1p2beta1_CropHintsParams {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Aspect ratios in floats, representing the ratio of the width to the height
  /// of the image. For example, if the desired aspect ratio is 4/3, the
  /// corresponding float value should be 1.33333.  If not specified, the
  /// best possible crop is returned. The number of provided aspect ratios is
  /// limited to a maximum of 16; any aspect ratios provided after the 16th are
  /// ignored.
  public var aspectRatios: [Float] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Parameters for web detection request.
public struct Google_Cloud_Vision_V1p2beta1_WebDetectionParams {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Whether to include results derived from the geo information in the image.
  public var includeGeoResults: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Image context and/or feature-specific parameters.
public struct Google_Cloud_Vision_V1p2beta1_ImageContext {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Not used.
  public var latLongRect: Google_Cloud_Vision_V1p2beta1_LatLongRect {
    get {return _latLongRect ?? Google_Cloud_Vision_V1p2beta1_LatLongRect()}
    set {_latLongRect = newValue}
  }
  /// Returns true if `latLongRect` has been explicitly set.
  public var hasLatLongRect: Bool {return self._latLongRect != nil}
  /// Clears the value of `latLongRect`. Subsequent reads from it will return its default value.
  public mutating func clearLatLongRect() {self._latLongRect = nil}

  /// List of languages to use for TEXT_DETECTION. In most cases, an empty value
  /// yields the best results since it enables automatic language detection. For
  /// languages based on the Latin alphabet, setting `language_hints` is not
  /// needed. In rare cases, when the language of the text in the image is known,
  /// setting a hint will help get better results (although it will be a
  /// significant hindrance if the hint is wrong). Text detection returns an
  /// error if one or more of the specified languages is not one of the
  /// [supported languages](https://cloud.google.com/vision/docs/languages).
  public var languageHints: [String] = []

  /// Parameters for crop hints annotation request.
  public var cropHintsParams: Google_Cloud_Vision_V1p2beta1_CropHintsParams {
    get {return _cropHintsParams ?? Google_Cloud_Vision_V1p2beta1_CropHintsParams()}
    set {_cropHintsParams = newValue}
  }
  /// Returns true if `cropHintsParams` has been explicitly set.
  public var hasCropHintsParams: Bool {return self._cropHintsParams != nil}
  /// Clears the value of `cropHintsParams`. Subsequent reads from it will return its default value.
  public mutating func clearCropHintsParams() {self._cropHintsParams = nil}

  /// Parameters for web detection.
  public var webDetectionParams: Google_Cloud_Vision_V1p2beta1_WebDetectionParams {
    get {return _webDetectionParams ?? Google_Cloud_Vision_V1p2beta1_WebDetectionParams()}
    set {_webDetectionParams = newValue}
  }
  /// Returns true if `webDetectionParams` has been explicitly set.
  public var hasWebDetectionParams: Bool {return self._webDetectionParams != nil}
  /// Clears the value of `webDetectionParams`. Subsequent reads from it will return its default value.
  public mutating func clearWebDetectionParams() {self._webDetectionParams = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _latLongRect: Google_Cloud_Vision_V1p2beta1_LatLongRect? = nil
  fileprivate var _cropHintsParams: Google_Cloud_Vision_V1p2beta1_CropHintsParams? = nil
  fileprivate var _webDetectionParams: Google_Cloud_Vision_V1p2beta1_WebDetectionParams? = nil
}

/// Request for performing Google Cloud Vision API tasks over a user-provided
/// image, with user-requested features.
public struct Google_Cloud_Vision_V1p2beta1_AnnotateImageRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The image to be processed.
  public var image: Google_Cloud_Vision_V1p2beta1_Image {
    get {return _image ?? Google_Cloud_Vision_V1p2beta1_Image()}
    set {_image = newValue}
  }
  /// Returns true if `image` has been explicitly set.
  public var hasImage: Bool {return self._image != nil}
  /// Clears the value of `image`. Subsequent reads from it will return its default value.
  public mutating func clearImage() {self._image = nil}

  /// Requested features.
  public var features: [Google_Cloud_Vision_V1p2beta1_Feature] = []

  /// Additional context that may accompany the image.
  public var imageContext: Google_Cloud_Vision_V1p2beta1_ImageContext {
    get {return _imageContext ?? Google_Cloud_Vision_V1p2beta1_ImageContext()}
    set {_imageContext = newValue}
  }
  /// Returns true if `imageContext` has been explicitly set.
  public var hasImageContext: Bool {return self._imageContext != nil}
  /// Clears the value of `imageContext`. Subsequent reads from it will return its default value.
  public mutating func clearImageContext() {self._imageContext = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _image: Google_Cloud_Vision_V1p2beta1_Image? = nil
  fileprivate var _imageContext: Google_Cloud_Vision_V1p2beta1_ImageContext? = nil
}

/// If an image was produced from a file (e.g. a PDF), this message gives
/// information about the source of that image.
public struct Google_Cloud_Vision_V1p2beta1_ImageAnnotationContext {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The URI of the file used to produce the image.
  public var uri: String = String()

  /// If the file was a PDF or TIFF, this field gives the page number within
  /// the file used to produce the image.
  public var pageNumber: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response to an image annotation request.
public struct Google_Cloud_Vision_V1p2beta1_AnnotateImageResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// If present, face detection has completed successfully.
  public var faceAnnotations: [Google_Cloud_Vision_V1p2beta1_FaceAnnotation] {
    get {return _storage._faceAnnotations}
    set {_uniqueStorage()._faceAnnotations = newValue}
  }

  /// If present, landmark detection has completed successfully.
  public var landmarkAnnotations: [Google_Cloud_Vision_V1p2beta1_EntityAnnotation] {
    get {return _storage._landmarkAnnotations}
    set {_uniqueStorage()._landmarkAnnotations = newValue}
  }

  /// If present, logo detection has completed successfully.
  public var logoAnnotations: [Google_Cloud_Vision_V1p2beta1_EntityAnnotation] {
    get {return _storage._logoAnnotations}
    set {_uniqueStorage()._logoAnnotations = newValue}
  }

  /// If present, label detection has completed successfully.
  public var labelAnnotations: [Google_Cloud_Vision_V1p2beta1_EntityAnnotation] {
    get {return _storage._labelAnnotations}
    set {_uniqueStorage()._labelAnnotations = newValue}
  }

  /// If present, text (OCR) detection has completed successfully.
  public var textAnnotations: [Google_Cloud_Vision_V1p2beta1_EntityAnnotation] {
    get {return _storage._textAnnotations}
    set {_uniqueStorage()._textAnnotations = newValue}
  }

  /// If present, text (OCR) detection or document (OCR) text detection has
  /// completed successfully.
  /// This annotation provides the structural hierarchy for the OCR detected
  /// text.
  public var fullTextAnnotation: Google_Cloud_Vision_V1p2beta1_TextAnnotation {
    get {return _storage._fullTextAnnotation ?? Google_Cloud_Vision_V1p2beta1_TextAnnotation()}
    set {_uniqueStorage()._fullTextAnnotation = newValue}
  }
  /// Returns true if `fullTextAnnotation` has been explicitly set.
  public var hasFullTextAnnotation: Bool {return _storage._fullTextAnnotation != nil}
  /// Clears the value of `fullTextAnnotation`. Subsequent reads from it will return its default value.
  public mutating func clearFullTextAnnotation() {_uniqueStorage()._fullTextAnnotation = nil}

  /// If present, safe-search annotation has completed successfully.
  public var safeSearchAnnotation: Google_Cloud_Vision_V1p2beta1_SafeSearchAnnotation {
    get {return _storage._safeSearchAnnotation ?? Google_Cloud_Vision_V1p2beta1_SafeSearchAnnotation()}
    set {_uniqueStorage()._safeSearchAnnotation = newValue}
  }
  /// Returns true if `safeSearchAnnotation` has been explicitly set.
  public var hasSafeSearchAnnotation: Bool {return _storage._safeSearchAnnotation != nil}
  /// Clears the value of `safeSearchAnnotation`. Subsequent reads from it will return its default value.
  public mutating func clearSafeSearchAnnotation() {_uniqueStorage()._safeSearchAnnotation = nil}

  /// If present, image properties were extracted successfully.
  public var imagePropertiesAnnotation: Google_Cloud_Vision_V1p2beta1_ImageProperties {
    get {return _storage._imagePropertiesAnnotation ?? Google_Cloud_Vision_V1p2beta1_ImageProperties()}
    set {_uniqueStorage()._imagePropertiesAnnotation = newValue}
  }
  /// Returns true if `imagePropertiesAnnotation` has been explicitly set.
  public var hasImagePropertiesAnnotation: Bool {return _storage._imagePropertiesAnnotation != nil}
  /// Clears the value of `imagePropertiesAnnotation`. Subsequent reads from it will return its default value.
  public mutating func clearImagePropertiesAnnotation() {_uniqueStorage()._imagePropertiesAnnotation = nil}

  /// If present, crop hints have completed successfully.
  public var cropHintsAnnotation: Google_Cloud_Vision_V1p2beta1_CropHintsAnnotation {
    get {return _storage._cropHintsAnnotation ?? Google_Cloud_Vision_V1p2beta1_CropHintsAnnotation()}
    set {_uniqueStorage()._cropHintsAnnotation = newValue}
  }
  /// Returns true if `cropHintsAnnotation` has been explicitly set.
  public var hasCropHintsAnnotation: Bool {return _storage._cropHintsAnnotation != nil}
  /// Clears the value of `cropHintsAnnotation`. Subsequent reads from it will return its default value.
  public mutating func clearCropHintsAnnotation() {_uniqueStorage()._cropHintsAnnotation = nil}

  /// If present, web detection has completed successfully.
  public var webDetection: Google_Cloud_Vision_V1p2beta1_WebDetection {
    get {return _storage._webDetection ?? Google_Cloud_Vision_V1p2beta1_WebDetection()}
    set {_uniqueStorage()._webDetection = newValue}
  }
  /// Returns true if `webDetection` has been explicitly set.
  public var hasWebDetection: Bool {return _storage._webDetection != nil}
  /// Clears the value of `webDetection`. Subsequent reads from it will return its default value.
  public mutating func clearWebDetection() {_uniqueStorage()._webDetection = nil}

  /// If set, represents the error message for the operation.
  /// Note that filled-in image annotations are guaranteed to be
  /// correct, even when `error` is set.
  public var error: Google_Rpc_Status {
    get {return _storage._error ?? Google_Rpc_Status()}
    set {_uniqueStorage()._error = newValue}
  }
  /// Returns true if `error` has been explicitly set.
  public var hasError: Bool {return _storage._error != nil}
  /// Clears the value of `error`. Subsequent reads from it will return its default value.
  public mutating func clearError() {_uniqueStorage()._error = nil}

  /// If present, contextual information is needed to understand where this image
  /// comes from.
  public var context: Google_Cloud_Vision_V1p2beta1_ImageAnnotationContext {
    get {return _storage._context ?? Google_Cloud_Vision_V1p2beta1_ImageAnnotationContext()}
    set {_uniqueStorage()._context = newValue}
  }
  /// Returns true if `context` has been explicitly set.
  public var hasContext: Bool {return _storage._context != nil}
  /// Clears the value of `context`. Subsequent reads from it will return its default value.
  public mutating func clearContext() {_uniqueStorage()._context = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Response to a single file annotation request. A file may contain one or more
/// images, which individually have their own responses.
public struct Google_Cloud_Vision_V1p2beta1_AnnotateFileResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Information about the file for which this response is generated.
  public var inputConfig: Google_Cloud_Vision_V1p2beta1_InputConfig {
    get {return _inputConfig ?? Google_Cloud_Vision_V1p2beta1_InputConfig()}
    set {_inputConfig = newValue}
  }
  /// Returns true if `inputConfig` has been explicitly set.
  public var hasInputConfig: Bool {return self._inputConfig != nil}
  /// Clears the value of `inputConfig`. Subsequent reads from it will return its default value.
  public mutating func clearInputConfig() {self._inputConfig = nil}

  /// Individual responses to images found within the file.
  public var responses: [Google_Cloud_Vision_V1p2beta1_AnnotateImageResponse] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _inputConfig: Google_Cloud_Vision_V1p2beta1_InputConfig? = nil
}

/// Multiple image annotation requests are batched into a single service call.
public struct Google_Cloud_Vision_V1p2beta1_BatchAnnotateImagesRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Individual image annotation requests for this batch.
  public var requests: [Google_Cloud_Vision_V1p2beta1_AnnotateImageRequest] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response to a batch image annotation request.
public struct Google_Cloud_Vision_V1p2beta1_BatchAnnotateImagesResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Individual responses to image annotation requests within the batch.
  public var responses: [Google_Cloud_Vision_V1p2beta1_AnnotateImageResponse] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// An offline file annotation request.
public struct Google_Cloud_Vision_V1p2beta1_AsyncAnnotateFileRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Information about the input file.
  public var inputConfig: Google_Cloud_Vision_V1p2beta1_InputConfig {
    get {return _inputConfig ?? Google_Cloud_Vision_V1p2beta1_InputConfig()}
    set {_inputConfig = newValue}
  }
  /// Returns true if `inputConfig` has been explicitly set.
  public var hasInputConfig: Bool {return self._inputConfig != nil}
  /// Clears the value of `inputConfig`. Subsequent reads from it will return its default value.
  public mutating func clearInputConfig() {self._inputConfig = nil}

  /// Required. Requested features.
  public var features: [Google_Cloud_Vision_V1p2beta1_Feature] = []

  /// Additional context that may accompany the image(s) in the file.
  public var imageContext: Google_Cloud_Vision_V1p2beta1_ImageContext {
    get {return _imageContext ?? Google_Cloud_Vision_V1p2beta1_ImageContext()}
    set {_imageContext = newValue}
  }
  /// Returns true if `imageContext` has been explicitly set.
  public var hasImageContext: Bool {return self._imageContext != nil}
  /// Clears the value of `imageContext`. Subsequent reads from it will return its default value.
  public mutating func clearImageContext() {self._imageContext = nil}

  /// Required. The desired output location and metadata (e.g. format).
  public var outputConfig: Google_Cloud_Vision_V1p2beta1_OutputConfig {
    get {return _outputConfig ?? Google_Cloud_Vision_V1p2beta1_OutputConfig()}
    set {_outputConfig = newValue}
  }
  /// Returns true if `outputConfig` has been explicitly set.
  public var hasOutputConfig: Bool {return self._outputConfig != nil}
  /// Clears the value of `outputConfig`. Subsequent reads from it will return its default value.
  public mutating func clearOutputConfig() {self._outputConfig = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _inputConfig: Google_Cloud_Vision_V1p2beta1_InputConfig? = nil
  fileprivate var _imageContext: Google_Cloud_Vision_V1p2beta1_ImageContext? = nil
  fileprivate var _outputConfig: Google_Cloud_Vision_V1p2beta1_OutputConfig? = nil
}

/// The response for a single offline file annotation request.
public struct Google_Cloud_Vision_V1p2beta1_AsyncAnnotateFileResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The output location and metadata from AsyncAnnotateFileRequest.
  public var outputConfig: Google_Cloud_Vision_V1p2beta1_OutputConfig {
    get {return _outputConfig ?? Google_Cloud_Vision_V1p2beta1_OutputConfig()}
    set {_outputConfig = newValue}
  }
  /// Returns true if `outputConfig` has been explicitly set.
  public var hasOutputConfig: Bool {return self._outputConfig != nil}
  /// Clears the value of `outputConfig`. Subsequent reads from it will return its default value.
  public mutating func clearOutputConfig() {self._outputConfig = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _outputConfig: Google_Cloud_Vision_V1p2beta1_OutputConfig? = nil
}

/// Multiple async file annotation requests are batched into a single service
/// call.
public struct Google_Cloud_Vision_V1p2beta1_AsyncBatchAnnotateFilesRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Individual async file annotation requests for this batch.
  public var requests: [Google_Cloud_Vision_V1p2beta1_AsyncAnnotateFileRequest] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response to an async batch file annotation request.
public struct Google_Cloud_Vision_V1p2beta1_AsyncBatchAnnotateFilesResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The list of file annotation responses, one for each request in
  /// AsyncBatchAnnotateFilesRequest.
  public var responses: [Google_Cloud_Vision_V1p2beta1_AsyncAnnotateFileResponse] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// The desired input location and metadata.
public struct Google_Cloud_Vision_V1p2beta1_InputConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The Google Cloud Storage location to read the input from.
  public var gcsSource: Google_Cloud_Vision_V1p2beta1_GcsSource {
    get {return _gcsSource ?? Google_Cloud_Vision_V1p2beta1_GcsSource()}
    set {_gcsSource = newValue}
  }
  /// Returns true if `gcsSource` has been explicitly set.
  public var hasGcsSource: Bool {return self._gcsSource != nil}
  /// Clears the value of `gcsSource`. Subsequent reads from it will return its default value.
  public mutating func clearGcsSource() {self._gcsSource = nil}

  /// The type of the file. Currently only "application/pdf" and "image/tiff"
  /// are supported. Wildcards are not supported.
  public var mimeType: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _gcsSource: Google_Cloud_Vision_V1p2beta1_GcsSource? = nil
}

/// The desired output location and metadata.
public struct Google_Cloud_Vision_V1p2beta1_OutputConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The Google Cloud Storage location to write the output(s) to.
  public var gcsDestination: Google_Cloud_Vision_V1p2beta1_GcsDestination {
    get {return _gcsDestination ?? Google_Cloud_Vision_V1p2beta1_GcsDestination()}
    set {_gcsDestination = newValue}
  }
  /// Returns true if `gcsDestination` has been explicitly set.
  public var hasGcsDestination: Bool {return self._gcsDestination != nil}
  /// Clears the value of `gcsDestination`. Subsequent reads from it will return its default value.
  public mutating func clearGcsDestination() {self._gcsDestination = nil}

  /// The max number of response protos to put into each output JSON file on GCS.
  /// The valid range is [1, 100]. If not specified, the default value is 20.
  ///
  /// For example, for one pdf file with 100 pages, 100 response protos will
  /// be generated. If `batch_size` = 20, then 5 json files each
  /// containing 20 response protos will be written under the prefix
  /// `gcs_destination`.`uri`.
  ///
  /// Currently, batch_size only applies to GcsDestination, with potential future
  /// support for other output configurations.
  public var batchSize: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _gcsDestination: Google_Cloud_Vision_V1p2beta1_GcsDestination? = nil
}

/// The Google Cloud Storage location where the input will be read from.
public struct Google_Cloud_Vision_V1p2beta1_GcsSource {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Google Cloud Storage URI for the input file. This must only be a GCS
  /// object. Wildcards are not currently supported.
  public var uri: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// The Google Cloud Storage location where the output will be written to.
public struct Google_Cloud_Vision_V1p2beta1_GcsDestination {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Google Cloud Storage URI where the results will be stored. Results will
  /// be in JSON format and preceded by its corresponding input URI. This field
  /// can either represent a single file, or a prefix for multiple outputs.
  /// Prefixes must end in a `/`.
  ///
  /// Examples:
  ///
  /// *    File: gs://bucket-name/filename.json
  /// *    Prefix: gs://bucket-name/prefix/here/
  /// *    File: gs://bucket-name/prefix/here
  ///
  /// If multiple outputs, each response is still AnnotateFileResponse, each of
  /// which contains some subset of the full list of AnnotateImageResponse.
  /// Multiple outputs can happen if, for example, the output JSON is too large
  /// and overflows into multiple sharded files.
  public var uri: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Contains metadata for the BatchAnnotateImages operation.
public struct Google_Cloud_Vision_V1p2beta1_OperationMetadata {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Current state of the batch operation.
  public var state: Google_Cloud_Vision_V1p2beta1_OperationMetadata.State = .unspecified

  /// The time when the batch request was received.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return self._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {self._createTime = nil}

  /// The time when the operation result was last updated.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return self._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {self._updateTime = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Batch operation states.
  public enum State: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Invalid.
    case unspecified // = 0

    /// Request is received.
    case created // = 1

    /// Request is actively being processed.
    case running // = 2

    /// The batch processing is done.
    case done // = 3

    /// The batch processing was cancelled.
    case cancelled // = 4
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .created
      case 2: self = .running
      case 3: self = .done
      case 4: self = .cancelled
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .created: return 1
      case .running: return 2
      case .done: return 3
      case .cancelled: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
  fileprivate var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

#if swift(>=4.2)

extension Google_Cloud_Vision_V1p2beta1_OperationMetadata.State: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Vision_V1p2beta1_OperationMetadata.State] = [
    .unspecified,
    .created,
    .running,
    .done,
    .cancelled,
  ]
}

#endif  // swift(>=4.2)

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.vision.v1p2beta1"

extension Google_Cloud_Vision_V1p2beta1_Likelihood: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "UNKNOWN"),
    1: .same(proto: "VERY_UNLIKELY"),
    2: .same(proto: "UNLIKELY"),
    3: .same(proto: "POSSIBLE"),
    4: .same(proto: "LIKELY"),
    5: .same(proto: "VERY_LIKELY"),
  ]
}

extension Google_Cloud_Vision_V1p2beta1_Feature: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Feature"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "type"),
    2: .standard(proto: "max_results"),
    3: .same(proto: "model"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.type) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.maxResults) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.model) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.type != .unspecified {
      try visitor.visitSingularEnumField(value: self.type, fieldNumber: 1)
    }
    if self.maxResults != 0 {
      try visitor.visitSingularInt32Field(value: self.maxResults, fieldNumber: 2)
    }
    if !self.model.isEmpty {
      try visitor.visitSingularStringField(value: self.model, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_Feature, rhs: Google_Cloud_Vision_V1p2beta1_Feature) -> Bool {
    if lhs.type != rhs.type {return false}
    if lhs.maxResults != rhs.maxResults {return false}
    if lhs.model != rhs.model {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_Feature.TypeEnum: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TYPE_UNSPECIFIED"),
    1: .same(proto: "FACE_DETECTION"),
    2: .same(proto: "LANDMARK_DETECTION"),
    3: .same(proto: "LOGO_DETECTION"),
    4: .same(proto: "LABEL_DETECTION"),
    5: .same(proto: "TEXT_DETECTION"),
    6: .same(proto: "SAFE_SEARCH_DETECTION"),
    7: .same(proto: "IMAGE_PROPERTIES"),
    9: .same(proto: "CROP_HINTS"),
    10: .same(proto: "WEB_DETECTION"),
    11: .same(proto: "DOCUMENT_TEXT_DETECTION"),
  ]
}

extension Google_Cloud_Vision_V1p2beta1_ImageSource: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ImageSource"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "gcs_image_uri"),
    2: .standard(proto: "image_uri"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.gcsImageUri) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.imageUri) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.gcsImageUri.isEmpty {
      try visitor.visitSingularStringField(value: self.gcsImageUri, fieldNumber: 1)
    }
    if !self.imageUri.isEmpty {
      try visitor.visitSingularStringField(value: self.imageUri, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_ImageSource, rhs: Google_Cloud_Vision_V1p2beta1_ImageSource) -> Bool {
    if lhs.gcsImageUri != rhs.gcsImageUri {return false}
    if lhs.imageUri != rhs.imageUri {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_Image: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Image"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "content"),
    2: .same(proto: "source"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.content) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._source) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.content.isEmpty {
      try visitor.visitSingularBytesField(value: self.content, fieldNumber: 1)
    }
    if let v = self._source {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_Image, rhs: Google_Cloud_Vision_V1p2beta1_Image) -> Bool {
    if lhs.content != rhs.content {return false}
    if lhs._source != rhs._source {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_FaceAnnotation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FaceAnnotation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "bounding_poly"),
    2: .standard(proto: "fd_bounding_poly"),
    3: .same(proto: "landmarks"),
    4: .standard(proto: "roll_angle"),
    5: .standard(proto: "pan_angle"),
    6: .standard(proto: "tilt_angle"),
    7: .standard(proto: "detection_confidence"),
    8: .standard(proto: "landmarking_confidence"),
    9: .standard(proto: "joy_likelihood"),
    10: .standard(proto: "sorrow_likelihood"),
    11: .standard(proto: "anger_likelihood"),
    12: .standard(proto: "surprise_likelihood"),
    13: .standard(proto: "under_exposed_likelihood"),
    14: .standard(proto: "blurred_likelihood"),
    15: .standard(proto: "headwear_likelihood"),
  ]

  fileprivate class _StorageClass {
    var _boundingPoly: Google_Cloud_Vision_V1p2beta1_BoundingPoly? = nil
    var _fdBoundingPoly: Google_Cloud_Vision_V1p2beta1_BoundingPoly? = nil
    var _landmarks: [Google_Cloud_Vision_V1p2beta1_FaceAnnotation.Landmark] = []
    var _rollAngle: Float = 0
    var _panAngle: Float = 0
    var _tiltAngle: Float = 0
    var _detectionConfidence: Float = 0
    var _landmarkingConfidence: Float = 0
    var _joyLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown
    var _sorrowLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown
    var _angerLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown
    var _surpriseLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown
    var _underExposedLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown
    var _blurredLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown
    var _headwearLikelihood: Google_Cloud_Vision_V1p2beta1_Likelihood = .unknown

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _boundingPoly = source._boundingPoly
      _fdBoundingPoly = source._fdBoundingPoly
      _landmarks = source._landmarks
      _rollAngle = source._rollAngle
      _panAngle = source._panAngle
      _tiltAngle = source._tiltAngle
      _detectionConfidence = source._detectionConfidence
      _landmarkingConfidence = source._landmarkingConfidence
      _joyLikelihood = source._joyLikelihood
      _sorrowLikelihood = source._sorrowLikelihood
      _angerLikelihood = source._angerLikelihood
      _surpriseLikelihood = source._surpriseLikelihood
      _underExposedLikelihood = source._underExposedLikelihood
      _blurredLikelihood = source._blurredLikelihood
      _headwearLikelihood = source._headwearLikelihood
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._boundingPoly) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._fdBoundingPoly) }()
        case 3: try { try decoder.decodeRepeatedMessageField(value: &_storage._landmarks) }()
        case 4: try { try decoder.decodeSingularFloatField(value: &_storage._rollAngle) }()
        case 5: try { try decoder.decodeSingularFloatField(value: &_storage._panAngle) }()
        case 6: try { try decoder.decodeSingularFloatField(value: &_storage._tiltAngle) }()
        case 7: try { try decoder.decodeSingularFloatField(value: &_storage._detectionConfidence) }()
        case 8: try { try decoder.decodeSingularFloatField(value: &_storage._landmarkingConfidence) }()
        case 9: try { try decoder.decodeSingularEnumField(value: &_storage._joyLikelihood) }()
        case 10: try { try decoder.decodeSingularEnumField(value: &_storage._sorrowLikelihood) }()
        case 11: try { try decoder.decodeSingularEnumField(value: &_storage._angerLikelihood) }()
        case 12: try { try decoder.decodeSingularEnumField(value: &_storage._surpriseLikelihood) }()
        case 13: try { try decoder.decodeSingularEnumField(value: &_storage._underExposedLikelihood) }()
        case 14: try { try decoder.decodeSingularEnumField(value: &_storage._blurredLikelihood) }()
        case 15: try { try decoder.decodeSingularEnumField(value: &_storage._headwearLikelihood) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if let v = _storage._boundingPoly {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }
      if let v = _storage._fdBoundingPoly {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if !_storage._landmarks.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._landmarks, fieldNumber: 3)
      }
      if _storage._rollAngle != 0 {
        try visitor.visitSingularFloatField(value: _storage._rollAngle, fieldNumber: 4)
      }
      if _storage._panAngle != 0 {
        try visitor.visitSingularFloatField(value: _storage._panAngle, fieldNumber: 5)
      }
      if _storage._tiltAngle != 0 {
        try visitor.visitSingularFloatField(value: _storage._tiltAngle, fieldNumber: 6)
      }
      if _storage._detectionConfidence != 0 {
        try visitor.visitSingularFloatField(value: _storage._detectionConfidence, fieldNumber: 7)
      }
      if _storage._landmarkingConfidence != 0 {
        try visitor.visitSingularFloatField(value: _storage._landmarkingConfidence, fieldNumber: 8)
      }
      if _storage._joyLikelihood != .unknown {
        try visitor.visitSingularEnumField(value: _storage._joyLikelihood, fieldNumber: 9)
      }
      if _storage._sorrowLikelihood != .unknown {
        try visitor.visitSingularEnumField(value: _storage._sorrowLikelihood, fieldNumber: 10)
      }
      if _storage._angerLikelihood != .unknown {
        try visitor.visitSingularEnumField(value: _storage._angerLikelihood, fieldNumber: 11)
      }
      if _storage._surpriseLikelihood != .unknown {
        try visitor.visitSingularEnumField(value: _storage._surpriseLikelihood, fieldNumber: 12)
      }
      if _storage._underExposedLikelihood != .unknown {
        try visitor.visitSingularEnumField(value: _storage._underExposedLikelihood, fieldNumber: 13)
      }
      if _storage._blurredLikelihood != .unknown {
        try visitor.visitSingularEnumField(value: _storage._blurredLikelihood, fieldNumber: 14)
      }
      if _storage._headwearLikelihood != .unknown {
        try visitor.visitSingularEnumField(value: _storage._headwearLikelihood, fieldNumber: 15)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_FaceAnnotation, rhs: Google_Cloud_Vision_V1p2beta1_FaceAnnotation) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._boundingPoly != rhs_storage._boundingPoly {return false}
        if _storage._fdBoundingPoly != rhs_storage._fdBoundingPoly {return false}
        if _storage._landmarks != rhs_storage._landmarks {return false}
        if _storage._rollAngle != rhs_storage._rollAngle {return false}
        if _storage._panAngle != rhs_storage._panAngle {return false}
        if _storage._tiltAngle != rhs_storage._tiltAngle {return false}
        if _storage._detectionConfidence != rhs_storage._detectionConfidence {return false}
        if _storage._landmarkingConfidence != rhs_storage._landmarkingConfidence {return false}
        if _storage._joyLikelihood != rhs_storage._joyLikelihood {return false}
        if _storage._sorrowLikelihood != rhs_storage._sorrowLikelihood {return false}
        if _storage._angerLikelihood != rhs_storage._angerLikelihood {return false}
        if _storage._surpriseLikelihood != rhs_storage._surpriseLikelihood {return false}
        if _storage._underExposedLikelihood != rhs_storage._underExposedLikelihood {return false}
        if _storage._blurredLikelihood != rhs_storage._blurredLikelihood {return false}
        if _storage._headwearLikelihood != rhs_storage._headwearLikelihood {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_FaceAnnotation.Landmark: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Vision_V1p2beta1_FaceAnnotation.protoMessageName + ".Landmark"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    3: .same(proto: "type"),
    4: .same(proto: "position"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 3: try { try decoder.decodeSingularEnumField(value: &self.type) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._position) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.type != .unknownLandmark {
      try visitor.visitSingularEnumField(value: self.type, fieldNumber: 3)
    }
    if let v = self._position {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_FaceAnnotation.Landmark, rhs: Google_Cloud_Vision_V1p2beta1_FaceAnnotation.Landmark) -> Bool {
    if lhs.type != rhs.type {return false}
    if lhs._position != rhs._position {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_FaceAnnotation.Landmark.TypeEnum: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "UNKNOWN_LANDMARK"),
    1: .same(proto: "LEFT_EYE"),
    2: .same(proto: "RIGHT_EYE"),
    3: .same(proto: "LEFT_OF_LEFT_EYEBROW"),
    4: .same(proto: "RIGHT_OF_LEFT_EYEBROW"),
    5: .same(proto: "LEFT_OF_RIGHT_EYEBROW"),
    6: .same(proto: "RIGHT_OF_RIGHT_EYEBROW"),
    7: .same(proto: "MIDPOINT_BETWEEN_EYES"),
    8: .same(proto: "NOSE_TIP"),
    9: .same(proto: "UPPER_LIP"),
    10: .same(proto: "LOWER_LIP"),
    11: .same(proto: "MOUTH_LEFT"),
    12: .same(proto: "MOUTH_RIGHT"),
    13: .same(proto: "MOUTH_CENTER"),
    14: .same(proto: "NOSE_BOTTOM_RIGHT"),
    15: .same(proto: "NOSE_BOTTOM_LEFT"),
    16: .same(proto: "NOSE_BOTTOM_CENTER"),
    17: .same(proto: "LEFT_EYE_TOP_BOUNDARY"),
    18: .same(proto: "LEFT_EYE_RIGHT_CORNER"),
    19: .same(proto: "LEFT_EYE_BOTTOM_BOUNDARY"),
    20: .same(proto: "LEFT_EYE_LEFT_CORNER"),
    21: .same(proto: "RIGHT_EYE_TOP_BOUNDARY"),
    22: .same(proto: "RIGHT_EYE_RIGHT_CORNER"),
    23: .same(proto: "RIGHT_EYE_BOTTOM_BOUNDARY"),
    24: .same(proto: "RIGHT_EYE_LEFT_CORNER"),
    25: .same(proto: "LEFT_EYEBROW_UPPER_MIDPOINT"),
    26: .same(proto: "RIGHT_EYEBROW_UPPER_MIDPOINT"),
    27: .same(proto: "LEFT_EAR_TRAGION"),
    28: .same(proto: "RIGHT_EAR_TRAGION"),
    29: .same(proto: "LEFT_EYE_PUPIL"),
    30: .same(proto: "RIGHT_EYE_PUPIL"),
    31: .same(proto: "FOREHEAD_GLABELLA"),
    32: .same(proto: "CHIN_GNATHION"),
    33: .same(proto: "CHIN_LEFT_GONION"),
    34: .same(proto: "CHIN_RIGHT_GONION"),
  ]
}

extension Google_Cloud_Vision_V1p2beta1_LocationInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".LocationInfo"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "lat_lng"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._latLng) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._latLng {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_LocationInfo, rhs: Google_Cloud_Vision_V1p2beta1_LocationInfo) -> Bool {
    if lhs._latLng != rhs._latLng {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_Property: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Property"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "value"),
    3: .standard(proto: "uint64_value"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.value) }()
      case 3: try { try decoder.decodeSingularUInt64Field(value: &self.uint64Value) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if !self.value.isEmpty {
      try visitor.visitSingularStringField(value: self.value, fieldNumber: 2)
    }
    if self.uint64Value != 0 {
      try visitor.visitSingularUInt64Field(value: self.uint64Value, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_Property, rhs: Google_Cloud_Vision_V1p2beta1_Property) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.value != rhs.value {return false}
    if lhs.uint64Value != rhs.uint64Value {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_EntityAnnotation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".EntityAnnotation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "mid"),
    2: .same(proto: "locale"),
    3: .same(proto: "description"),
    4: .same(proto: "score"),
    5: .same(proto: "confidence"),
    6: .same(proto: "topicality"),
    7: .standard(proto: "bounding_poly"),
    8: .same(proto: "locations"),
    9: .same(proto: "properties"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.mid) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.locale) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.description_p) }()
      case 4: try { try decoder.decodeSingularFloatField(value: &self.score) }()
      case 5: try { try decoder.decodeSingularFloatField(value: &self.confidence) }()
      case 6: try { try decoder.decodeSingularFloatField(value: &self.topicality) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._boundingPoly) }()
      case 8: try { try decoder.decodeRepeatedMessageField(value: &self.locations) }()
      case 9: try { try decoder.decodeRepeatedMessageField(value: &self.properties) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.mid.isEmpty {
      try visitor.visitSingularStringField(value: self.mid, fieldNumber: 1)
    }
    if !self.locale.isEmpty {
      try visitor.visitSingularStringField(value: self.locale, fieldNumber: 2)
    }
    if !self.description_p.isEmpty {
      try visitor.visitSingularStringField(value: self.description_p, fieldNumber: 3)
    }
    if self.score != 0 {
      try visitor.visitSingularFloatField(value: self.score, fieldNumber: 4)
    }
    if self.confidence != 0 {
      try visitor.visitSingularFloatField(value: self.confidence, fieldNumber: 5)
    }
    if self.topicality != 0 {
      try visitor.visitSingularFloatField(value: self.topicality, fieldNumber: 6)
    }
    if let v = self._boundingPoly {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }
    if !self.locations.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.locations, fieldNumber: 8)
    }
    if !self.properties.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.properties, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_EntityAnnotation, rhs: Google_Cloud_Vision_V1p2beta1_EntityAnnotation) -> Bool {
    if lhs.mid != rhs.mid {return false}
    if lhs.locale != rhs.locale {return false}
    if lhs.description_p != rhs.description_p {return false}
    if lhs.score != rhs.score {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.topicality != rhs.topicality {return false}
    if lhs._boundingPoly != rhs._boundingPoly {return false}
    if lhs.locations != rhs.locations {return false}
    if lhs.properties != rhs.properties {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_SafeSearchAnnotation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SafeSearchAnnotation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "adult"),
    2: .same(proto: "spoof"),
    3: .same(proto: "medical"),
    4: .same(proto: "violence"),
    9: .same(proto: "racy"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.adult) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.spoof) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.medical) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.violence) }()
      case 9: try { try decoder.decodeSingularEnumField(value: &self.racy) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.adult != .unknown {
      try visitor.visitSingularEnumField(value: self.adult, fieldNumber: 1)
    }
    if self.spoof != .unknown {
      try visitor.visitSingularEnumField(value: self.spoof, fieldNumber: 2)
    }
    if self.medical != .unknown {
      try visitor.visitSingularEnumField(value: self.medical, fieldNumber: 3)
    }
    if self.violence != .unknown {
      try visitor.visitSingularEnumField(value: self.violence, fieldNumber: 4)
    }
    if self.racy != .unknown {
      try visitor.visitSingularEnumField(value: self.racy, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_SafeSearchAnnotation, rhs: Google_Cloud_Vision_V1p2beta1_SafeSearchAnnotation) -> Bool {
    if lhs.adult != rhs.adult {return false}
    if lhs.spoof != rhs.spoof {return false}
    if lhs.medical != rhs.medical {return false}
    if lhs.violence != rhs.violence {return false}
    if lhs.racy != rhs.racy {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_LatLongRect: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".LatLongRect"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "min_lat_lng"),
    2: .standard(proto: "max_lat_lng"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._minLatLng) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._maxLatLng) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._minLatLng {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._maxLatLng {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_LatLongRect, rhs: Google_Cloud_Vision_V1p2beta1_LatLongRect) -> Bool {
    if lhs._minLatLng != rhs._minLatLng {return false}
    if lhs._maxLatLng != rhs._maxLatLng {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_ColorInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ColorInfo"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "color"),
    2: .same(proto: "score"),
    3: .standard(proto: "pixel_fraction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._color) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.score) }()
      case 3: try { try decoder.decodeSingularFloatField(value: &self.pixelFraction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._color {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if self.score != 0 {
      try visitor.visitSingularFloatField(value: self.score, fieldNumber: 2)
    }
    if self.pixelFraction != 0 {
      try visitor.visitSingularFloatField(value: self.pixelFraction, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_ColorInfo, rhs: Google_Cloud_Vision_V1p2beta1_ColorInfo) -> Bool {
    if lhs._color != rhs._color {return false}
    if lhs.score != rhs.score {return false}
    if lhs.pixelFraction != rhs.pixelFraction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_DominantColorsAnnotation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DominantColorsAnnotation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "colors"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.colors) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.colors.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.colors, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_DominantColorsAnnotation, rhs: Google_Cloud_Vision_V1p2beta1_DominantColorsAnnotation) -> Bool {
    if lhs.colors != rhs.colors {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_ImageProperties: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ImageProperties"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "dominant_colors"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._dominantColors) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._dominantColors {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_ImageProperties, rhs: Google_Cloud_Vision_V1p2beta1_ImageProperties) -> Bool {
    if lhs._dominantColors != rhs._dominantColors {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_CropHint: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CropHint"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "bounding_poly"),
    2: .same(proto: "confidence"),
    3: .standard(proto: "importance_fraction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._boundingPoly) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.confidence) }()
      case 3: try { try decoder.decodeSingularFloatField(value: &self.importanceFraction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._boundingPoly {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if self.confidence != 0 {
      try visitor.visitSingularFloatField(value: self.confidence, fieldNumber: 2)
    }
    if self.importanceFraction != 0 {
      try visitor.visitSingularFloatField(value: self.importanceFraction, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_CropHint, rhs: Google_Cloud_Vision_V1p2beta1_CropHint) -> Bool {
    if lhs._boundingPoly != rhs._boundingPoly {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.importanceFraction != rhs.importanceFraction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_CropHintsAnnotation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CropHintsAnnotation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "crop_hints"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.cropHints) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.cropHints.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.cropHints, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_CropHintsAnnotation, rhs: Google_Cloud_Vision_V1p2beta1_CropHintsAnnotation) -> Bool {
    if lhs.cropHints != rhs.cropHints {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_CropHintsParams: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CropHintsParams"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "aspect_ratios"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedFloatField(value: &self.aspectRatios) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.aspectRatios.isEmpty {
      try visitor.visitPackedFloatField(value: self.aspectRatios, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_CropHintsParams, rhs: Google_Cloud_Vision_V1p2beta1_CropHintsParams) -> Bool {
    if lhs.aspectRatios != rhs.aspectRatios {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_WebDetectionParams: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".WebDetectionParams"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .standard(proto: "include_geo_results"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularBoolField(value: &self.includeGeoResults) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.includeGeoResults != false {
      try visitor.visitSingularBoolField(value: self.includeGeoResults, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_WebDetectionParams, rhs: Google_Cloud_Vision_V1p2beta1_WebDetectionParams) -> Bool {
    if lhs.includeGeoResults != rhs.includeGeoResults {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_ImageContext: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ImageContext"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "lat_long_rect"),
    2: .standard(proto: "language_hints"),
    4: .standard(proto: "crop_hints_params"),
    6: .standard(proto: "web_detection_params"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._latLongRect) }()
      case 2: try { try decoder.decodeRepeatedStringField(value: &self.languageHints) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._cropHintsParams) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._webDetectionParams) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._latLongRect {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.languageHints.isEmpty {
      try visitor.visitRepeatedStringField(value: self.languageHints, fieldNumber: 2)
    }
    if let v = self._cropHintsParams {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    if let v = self._webDetectionParams {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_ImageContext, rhs: Google_Cloud_Vision_V1p2beta1_ImageContext) -> Bool {
    if lhs._latLongRect != rhs._latLongRect {return false}
    if lhs.languageHints != rhs.languageHints {return false}
    if lhs._cropHintsParams != rhs._cropHintsParams {return false}
    if lhs._webDetectionParams != rhs._webDetectionParams {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_AnnotateImageRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AnnotateImageRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "image"),
    2: .same(proto: "features"),
    3: .standard(proto: "image_context"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._image) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.features) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._imageContext) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._image {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.features.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.features, fieldNumber: 2)
    }
    if let v = self._imageContext {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_AnnotateImageRequest, rhs: Google_Cloud_Vision_V1p2beta1_AnnotateImageRequest) -> Bool {
    if lhs._image != rhs._image {return false}
    if lhs.features != rhs.features {return false}
    if lhs._imageContext != rhs._imageContext {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_ImageAnnotationContext: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ImageAnnotationContext"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "uri"),
    2: .standard(proto: "page_number"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.uri) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.pageNumber) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.uri.isEmpty {
      try visitor.visitSingularStringField(value: self.uri, fieldNumber: 1)
    }
    if self.pageNumber != 0 {
      try visitor.visitSingularInt32Field(value: self.pageNumber, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_ImageAnnotationContext, rhs: Google_Cloud_Vision_V1p2beta1_ImageAnnotationContext) -> Bool {
    if lhs.uri != rhs.uri {return false}
    if lhs.pageNumber != rhs.pageNumber {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_AnnotateImageResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AnnotateImageResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "face_annotations"),
    2: .standard(proto: "landmark_annotations"),
    3: .standard(proto: "logo_annotations"),
    4: .standard(proto: "label_annotations"),
    5: .standard(proto: "text_annotations"),
    12: .standard(proto: "full_text_annotation"),
    6: .standard(proto: "safe_search_annotation"),
    8: .standard(proto: "image_properties_annotation"),
    11: .standard(proto: "crop_hints_annotation"),
    13: .standard(proto: "web_detection"),
    9: .same(proto: "error"),
    21: .same(proto: "context"),
  ]

  fileprivate class _StorageClass {
    var _faceAnnotations: [Google_Cloud_Vision_V1p2beta1_FaceAnnotation] = []
    var _landmarkAnnotations: [Google_Cloud_Vision_V1p2beta1_EntityAnnotation] = []
    var _logoAnnotations: [Google_Cloud_Vision_V1p2beta1_EntityAnnotation] = []
    var _labelAnnotations: [Google_Cloud_Vision_V1p2beta1_EntityAnnotation] = []
    var _textAnnotations: [Google_Cloud_Vision_V1p2beta1_EntityAnnotation] = []
    var _fullTextAnnotation: Google_Cloud_Vision_V1p2beta1_TextAnnotation? = nil
    var _safeSearchAnnotation: Google_Cloud_Vision_V1p2beta1_SafeSearchAnnotation? = nil
    var _imagePropertiesAnnotation: Google_Cloud_Vision_V1p2beta1_ImageProperties? = nil
    var _cropHintsAnnotation: Google_Cloud_Vision_V1p2beta1_CropHintsAnnotation? = nil
    var _webDetection: Google_Cloud_Vision_V1p2beta1_WebDetection? = nil
    var _error: Google_Rpc_Status? = nil
    var _context: Google_Cloud_Vision_V1p2beta1_ImageAnnotationContext? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _faceAnnotations = source._faceAnnotations
      _landmarkAnnotations = source._landmarkAnnotations
      _logoAnnotations = source._logoAnnotations
      _labelAnnotations = source._labelAnnotations
      _textAnnotations = source._textAnnotations
      _fullTextAnnotation = source._fullTextAnnotation
      _safeSearchAnnotation = source._safeSearchAnnotation
      _imagePropertiesAnnotation = source._imagePropertiesAnnotation
      _cropHintsAnnotation = source._cropHintsAnnotation
      _webDetection = source._webDetection
      _error = source._error
      _context = source._context
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeRepeatedMessageField(value: &_storage._faceAnnotations) }()
        case 2: try { try decoder.decodeRepeatedMessageField(value: &_storage._landmarkAnnotations) }()
        case 3: try { try decoder.decodeRepeatedMessageField(value: &_storage._logoAnnotations) }()
        case 4: try { try decoder.decodeRepeatedMessageField(value: &_storage._labelAnnotations) }()
        case 5: try { try decoder.decodeRepeatedMessageField(value: &_storage._textAnnotations) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._safeSearchAnnotation) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._imagePropertiesAnnotation) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._error) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._cropHintsAnnotation) }()
        case 12: try { try decoder.decodeSingularMessageField(value: &_storage._fullTextAnnotation) }()
        case 13: try { try decoder.decodeSingularMessageField(value: &_storage._webDetection) }()
        case 21: try { try decoder.decodeSingularMessageField(value: &_storage._context) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._faceAnnotations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._faceAnnotations, fieldNumber: 1)
      }
      if !_storage._landmarkAnnotations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._landmarkAnnotations, fieldNumber: 2)
      }
      if !_storage._logoAnnotations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._logoAnnotations, fieldNumber: 3)
      }
      if !_storage._labelAnnotations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._labelAnnotations, fieldNumber: 4)
      }
      if !_storage._textAnnotations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._textAnnotations, fieldNumber: 5)
      }
      if let v = _storage._safeSearchAnnotation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      }
      if let v = _storage._imagePropertiesAnnotation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      }
      if let v = _storage._error {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      }
      if let v = _storage._cropHintsAnnotation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      }
      if let v = _storage._fullTextAnnotation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      }
      if let v = _storage._webDetection {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
      }
      if let v = _storage._context {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_AnnotateImageResponse, rhs: Google_Cloud_Vision_V1p2beta1_AnnotateImageResponse) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._faceAnnotations != rhs_storage._faceAnnotations {return false}
        if _storage._landmarkAnnotations != rhs_storage._landmarkAnnotations {return false}
        if _storage._logoAnnotations != rhs_storage._logoAnnotations {return false}
        if _storage._labelAnnotations != rhs_storage._labelAnnotations {return false}
        if _storage._textAnnotations != rhs_storage._textAnnotations {return false}
        if _storage._fullTextAnnotation != rhs_storage._fullTextAnnotation {return false}
        if _storage._safeSearchAnnotation != rhs_storage._safeSearchAnnotation {return false}
        if _storage._imagePropertiesAnnotation != rhs_storage._imagePropertiesAnnotation {return false}
        if _storage._cropHintsAnnotation != rhs_storage._cropHintsAnnotation {return false}
        if _storage._webDetection != rhs_storage._webDetection {return false}
        if _storage._error != rhs_storage._error {return false}
        if _storage._context != rhs_storage._context {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_AnnotateFileResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AnnotateFileResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "input_config"),
    2: .same(proto: "responses"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._inputConfig) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.responses) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._inputConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.responses.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.responses, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_AnnotateFileResponse, rhs: Google_Cloud_Vision_V1p2beta1_AnnotateFileResponse) -> Bool {
    if lhs._inputConfig != rhs._inputConfig {return false}
    if lhs.responses != rhs.responses {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_BatchAnnotateImagesRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchAnnotateImagesRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "requests"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.requests) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.requests.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.requests, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_BatchAnnotateImagesRequest, rhs: Google_Cloud_Vision_V1p2beta1_BatchAnnotateImagesRequest) -> Bool {
    if lhs.requests != rhs.requests {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_BatchAnnotateImagesResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchAnnotateImagesResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "responses"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.responses) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.responses.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.responses, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_BatchAnnotateImagesResponse, rhs: Google_Cloud_Vision_V1p2beta1_BatchAnnotateImagesResponse) -> Bool {
    if lhs.responses != rhs.responses {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_AsyncAnnotateFileRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AsyncAnnotateFileRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "input_config"),
    2: .same(proto: "features"),
    3: .standard(proto: "image_context"),
    4: .standard(proto: "output_config"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._inputConfig) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.features) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._imageContext) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._outputConfig) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._inputConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.features.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.features, fieldNumber: 2)
    }
    if let v = self._imageContext {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }
    if let v = self._outputConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_AsyncAnnotateFileRequest, rhs: Google_Cloud_Vision_V1p2beta1_AsyncAnnotateFileRequest) -> Bool {
    if lhs._inputConfig != rhs._inputConfig {return false}
    if lhs.features != rhs.features {return false}
    if lhs._imageContext != rhs._imageContext {return false}
    if lhs._outputConfig != rhs._outputConfig {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_AsyncAnnotateFileResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AsyncAnnotateFileResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "output_config"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._outputConfig) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._outputConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_AsyncAnnotateFileResponse, rhs: Google_Cloud_Vision_V1p2beta1_AsyncAnnotateFileResponse) -> Bool {
    if lhs._outputConfig != rhs._outputConfig {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_AsyncBatchAnnotateFilesRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AsyncBatchAnnotateFilesRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "requests"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.requests) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.requests.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.requests, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_AsyncBatchAnnotateFilesRequest, rhs: Google_Cloud_Vision_V1p2beta1_AsyncBatchAnnotateFilesRequest) -> Bool {
    if lhs.requests != rhs.requests {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_AsyncBatchAnnotateFilesResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AsyncBatchAnnotateFilesResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "responses"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.responses) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.responses.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.responses, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_AsyncBatchAnnotateFilesResponse, rhs: Google_Cloud_Vision_V1p2beta1_AsyncBatchAnnotateFilesResponse) -> Bool {
    if lhs.responses != rhs.responses {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_InputConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".InputConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "gcs_source"),
    2: .standard(proto: "mime_type"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._gcsSource) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.mimeType) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._gcsSource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.mimeType.isEmpty {
      try visitor.visitSingularStringField(value: self.mimeType, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_InputConfig, rhs: Google_Cloud_Vision_V1p2beta1_InputConfig) -> Bool {
    if lhs._gcsSource != rhs._gcsSource {return false}
    if lhs.mimeType != rhs.mimeType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_OutputConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".OutputConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "gcs_destination"),
    2: .standard(proto: "batch_size"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._gcsDestination) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.batchSize) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._gcsDestination {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if self.batchSize != 0 {
      try visitor.visitSingularInt32Field(value: self.batchSize, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_OutputConfig, rhs: Google_Cloud_Vision_V1p2beta1_OutputConfig) -> Bool {
    if lhs._gcsDestination != rhs._gcsDestination {return false}
    if lhs.batchSize != rhs.batchSize {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_GcsSource: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GcsSource"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "uri"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.uri) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.uri.isEmpty {
      try visitor.visitSingularStringField(value: self.uri, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_GcsSource, rhs: Google_Cloud_Vision_V1p2beta1_GcsSource) -> Bool {
    if lhs.uri != rhs.uri {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_GcsDestination: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GcsDestination"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "uri"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.uri) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.uri.isEmpty {
      try visitor.visitSingularStringField(value: self.uri, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_GcsDestination, rhs: Google_Cloud_Vision_V1p2beta1_GcsDestination) -> Bool {
    if lhs.uri != rhs.uri {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_OperationMetadata: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".OperationMetadata"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "state"),
    5: .standard(proto: "create_time"),
    6: .standard(proto: "update_time"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.state) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._createTime) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._updateTime) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.state != .unspecified {
      try visitor.visitSingularEnumField(value: self.state, fieldNumber: 1)
    }
    if let v = self._createTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }
    if let v = self._updateTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p2beta1_OperationMetadata, rhs: Google_Cloud_Vision_V1p2beta1_OperationMetadata) -> Bool {
    if lhs.state != rhs.state {return false}
    if lhs._createTime != rhs._createTime {return false}
    if lhs._updateTime != rhs._updateTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p2beta1_OperationMetadata.State: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "STATE_UNSPECIFIED"),
    1: .same(proto: "CREATED"),
    2: .same(proto: "RUNNING"),
    3: .same(proto: "DONE"),
    4: .same(proto: "CANCELLED"),
  ]
}
