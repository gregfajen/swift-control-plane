// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/vision/v1p1beta1/image_annotator.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2019 Google LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// A bucketized representation of likelihood, which is intended to give clients
/// highly stable results across model upgrades.
public enum Google_Cloud_Vision_V1p1beta1_Likelihood: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// Unknown likelihood.
  case unknown // = 0

  /// It is very unlikely that the image belongs to the specified vertical.
  case veryUnlikely // = 1

  /// It is unlikely that the image belongs to the specified vertical.
  case unlikely // = 2

  /// It is possible that the image belongs to the specified vertical.
  case possible // = 3

  /// It is likely that the image belongs to the specified vertical.
  case likely // = 4

  /// It is very likely that the image belongs to the specified vertical.
  case veryLikely // = 5
  case UNRECOGNIZED(Int)

  public init() {
    self = .unknown
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unknown
    case 1: self = .veryUnlikely
    case 2: self = .unlikely
    case 3: self = .possible
    case 4: self = .likely
    case 5: self = .veryLikely
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .unknown: return 0
    case .veryUnlikely: return 1
    case .unlikely: return 2
    case .possible: return 3
    case .likely: return 4
    case .veryLikely: return 5
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Google_Cloud_Vision_V1p1beta1_Likelihood: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Vision_V1p1beta1_Likelihood] = [
    .unknown,
    .veryUnlikely,
    .unlikely,
    .possible,
    .likely,
    .veryLikely,
  ]
}

#endif  // swift(>=4.2)

/// Users describe the type of Google Cloud Vision API tasks to perform over
/// images by using *Feature*s. Each Feature indicates a type of image
/// detection task to perform. Features encode the Cloud Vision API
/// vertical to operate on and the number of top-scoring results to return.
public struct Google_Cloud_Vision_V1p1beta1_Feature {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The feature type.
  public var type: Google_Cloud_Vision_V1p1beta1_Feature.TypeEnum = .unspecified

  /// Maximum number of results of this type.
  public var maxResults: Int32 = 0

  /// Model to use for the feature.
  /// Supported values: "builtin/stable" (the default if unset) and
  /// "builtin/latest".
  public var model: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Type of image feature.
  public enum TypeEnum: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Unspecified feature type.
    case unspecified // = 0

    /// Run face detection.
    case faceDetection // = 1

    /// Run landmark detection.
    case landmarkDetection // = 2

    /// Run logo detection.
    case logoDetection // = 3

    /// Run label detection.
    case labelDetection // = 4

    /// Run OCR.
    case textDetection // = 5

    /// Run dense text document OCR. Takes precedence when both
    /// DOCUMENT_TEXT_DETECTION and TEXT_DETECTION are present.
    case documentTextDetection // = 11

    /// Run computer vision models to compute image safe-search properties.
    case safeSearchDetection // = 6

    /// Compute a set of image properties, such as the image's dominant colors.
    case imageProperties // = 7

    /// Run crop hints.
    case cropHints // = 9

    /// Run web detection.
    case webDetection // = 10
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .faceDetection
      case 2: self = .landmarkDetection
      case 3: self = .logoDetection
      case 4: self = .labelDetection
      case 5: self = .textDetection
      case 6: self = .safeSearchDetection
      case 7: self = .imageProperties
      case 9: self = .cropHints
      case 10: self = .webDetection
      case 11: self = .documentTextDetection
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .faceDetection: return 1
      case .landmarkDetection: return 2
      case .logoDetection: return 3
      case .labelDetection: return 4
      case .textDetection: return 5
      case .safeSearchDetection: return 6
      case .imageProperties: return 7
      case .cropHints: return 9
      case .webDetection: return 10
      case .documentTextDetection: return 11
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}
}

#if swift(>=4.2)

extension Google_Cloud_Vision_V1p1beta1_Feature.TypeEnum: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Vision_V1p1beta1_Feature.TypeEnum] = [
    .unspecified,
    .faceDetection,
    .landmarkDetection,
    .logoDetection,
    .labelDetection,
    .textDetection,
    .documentTextDetection,
    .safeSearchDetection,
    .imageProperties,
    .cropHints,
    .webDetection,
  ]
}

#endif  // swift(>=4.2)

/// External image source (Google Cloud Storage image location).
public struct Google_Cloud_Vision_V1p1beta1_ImageSource {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// NOTE: For new code `image_uri` below is preferred.
  /// Google Cloud Storage image URI, which must be in the following form:
  /// `gs://bucket_name/object_name` (for details, see
  /// [Google Cloud Storage Request
  /// URIs](https://cloud.google.com/storage/docs/reference-uris)).
  /// NOTE: Cloud Storage object versioning is not supported.
  public var gcsImageUri: String = String()

  /// Image URI which supports:
  /// 1) Google Cloud Storage image URI, which must be in the following form:
  /// `gs://bucket_name/object_name` (for details, see
  /// [Google Cloud Storage Request
  /// URIs](https://cloud.google.com/storage/docs/reference-uris)).
  /// NOTE: Cloud Storage object versioning is not supported.
  /// 2) Publicly accessible image HTTP/HTTPS URL.
  /// This is preferred over the legacy `gcs_image_uri` above. When both
  /// `gcs_image_uri` and `image_uri` are specified, `image_uri` takes
  /// precedence.
  public var imageUri: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Client image to perform Google Cloud Vision API tasks over.
public struct Google_Cloud_Vision_V1p1beta1_Image {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Image content, represented as a stream of bytes.
  /// Note: as with all `bytes` fields, protobuffers use a pure binary
  /// representation, whereas JSON representations use base64.
  public var content: Data = Data()

  /// Google Cloud Storage image location. If both `content` and `source`
  /// are provided for an image, `content` takes precedence and is
  /// used to perform the image annotation request.
  public var source: Google_Cloud_Vision_V1p1beta1_ImageSource {
    get {return _source ?? Google_Cloud_Vision_V1p1beta1_ImageSource()}
    set {_source = newValue}
  }
  /// Returns true if `source` has been explicitly set.
  public var hasSource: Bool {return self._source != nil}
  /// Clears the value of `source`. Subsequent reads from it will return its default value.
  public mutating func clearSource() {self._source = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _source: Google_Cloud_Vision_V1p1beta1_ImageSource? = nil
}

/// A face annotation object contains the results of face detection.
public struct Google_Cloud_Vision_V1p1beta1_FaceAnnotation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The bounding polygon around the face. The coordinates of the bounding box
  /// are in the original image's scale, as returned in `ImageParams`.
  /// The bounding box is computed to "frame" the face in accordance with human
  /// expectations. It is based on the landmarker results.
  /// Note that one or more x and/or y coordinates may not be generated in the
  /// `BoundingPoly` (the polygon will be unbounded) if only a partial face
  /// appears in the image to be annotated.
  public var boundingPoly: Google_Cloud_Vision_V1p1beta1_BoundingPoly {
    get {return _boundingPoly ?? Google_Cloud_Vision_V1p1beta1_BoundingPoly()}
    set {_boundingPoly = newValue}
  }
  /// Returns true if `boundingPoly` has been explicitly set.
  public var hasBoundingPoly: Bool {return self._boundingPoly != nil}
  /// Clears the value of `boundingPoly`. Subsequent reads from it will return its default value.
  public mutating func clearBoundingPoly() {self._boundingPoly = nil}

  /// The `fd_bounding_poly` bounding polygon is tighter than the
  /// `boundingPoly`, and encloses only the skin part of the face. Typically, it
  /// is used to eliminate the face from any image analysis that detects the
  /// "amount of skin" visible in an image. It is not based on the
  /// landmarker results, only on the initial face detection, hence
  /// the <code>fd</code> (face detection) prefix.
  public var fdBoundingPoly: Google_Cloud_Vision_V1p1beta1_BoundingPoly {
    get {return _fdBoundingPoly ?? Google_Cloud_Vision_V1p1beta1_BoundingPoly()}
    set {_fdBoundingPoly = newValue}
  }
  /// Returns true if `fdBoundingPoly` has been explicitly set.
  public var hasFdBoundingPoly: Bool {return self._fdBoundingPoly != nil}
  /// Clears the value of `fdBoundingPoly`. Subsequent reads from it will return its default value.
  public mutating func clearFdBoundingPoly() {self._fdBoundingPoly = nil}

  /// Detected face landmarks.
  public var landmarks: [Google_Cloud_Vision_V1p1beta1_FaceAnnotation.Landmark] = []

  /// Roll angle, which indicates the amount of clockwise/anti-clockwise rotation
  /// of the face relative to the image vertical about the axis perpendicular to
  /// the face. Range [-180,180].
  public var rollAngle: Float = 0

  /// Yaw angle, which indicates the leftward/rightward angle that the face is
  /// pointing relative to the vertical plane perpendicular to the image. Range
  /// [-180,180].
  public var panAngle: Float = 0

  /// Pitch angle, which indicates the upwards/downwards angle that the face is
  /// pointing relative to the image's horizontal plane. Range [-180,180].
  public var tiltAngle: Float = 0

  /// Detection confidence. Range [0, 1].
  public var detectionConfidence: Float = 0

  /// Face landmarking confidence. Range [0, 1].
  public var landmarkingConfidence: Float = 0

  /// Joy likelihood.
  public var joyLikelihood: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  /// Sorrow likelihood.
  public var sorrowLikelihood: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  /// Anger likelihood.
  public var angerLikelihood: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  /// Surprise likelihood.
  public var surpriseLikelihood: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  /// Under-exposed likelihood.
  public var underExposedLikelihood: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  /// Blurred likelihood.
  public var blurredLikelihood: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  /// Headwear likelihood.
  public var headwearLikelihood: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// A face-specific landmark (for example, a face feature).
  public struct Landmark {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Face landmark type.
    public var type: Google_Cloud_Vision_V1p1beta1_FaceAnnotation.Landmark.TypeEnum = .unknownLandmark

    /// Face landmark position.
    public var position: Google_Cloud_Vision_V1p1beta1_Position {
      get {return _position ?? Google_Cloud_Vision_V1p1beta1_Position()}
      set {_position = newValue}
    }
    /// Returns true if `position` has been explicitly set.
    public var hasPosition: Bool {return self._position != nil}
    /// Clears the value of `position`. Subsequent reads from it will return its default value.
    public mutating func clearPosition() {self._position = nil}

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    /// Face landmark (feature) type.
    /// Left and right are defined from the vantage of the viewer of the image
    /// without considering mirror projections typical of photos. So, `LEFT_EYE`,
    /// typically, is the person's right eye.
    public enum TypeEnum: SwiftProtobuf.Enum {
      public typealias RawValue = Int

      /// Unknown face landmark detected. Should not be filled.
      case unknownLandmark // = 0

      /// Left eye.
      case leftEye // = 1

      /// Right eye.
      case rightEye // = 2

      /// Left of left eyebrow.
      case leftOfLeftEyebrow // = 3

      /// Right of left eyebrow.
      case rightOfLeftEyebrow // = 4

      /// Left of right eyebrow.
      case leftOfRightEyebrow // = 5

      /// Right of right eyebrow.
      case rightOfRightEyebrow // = 6

      /// Midpoint between eyes.
      case midpointBetweenEyes // = 7

      /// Nose tip.
      case noseTip // = 8

      /// Upper lip.
      case upperLip // = 9

      /// Lower lip.
      case lowerLip // = 10

      /// Mouth left.
      case mouthLeft // = 11

      /// Mouth right.
      case mouthRight // = 12

      /// Mouth center.
      case mouthCenter // = 13

      /// Nose, bottom right.
      case noseBottomRight // = 14

      /// Nose, bottom left.
      case noseBottomLeft // = 15

      /// Nose, bottom center.
      case noseBottomCenter // = 16

      /// Left eye, top boundary.
      case leftEyeTopBoundary // = 17

      /// Left eye, right corner.
      case leftEyeRightCorner // = 18

      /// Left eye, bottom boundary.
      case leftEyeBottomBoundary // = 19

      /// Left eye, left corner.
      case leftEyeLeftCorner // = 20

      /// Right eye, top boundary.
      case rightEyeTopBoundary // = 21

      /// Right eye, right corner.
      case rightEyeRightCorner // = 22

      /// Right eye, bottom boundary.
      case rightEyeBottomBoundary // = 23

      /// Right eye, left corner.
      case rightEyeLeftCorner // = 24

      /// Left eyebrow, upper midpoint.
      case leftEyebrowUpperMidpoint // = 25

      /// Right eyebrow, upper midpoint.
      case rightEyebrowUpperMidpoint // = 26

      /// Left ear tragion.
      case leftEarTragion // = 27

      /// Right ear tragion.
      case rightEarTragion // = 28

      /// Left eye pupil.
      case leftEyePupil // = 29

      /// Right eye pupil.
      case rightEyePupil // = 30

      /// Forehead glabella.
      case foreheadGlabella // = 31

      /// Chin gnathion.
      case chinGnathion // = 32

      /// Chin left gonion.
      case chinLeftGonion // = 33

      /// Chin right gonion.
      case chinRightGonion // = 34
      case UNRECOGNIZED(Int)

      public init() {
        self = .unknownLandmark
      }

      public init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unknownLandmark
        case 1: self = .leftEye
        case 2: self = .rightEye
        case 3: self = .leftOfLeftEyebrow
        case 4: self = .rightOfLeftEyebrow
        case 5: self = .leftOfRightEyebrow
        case 6: self = .rightOfRightEyebrow
        case 7: self = .midpointBetweenEyes
        case 8: self = .noseTip
        case 9: self = .upperLip
        case 10: self = .lowerLip
        case 11: self = .mouthLeft
        case 12: self = .mouthRight
        case 13: self = .mouthCenter
        case 14: self = .noseBottomRight
        case 15: self = .noseBottomLeft
        case 16: self = .noseBottomCenter
        case 17: self = .leftEyeTopBoundary
        case 18: self = .leftEyeRightCorner
        case 19: self = .leftEyeBottomBoundary
        case 20: self = .leftEyeLeftCorner
        case 21: self = .rightEyeTopBoundary
        case 22: self = .rightEyeRightCorner
        case 23: self = .rightEyeBottomBoundary
        case 24: self = .rightEyeLeftCorner
        case 25: self = .leftEyebrowUpperMidpoint
        case 26: self = .rightEyebrowUpperMidpoint
        case 27: self = .leftEarTragion
        case 28: self = .rightEarTragion
        case 29: self = .leftEyePupil
        case 30: self = .rightEyePupil
        case 31: self = .foreheadGlabella
        case 32: self = .chinGnathion
        case 33: self = .chinLeftGonion
        case 34: self = .chinRightGonion
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      public var rawValue: Int {
        switch self {
        case .unknownLandmark: return 0
        case .leftEye: return 1
        case .rightEye: return 2
        case .leftOfLeftEyebrow: return 3
        case .rightOfLeftEyebrow: return 4
        case .leftOfRightEyebrow: return 5
        case .rightOfRightEyebrow: return 6
        case .midpointBetweenEyes: return 7
        case .noseTip: return 8
        case .upperLip: return 9
        case .lowerLip: return 10
        case .mouthLeft: return 11
        case .mouthRight: return 12
        case .mouthCenter: return 13
        case .noseBottomRight: return 14
        case .noseBottomLeft: return 15
        case .noseBottomCenter: return 16
        case .leftEyeTopBoundary: return 17
        case .leftEyeRightCorner: return 18
        case .leftEyeBottomBoundary: return 19
        case .leftEyeLeftCorner: return 20
        case .rightEyeTopBoundary: return 21
        case .rightEyeRightCorner: return 22
        case .rightEyeBottomBoundary: return 23
        case .rightEyeLeftCorner: return 24
        case .leftEyebrowUpperMidpoint: return 25
        case .rightEyebrowUpperMidpoint: return 26
        case .leftEarTragion: return 27
        case .rightEarTragion: return 28
        case .leftEyePupil: return 29
        case .rightEyePupil: return 30
        case .foreheadGlabella: return 31
        case .chinGnathion: return 32
        case .chinLeftGonion: return 33
        case .chinRightGonion: return 34
        case .UNRECOGNIZED(let i): return i
        }
      }

    }

    public init() {}

    fileprivate var _position: Google_Cloud_Vision_V1p1beta1_Position? = nil
  }

  public init() {}

  fileprivate var _boundingPoly: Google_Cloud_Vision_V1p1beta1_BoundingPoly? = nil
  fileprivate var _fdBoundingPoly: Google_Cloud_Vision_V1p1beta1_BoundingPoly? = nil
}

#if swift(>=4.2)

extension Google_Cloud_Vision_V1p1beta1_FaceAnnotation.Landmark.TypeEnum: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Vision_V1p1beta1_FaceAnnotation.Landmark.TypeEnum] = [
    .unknownLandmark,
    .leftEye,
    .rightEye,
    .leftOfLeftEyebrow,
    .rightOfLeftEyebrow,
    .leftOfRightEyebrow,
    .rightOfRightEyebrow,
    .midpointBetweenEyes,
    .noseTip,
    .upperLip,
    .lowerLip,
    .mouthLeft,
    .mouthRight,
    .mouthCenter,
    .noseBottomRight,
    .noseBottomLeft,
    .noseBottomCenter,
    .leftEyeTopBoundary,
    .leftEyeRightCorner,
    .leftEyeBottomBoundary,
    .leftEyeLeftCorner,
    .rightEyeTopBoundary,
    .rightEyeRightCorner,
    .rightEyeBottomBoundary,
    .rightEyeLeftCorner,
    .leftEyebrowUpperMidpoint,
    .rightEyebrowUpperMidpoint,
    .leftEarTragion,
    .rightEarTragion,
    .leftEyePupil,
    .rightEyePupil,
    .foreheadGlabella,
    .chinGnathion,
    .chinLeftGonion,
    .chinRightGonion,
  ]
}

#endif  // swift(>=4.2)

/// Detected entity location information.
public struct Google_Cloud_Vision_V1p1beta1_LocationInfo {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// lat/long location coordinates.
  public var latLng: Google_Type_LatLng {
    get {return _latLng ?? Google_Type_LatLng()}
    set {_latLng = newValue}
  }
  /// Returns true if `latLng` has been explicitly set.
  public var hasLatLng: Bool {return self._latLng != nil}
  /// Clears the value of `latLng`. Subsequent reads from it will return its default value.
  public mutating func clearLatLng() {self._latLng = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _latLng: Google_Type_LatLng? = nil
}

/// A `Property` consists of a user-supplied name/value pair.
public struct Google_Cloud_Vision_V1p1beta1_Property {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Name of the property.
  public var name: String = String()

  /// Value of the property.
  public var value: String = String()

  /// Value of numeric properties.
  public var uint64Value: UInt64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Set of detected entity features.
public struct Google_Cloud_Vision_V1p1beta1_EntityAnnotation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Opaque entity ID. Some IDs may be available in
  /// [Google Knowledge Graph Search
  /// API](https://developers.google.com/knowledge-graph/).
  public var mid: String = String()

  /// The language code for the locale in which the entity textual
  /// `description` is expressed.
  public var locale: String = String()

  /// Entity textual description, expressed in its `locale` language.
  public var description_p: String = String()

  /// Overall score of the result. Range [0, 1].
  public var score: Float = 0

  /// The accuracy of the entity detection in an image.
  /// For example, for an image in which the "Eiffel Tower" entity is detected,
  /// this field represents the confidence that there is a tower in the query
  /// image. Range [0, 1].
  public var confidence: Float = 0

  /// The relevancy of the ICA (Image Content Annotation) label to the
  /// image. For example, the relevancy of "tower" is likely higher to an image
  /// containing the detected "Eiffel Tower" than to an image containing a
  /// detected distant towering building, even though the confidence that
  /// there is a tower in each image may be the same. Range [0, 1].
  public var topicality: Float = 0

  /// Image region to which this entity belongs. Not produced
  /// for `LABEL_DETECTION` features.
  public var boundingPoly: Google_Cloud_Vision_V1p1beta1_BoundingPoly {
    get {return _boundingPoly ?? Google_Cloud_Vision_V1p1beta1_BoundingPoly()}
    set {_boundingPoly = newValue}
  }
  /// Returns true if `boundingPoly` has been explicitly set.
  public var hasBoundingPoly: Bool {return self._boundingPoly != nil}
  /// Clears the value of `boundingPoly`. Subsequent reads from it will return its default value.
  public mutating func clearBoundingPoly() {self._boundingPoly = nil}

  /// The location information for the detected entity. Multiple
  /// `LocationInfo` elements can be present because one location may
  /// indicate the location of the scene in the image, and another location
  /// may indicate the location of the place where the image was taken.
  /// Location information is usually present for landmarks.
  public var locations: [Google_Cloud_Vision_V1p1beta1_LocationInfo] = []

  /// Some entities may have optional user-supplied `Property` (name/value)
  /// fields, such a score or string that qualifies the entity.
  public var properties: [Google_Cloud_Vision_V1p1beta1_Property] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _boundingPoly: Google_Cloud_Vision_V1p1beta1_BoundingPoly? = nil
}

/// Set of features pertaining to the image, computed by computer vision
/// methods over safe-search verticals (for example, adult, spoof, medical,
/// violence).
public struct Google_Cloud_Vision_V1p1beta1_SafeSearchAnnotation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Represents the adult content likelihood for the image. Adult content may
  /// contain elements such as nudity, pornographic images or cartoons, or
  /// sexual activities.
  public var adult: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  /// Spoof likelihood. The likelihood that an modification
  /// was made to the image's canonical version to make it appear
  /// funny or offensive.
  public var spoof: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  /// Likelihood that this is a medical image.
  public var medical: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  /// Likelihood that this image contains violent content.
  public var violence: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  /// Likelihood that the request image contains racy content. Racy content may
  /// include (but is not limited to) skimpy or sheer clothing, strategically
  /// covered nudity, lewd or provocative poses, or close-ups of sensitive
  /// body areas.
  public var racy: Google_Cloud_Vision_V1p1beta1_Likelihood = .unknown

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Rectangle determined by min and max `LatLng` pairs.
public struct Google_Cloud_Vision_V1p1beta1_LatLongRect {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Min lat/long pair.
  public var minLatLng: Google_Type_LatLng {
    get {return _minLatLng ?? Google_Type_LatLng()}
    set {_minLatLng = newValue}
  }
  /// Returns true if `minLatLng` has been explicitly set.
  public var hasMinLatLng: Bool {return self._minLatLng != nil}
  /// Clears the value of `minLatLng`. Subsequent reads from it will return its default value.
  public mutating func clearMinLatLng() {self._minLatLng = nil}

  /// Max lat/long pair.
  public var maxLatLng: Google_Type_LatLng {
    get {return _maxLatLng ?? Google_Type_LatLng()}
    set {_maxLatLng = newValue}
  }
  /// Returns true if `maxLatLng` has been explicitly set.
  public var hasMaxLatLng: Bool {return self._maxLatLng != nil}
  /// Clears the value of `maxLatLng`. Subsequent reads from it will return its default value.
  public mutating func clearMaxLatLng() {self._maxLatLng = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _minLatLng: Google_Type_LatLng? = nil
  fileprivate var _maxLatLng: Google_Type_LatLng? = nil
}

/// Color information consists of RGB channels, score, and the fraction of
/// the image that the color occupies in the image.
public struct Google_Cloud_Vision_V1p1beta1_ColorInfo {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// RGB components of the color.
  public var color: Google_Type_Color {
    get {return _color ?? Google_Type_Color()}
    set {_color = newValue}
  }
  /// Returns true if `color` has been explicitly set.
  public var hasColor: Bool {return self._color != nil}
  /// Clears the value of `color`. Subsequent reads from it will return its default value.
  public mutating func clearColor() {self._color = nil}

  /// Image-specific score for this color. Value in range [0, 1].
  public var score: Float = 0

  /// The fraction of pixels the color occupies in the image.
  /// Value in range [0, 1].
  public var pixelFraction: Float = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _color: Google_Type_Color? = nil
}

/// Set of dominant colors and their corresponding scores.
public struct Google_Cloud_Vision_V1p1beta1_DominantColorsAnnotation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// RGB color values with their score and pixel fraction.
  public var colors: [Google_Cloud_Vision_V1p1beta1_ColorInfo] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Stores image properties, such as dominant colors.
public struct Google_Cloud_Vision_V1p1beta1_ImageProperties {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// If present, dominant colors completed successfully.
  public var dominantColors: Google_Cloud_Vision_V1p1beta1_DominantColorsAnnotation {
    get {return _dominantColors ?? Google_Cloud_Vision_V1p1beta1_DominantColorsAnnotation()}
    set {_dominantColors = newValue}
  }
  /// Returns true if `dominantColors` has been explicitly set.
  public var hasDominantColors: Bool {return self._dominantColors != nil}
  /// Clears the value of `dominantColors`. Subsequent reads from it will return its default value.
  public mutating func clearDominantColors() {self._dominantColors = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _dominantColors: Google_Cloud_Vision_V1p1beta1_DominantColorsAnnotation? = nil
}

/// Single crop hint that is used to generate a new crop when serving an image.
public struct Google_Cloud_Vision_V1p1beta1_CropHint {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The bounding polygon for the crop region. The coordinates of the bounding
  /// box are in the original image's scale, as returned in `ImageParams`.
  public var boundingPoly: Google_Cloud_Vision_V1p1beta1_BoundingPoly {
    get {return _boundingPoly ?? Google_Cloud_Vision_V1p1beta1_BoundingPoly()}
    set {_boundingPoly = newValue}
  }
  /// Returns true if `boundingPoly` has been explicitly set.
  public var hasBoundingPoly: Bool {return self._boundingPoly != nil}
  /// Clears the value of `boundingPoly`. Subsequent reads from it will return its default value.
  public mutating func clearBoundingPoly() {self._boundingPoly = nil}

  /// Confidence of this being a salient region.  Range [0, 1].
  public var confidence: Float = 0

  /// Fraction of importance of this salient region with respect to the original
  /// image.
  public var importanceFraction: Float = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _boundingPoly: Google_Cloud_Vision_V1p1beta1_BoundingPoly? = nil
}

/// Set of crop hints that are used to generate new crops when serving images.
public struct Google_Cloud_Vision_V1p1beta1_CropHintsAnnotation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Crop hint results.
  public var cropHints: [Google_Cloud_Vision_V1p1beta1_CropHint] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Parameters for crop hints annotation request.
public struct Google_Cloud_Vision_V1p1beta1_CropHintsParams {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Aspect ratios in floats, representing the ratio of the width to the height
  /// of the image. For example, if the desired aspect ratio is 4/3, the
  /// corresponding float value should be 1.33333.  If not specified, the
  /// best possible crop is returned. The number of provided aspect ratios is
  /// limited to a maximum of 16; any aspect ratios provided after the 16th are
  /// ignored.
  public var aspectRatios: [Float] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Parameters for web detection request.
public struct Google_Cloud_Vision_V1p1beta1_WebDetectionParams {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Whether to include results derived from the geo information in the image.
  public var includeGeoResults: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Image context and/or feature-specific parameters.
public struct Google_Cloud_Vision_V1p1beta1_ImageContext {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// lat/long rectangle that specifies the location of the image.
  public var latLongRect: Google_Cloud_Vision_V1p1beta1_LatLongRect {
    get {return _latLongRect ?? Google_Cloud_Vision_V1p1beta1_LatLongRect()}
    set {_latLongRect = newValue}
  }
  /// Returns true if `latLongRect` has been explicitly set.
  public var hasLatLongRect: Bool {return self._latLongRect != nil}
  /// Clears the value of `latLongRect`. Subsequent reads from it will return its default value.
  public mutating func clearLatLongRect() {self._latLongRect = nil}

  /// List of languages to use for TEXT_DETECTION. In most cases, an empty value
  /// yields the best results since it enables automatic language detection. For
  /// languages based on the Latin alphabet, setting `language_hints` is not
  /// needed. In rare cases, when the language of the text in the image is known,
  /// setting a hint will help get better results (although it will be a
  /// significant hindrance if the hint is wrong). Text detection returns an
  /// error if one or more of the specified languages is not one of the
  /// [supported languages](https://cloud.google.com/vision/docs/languages).
  public var languageHints: [String] = []

  /// Parameters for crop hints annotation request.
  public var cropHintsParams: Google_Cloud_Vision_V1p1beta1_CropHintsParams {
    get {return _cropHintsParams ?? Google_Cloud_Vision_V1p1beta1_CropHintsParams()}
    set {_cropHintsParams = newValue}
  }
  /// Returns true if `cropHintsParams` has been explicitly set.
  public var hasCropHintsParams: Bool {return self._cropHintsParams != nil}
  /// Clears the value of `cropHintsParams`. Subsequent reads from it will return its default value.
  public mutating func clearCropHintsParams() {self._cropHintsParams = nil}

  /// Parameters for web detection.
  public var webDetectionParams: Google_Cloud_Vision_V1p1beta1_WebDetectionParams {
    get {return _webDetectionParams ?? Google_Cloud_Vision_V1p1beta1_WebDetectionParams()}
    set {_webDetectionParams = newValue}
  }
  /// Returns true if `webDetectionParams` has been explicitly set.
  public var hasWebDetectionParams: Bool {return self._webDetectionParams != nil}
  /// Clears the value of `webDetectionParams`. Subsequent reads from it will return its default value.
  public mutating func clearWebDetectionParams() {self._webDetectionParams = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _latLongRect: Google_Cloud_Vision_V1p1beta1_LatLongRect? = nil
  fileprivate var _cropHintsParams: Google_Cloud_Vision_V1p1beta1_CropHintsParams? = nil
  fileprivate var _webDetectionParams: Google_Cloud_Vision_V1p1beta1_WebDetectionParams? = nil
}

/// Request for performing Google Cloud Vision API tasks over a user-provided
/// image, with user-requested features.
public struct Google_Cloud_Vision_V1p1beta1_AnnotateImageRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The image to be processed.
  public var image: Google_Cloud_Vision_V1p1beta1_Image {
    get {return _image ?? Google_Cloud_Vision_V1p1beta1_Image()}
    set {_image = newValue}
  }
  /// Returns true if `image` has been explicitly set.
  public var hasImage: Bool {return self._image != nil}
  /// Clears the value of `image`. Subsequent reads from it will return its default value.
  public mutating func clearImage() {self._image = nil}

  /// Requested features.
  public var features: [Google_Cloud_Vision_V1p1beta1_Feature] = []

  /// Additional context that may accompany the image.
  public var imageContext: Google_Cloud_Vision_V1p1beta1_ImageContext {
    get {return _imageContext ?? Google_Cloud_Vision_V1p1beta1_ImageContext()}
    set {_imageContext = newValue}
  }
  /// Returns true if `imageContext` has been explicitly set.
  public var hasImageContext: Bool {return self._imageContext != nil}
  /// Clears the value of `imageContext`. Subsequent reads from it will return its default value.
  public mutating func clearImageContext() {self._imageContext = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _image: Google_Cloud_Vision_V1p1beta1_Image? = nil
  fileprivate var _imageContext: Google_Cloud_Vision_V1p1beta1_ImageContext? = nil
}

/// Response to an image annotation request.
public struct Google_Cloud_Vision_V1p1beta1_AnnotateImageResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// If present, face detection has completed successfully.
  public var faceAnnotations: [Google_Cloud_Vision_V1p1beta1_FaceAnnotation] {
    get {return _storage._faceAnnotations}
    set {_uniqueStorage()._faceAnnotations = newValue}
  }

  /// If present, landmark detection has completed successfully.
  public var landmarkAnnotations: [Google_Cloud_Vision_V1p1beta1_EntityAnnotation] {
    get {return _storage._landmarkAnnotations}
    set {_uniqueStorage()._landmarkAnnotations = newValue}
  }

  /// If present, logo detection has completed successfully.
  public var logoAnnotations: [Google_Cloud_Vision_V1p1beta1_EntityAnnotation] {
    get {return _storage._logoAnnotations}
    set {_uniqueStorage()._logoAnnotations = newValue}
  }

  /// If present, label detection has completed successfully.
  public var labelAnnotations: [Google_Cloud_Vision_V1p1beta1_EntityAnnotation] {
    get {return _storage._labelAnnotations}
    set {_uniqueStorage()._labelAnnotations = newValue}
  }

  /// If present, text (OCR) detection has completed successfully.
  public var textAnnotations: [Google_Cloud_Vision_V1p1beta1_EntityAnnotation] {
    get {return _storage._textAnnotations}
    set {_uniqueStorage()._textAnnotations = newValue}
  }

  /// If present, text (OCR) detection or document (OCR) text detection has
  /// completed successfully.
  /// This annotation provides the structural hierarchy for the OCR detected
  /// text.
  public var fullTextAnnotation: Google_Cloud_Vision_V1p1beta1_TextAnnotation {
    get {return _storage._fullTextAnnotation ?? Google_Cloud_Vision_V1p1beta1_TextAnnotation()}
    set {_uniqueStorage()._fullTextAnnotation = newValue}
  }
  /// Returns true if `fullTextAnnotation` has been explicitly set.
  public var hasFullTextAnnotation: Bool {return _storage._fullTextAnnotation != nil}
  /// Clears the value of `fullTextAnnotation`. Subsequent reads from it will return its default value.
  public mutating func clearFullTextAnnotation() {_uniqueStorage()._fullTextAnnotation = nil}

  /// If present, safe-search annotation has completed successfully.
  public var safeSearchAnnotation: Google_Cloud_Vision_V1p1beta1_SafeSearchAnnotation {
    get {return _storage._safeSearchAnnotation ?? Google_Cloud_Vision_V1p1beta1_SafeSearchAnnotation()}
    set {_uniqueStorage()._safeSearchAnnotation = newValue}
  }
  /// Returns true if `safeSearchAnnotation` has been explicitly set.
  public var hasSafeSearchAnnotation: Bool {return _storage._safeSearchAnnotation != nil}
  /// Clears the value of `safeSearchAnnotation`. Subsequent reads from it will return its default value.
  public mutating func clearSafeSearchAnnotation() {_uniqueStorage()._safeSearchAnnotation = nil}

  /// If present, image properties were extracted successfully.
  public var imagePropertiesAnnotation: Google_Cloud_Vision_V1p1beta1_ImageProperties {
    get {return _storage._imagePropertiesAnnotation ?? Google_Cloud_Vision_V1p1beta1_ImageProperties()}
    set {_uniqueStorage()._imagePropertiesAnnotation = newValue}
  }
  /// Returns true if `imagePropertiesAnnotation` has been explicitly set.
  public var hasImagePropertiesAnnotation: Bool {return _storage._imagePropertiesAnnotation != nil}
  /// Clears the value of `imagePropertiesAnnotation`. Subsequent reads from it will return its default value.
  public mutating func clearImagePropertiesAnnotation() {_uniqueStorage()._imagePropertiesAnnotation = nil}

  /// If present, crop hints have completed successfully.
  public var cropHintsAnnotation: Google_Cloud_Vision_V1p1beta1_CropHintsAnnotation {
    get {return _storage._cropHintsAnnotation ?? Google_Cloud_Vision_V1p1beta1_CropHintsAnnotation()}
    set {_uniqueStorage()._cropHintsAnnotation = newValue}
  }
  /// Returns true if `cropHintsAnnotation` has been explicitly set.
  public var hasCropHintsAnnotation: Bool {return _storage._cropHintsAnnotation != nil}
  /// Clears the value of `cropHintsAnnotation`. Subsequent reads from it will return its default value.
  public mutating func clearCropHintsAnnotation() {_uniqueStorage()._cropHintsAnnotation = nil}

  /// If present, web detection has completed successfully.
  public var webDetection: Google_Cloud_Vision_V1p1beta1_WebDetection {
    get {return _storage._webDetection ?? Google_Cloud_Vision_V1p1beta1_WebDetection()}
    set {_uniqueStorage()._webDetection = newValue}
  }
  /// Returns true if `webDetection` has been explicitly set.
  public var hasWebDetection: Bool {return _storage._webDetection != nil}
  /// Clears the value of `webDetection`. Subsequent reads from it will return its default value.
  public mutating func clearWebDetection() {_uniqueStorage()._webDetection = nil}

  /// If set, represents the error message for the operation.
  /// Note that filled-in image annotations are guaranteed to be
  /// correct, even when `error` is set.
  public var error: Google_Rpc_Status {
    get {return _storage._error ?? Google_Rpc_Status()}
    set {_uniqueStorage()._error = newValue}
  }
  /// Returns true if `error` has been explicitly set.
  public var hasError: Bool {return _storage._error != nil}
  /// Clears the value of `error`. Subsequent reads from it will return its default value.
  public mutating func clearError() {_uniqueStorage()._error = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Multiple image annotation requests are batched into a single service call.
public struct Google_Cloud_Vision_V1p1beta1_BatchAnnotateImagesRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Individual image annotation requests for this batch.
  public var requests: [Google_Cloud_Vision_V1p1beta1_AnnotateImageRequest] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response to a batch image annotation request.
public struct Google_Cloud_Vision_V1p1beta1_BatchAnnotateImagesResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Individual responses to image annotation requests within the batch.
  public var responses: [Google_Cloud_Vision_V1p1beta1_AnnotateImageResponse] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.vision.v1p1beta1"

extension Google_Cloud_Vision_V1p1beta1_Likelihood: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "UNKNOWN"),
    1: .same(proto: "VERY_UNLIKELY"),
    2: .same(proto: "UNLIKELY"),
    3: .same(proto: "POSSIBLE"),
    4: .same(proto: "LIKELY"),
    5: .same(proto: "VERY_LIKELY"),
  ]
}

extension Google_Cloud_Vision_V1p1beta1_Feature: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Feature"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "type"),
    2: .standard(proto: "max_results"),
    3: .same(proto: "model"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.type) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.maxResults) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.model) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.type != .unspecified {
      try visitor.visitSingularEnumField(value: self.type, fieldNumber: 1)
    }
    if self.maxResults != 0 {
      try visitor.visitSingularInt32Field(value: self.maxResults, fieldNumber: 2)
    }
    if !self.model.isEmpty {
      try visitor.visitSingularStringField(value: self.model, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_Feature, rhs: Google_Cloud_Vision_V1p1beta1_Feature) -> Bool {
    if lhs.type != rhs.type {return false}
    if lhs.maxResults != rhs.maxResults {return false}
    if lhs.model != rhs.model {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_Feature.TypeEnum: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TYPE_UNSPECIFIED"),
    1: .same(proto: "FACE_DETECTION"),
    2: .same(proto: "LANDMARK_DETECTION"),
    3: .same(proto: "LOGO_DETECTION"),
    4: .same(proto: "LABEL_DETECTION"),
    5: .same(proto: "TEXT_DETECTION"),
    6: .same(proto: "SAFE_SEARCH_DETECTION"),
    7: .same(proto: "IMAGE_PROPERTIES"),
    9: .same(proto: "CROP_HINTS"),
    10: .same(proto: "WEB_DETECTION"),
    11: .same(proto: "DOCUMENT_TEXT_DETECTION"),
  ]
}

extension Google_Cloud_Vision_V1p1beta1_ImageSource: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ImageSource"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "gcs_image_uri"),
    2: .standard(proto: "image_uri"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.gcsImageUri) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.imageUri) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.gcsImageUri.isEmpty {
      try visitor.visitSingularStringField(value: self.gcsImageUri, fieldNumber: 1)
    }
    if !self.imageUri.isEmpty {
      try visitor.visitSingularStringField(value: self.imageUri, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_ImageSource, rhs: Google_Cloud_Vision_V1p1beta1_ImageSource) -> Bool {
    if lhs.gcsImageUri != rhs.gcsImageUri {return false}
    if lhs.imageUri != rhs.imageUri {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_Image: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Image"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "content"),
    2: .same(proto: "source"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.content) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._source) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.content.isEmpty {
      try visitor.visitSingularBytesField(value: self.content, fieldNumber: 1)
    }
    if let v = self._source {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_Image, rhs: Google_Cloud_Vision_V1p1beta1_Image) -> Bool {
    if lhs.content != rhs.content {return false}
    if lhs._source != rhs._source {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_FaceAnnotation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FaceAnnotation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "bounding_poly"),
    2: .standard(proto: "fd_bounding_poly"),
    3: .same(proto: "landmarks"),
    4: .standard(proto: "roll_angle"),
    5: .standard(proto: "pan_angle"),
    6: .standard(proto: "tilt_angle"),
    7: .standard(proto: "detection_confidence"),
    8: .standard(proto: "landmarking_confidence"),
    9: .standard(proto: "joy_likelihood"),
    10: .standard(proto: "sorrow_likelihood"),
    11: .standard(proto: "anger_likelihood"),
    12: .standard(proto: "surprise_likelihood"),
    13: .standard(proto: "under_exposed_likelihood"),
    14: .standard(proto: "blurred_likelihood"),
    15: .standard(proto: "headwear_likelihood"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._boundingPoly) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._fdBoundingPoly) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.landmarks) }()
      case 4: try { try decoder.decodeSingularFloatField(value: &self.rollAngle) }()
      case 5: try { try decoder.decodeSingularFloatField(value: &self.panAngle) }()
      case 6: try { try decoder.decodeSingularFloatField(value: &self.tiltAngle) }()
      case 7: try { try decoder.decodeSingularFloatField(value: &self.detectionConfidence) }()
      case 8: try { try decoder.decodeSingularFloatField(value: &self.landmarkingConfidence) }()
      case 9: try { try decoder.decodeSingularEnumField(value: &self.joyLikelihood) }()
      case 10: try { try decoder.decodeSingularEnumField(value: &self.sorrowLikelihood) }()
      case 11: try { try decoder.decodeSingularEnumField(value: &self.angerLikelihood) }()
      case 12: try { try decoder.decodeSingularEnumField(value: &self.surpriseLikelihood) }()
      case 13: try { try decoder.decodeSingularEnumField(value: &self.underExposedLikelihood) }()
      case 14: try { try decoder.decodeSingularEnumField(value: &self.blurredLikelihood) }()
      case 15: try { try decoder.decodeSingularEnumField(value: &self.headwearLikelihood) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._boundingPoly {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._fdBoundingPoly {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if !self.landmarks.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.landmarks, fieldNumber: 3)
    }
    if self.rollAngle != 0 {
      try visitor.visitSingularFloatField(value: self.rollAngle, fieldNumber: 4)
    }
    if self.panAngle != 0 {
      try visitor.visitSingularFloatField(value: self.panAngle, fieldNumber: 5)
    }
    if self.tiltAngle != 0 {
      try visitor.visitSingularFloatField(value: self.tiltAngle, fieldNumber: 6)
    }
    if self.detectionConfidence != 0 {
      try visitor.visitSingularFloatField(value: self.detectionConfidence, fieldNumber: 7)
    }
    if self.landmarkingConfidence != 0 {
      try visitor.visitSingularFloatField(value: self.landmarkingConfidence, fieldNumber: 8)
    }
    if self.joyLikelihood != .unknown {
      try visitor.visitSingularEnumField(value: self.joyLikelihood, fieldNumber: 9)
    }
    if self.sorrowLikelihood != .unknown {
      try visitor.visitSingularEnumField(value: self.sorrowLikelihood, fieldNumber: 10)
    }
    if self.angerLikelihood != .unknown {
      try visitor.visitSingularEnumField(value: self.angerLikelihood, fieldNumber: 11)
    }
    if self.surpriseLikelihood != .unknown {
      try visitor.visitSingularEnumField(value: self.surpriseLikelihood, fieldNumber: 12)
    }
    if self.underExposedLikelihood != .unknown {
      try visitor.visitSingularEnumField(value: self.underExposedLikelihood, fieldNumber: 13)
    }
    if self.blurredLikelihood != .unknown {
      try visitor.visitSingularEnumField(value: self.blurredLikelihood, fieldNumber: 14)
    }
    if self.headwearLikelihood != .unknown {
      try visitor.visitSingularEnumField(value: self.headwearLikelihood, fieldNumber: 15)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_FaceAnnotation, rhs: Google_Cloud_Vision_V1p1beta1_FaceAnnotation) -> Bool {
    if lhs._boundingPoly != rhs._boundingPoly {return false}
    if lhs._fdBoundingPoly != rhs._fdBoundingPoly {return false}
    if lhs.landmarks != rhs.landmarks {return false}
    if lhs.rollAngle != rhs.rollAngle {return false}
    if lhs.panAngle != rhs.panAngle {return false}
    if lhs.tiltAngle != rhs.tiltAngle {return false}
    if lhs.detectionConfidence != rhs.detectionConfidence {return false}
    if lhs.landmarkingConfidence != rhs.landmarkingConfidence {return false}
    if lhs.joyLikelihood != rhs.joyLikelihood {return false}
    if lhs.sorrowLikelihood != rhs.sorrowLikelihood {return false}
    if lhs.angerLikelihood != rhs.angerLikelihood {return false}
    if lhs.surpriseLikelihood != rhs.surpriseLikelihood {return false}
    if lhs.underExposedLikelihood != rhs.underExposedLikelihood {return false}
    if lhs.blurredLikelihood != rhs.blurredLikelihood {return false}
    if lhs.headwearLikelihood != rhs.headwearLikelihood {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_FaceAnnotation.Landmark: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Vision_V1p1beta1_FaceAnnotation.protoMessageName + ".Landmark"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    3: .same(proto: "type"),
    4: .same(proto: "position"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 3: try { try decoder.decodeSingularEnumField(value: &self.type) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._position) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.type != .unknownLandmark {
      try visitor.visitSingularEnumField(value: self.type, fieldNumber: 3)
    }
    if let v = self._position {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_FaceAnnotation.Landmark, rhs: Google_Cloud_Vision_V1p1beta1_FaceAnnotation.Landmark) -> Bool {
    if lhs.type != rhs.type {return false}
    if lhs._position != rhs._position {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_FaceAnnotation.Landmark.TypeEnum: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "UNKNOWN_LANDMARK"),
    1: .same(proto: "LEFT_EYE"),
    2: .same(proto: "RIGHT_EYE"),
    3: .same(proto: "LEFT_OF_LEFT_EYEBROW"),
    4: .same(proto: "RIGHT_OF_LEFT_EYEBROW"),
    5: .same(proto: "LEFT_OF_RIGHT_EYEBROW"),
    6: .same(proto: "RIGHT_OF_RIGHT_EYEBROW"),
    7: .same(proto: "MIDPOINT_BETWEEN_EYES"),
    8: .same(proto: "NOSE_TIP"),
    9: .same(proto: "UPPER_LIP"),
    10: .same(proto: "LOWER_LIP"),
    11: .same(proto: "MOUTH_LEFT"),
    12: .same(proto: "MOUTH_RIGHT"),
    13: .same(proto: "MOUTH_CENTER"),
    14: .same(proto: "NOSE_BOTTOM_RIGHT"),
    15: .same(proto: "NOSE_BOTTOM_LEFT"),
    16: .same(proto: "NOSE_BOTTOM_CENTER"),
    17: .same(proto: "LEFT_EYE_TOP_BOUNDARY"),
    18: .same(proto: "LEFT_EYE_RIGHT_CORNER"),
    19: .same(proto: "LEFT_EYE_BOTTOM_BOUNDARY"),
    20: .same(proto: "LEFT_EYE_LEFT_CORNER"),
    21: .same(proto: "RIGHT_EYE_TOP_BOUNDARY"),
    22: .same(proto: "RIGHT_EYE_RIGHT_CORNER"),
    23: .same(proto: "RIGHT_EYE_BOTTOM_BOUNDARY"),
    24: .same(proto: "RIGHT_EYE_LEFT_CORNER"),
    25: .same(proto: "LEFT_EYEBROW_UPPER_MIDPOINT"),
    26: .same(proto: "RIGHT_EYEBROW_UPPER_MIDPOINT"),
    27: .same(proto: "LEFT_EAR_TRAGION"),
    28: .same(proto: "RIGHT_EAR_TRAGION"),
    29: .same(proto: "LEFT_EYE_PUPIL"),
    30: .same(proto: "RIGHT_EYE_PUPIL"),
    31: .same(proto: "FOREHEAD_GLABELLA"),
    32: .same(proto: "CHIN_GNATHION"),
    33: .same(proto: "CHIN_LEFT_GONION"),
    34: .same(proto: "CHIN_RIGHT_GONION"),
  ]
}

extension Google_Cloud_Vision_V1p1beta1_LocationInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".LocationInfo"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "lat_lng"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._latLng) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._latLng {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_LocationInfo, rhs: Google_Cloud_Vision_V1p1beta1_LocationInfo) -> Bool {
    if lhs._latLng != rhs._latLng {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_Property: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Property"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "value"),
    3: .standard(proto: "uint64_value"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.value) }()
      case 3: try { try decoder.decodeSingularUInt64Field(value: &self.uint64Value) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if !self.value.isEmpty {
      try visitor.visitSingularStringField(value: self.value, fieldNumber: 2)
    }
    if self.uint64Value != 0 {
      try visitor.visitSingularUInt64Field(value: self.uint64Value, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_Property, rhs: Google_Cloud_Vision_V1p1beta1_Property) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.value != rhs.value {return false}
    if lhs.uint64Value != rhs.uint64Value {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_EntityAnnotation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".EntityAnnotation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "mid"),
    2: .same(proto: "locale"),
    3: .same(proto: "description"),
    4: .same(proto: "score"),
    5: .same(proto: "confidence"),
    6: .same(proto: "topicality"),
    7: .standard(proto: "bounding_poly"),
    8: .same(proto: "locations"),
    9: .same(proto: "properties"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.mid) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.locale) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.description_p) }()
      case 4: try { try decoder.decodeSingularFloatField(value: &self.score) }()
      case 5: try { try decoder.decodeSingularFloatField(value: &self.confidence) }()
      case 6: try { try decoder.decodeSingularFloatField(value: &self.topicality) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._boundingPoly) }()
      case 8: try { try decoder.decodeRepeatedMessageField(value: &self.locations) }()
      case 9: try { try decoder.decodeRepeatedMessageField(value: &self.properties) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.mid.isEmpty {
      try visitor.visitSingularStringField(value: self.mid, fieldNumber: 1)
    }
    if !self.locale.isEmpty {
      try visitor.visitSingularStringField(value: self.locale, fieldNumber: 2)
    }
    if !self.description_p.isEmpty {
      try visitor.visitSingularStringField(value: self.description_p, fieldNumber: 3)
    }
    if self.score != 0 {
      try visitor.visitSingularFloatField(value: self.score, fieldNumber: 4)
    }
    if self.confidence != 0 {
      try visitor.visitSingularFloatField(value: self.confidence, fieldNumber: 5)
    }
    if self.topicality != 0 {
      try visitor.visitSingularFloatField(value: self.topicality, fieldNumber: 6)
    }
    if let v = self._boundingPoly {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }
    if !self.locations.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.locations, fieldNumber: 8)
    }
    if !self.properties.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.properties, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_EntityAnnotation, rhs: Google_Cloud_Vision_V1p1beta1_EntityAnnotation) -> Bool {
    if lhs.mid != rhs.mid {return false}
    if lhs.locale != rhs.locale {return false}
    if lhs.description_p != rhs.description_p {return false}
    if lhs.score != rhs.score {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.topicality != rhs.topicality {return false}
    if lhs._boundingPoly != rhs._boundingPoly {return false}
    if lhs.locations != rhs.locations {return false}
    if lhs.properties != rhs.properties {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_SafeSearchAnnotation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SafeSearchAnnotation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "adult"),
    2: .same(proto: "spoof"),
    3: .same(proto: "medical"),
    4: .same(proto: "violence"),
    9: .same(proto: "racy"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.adult) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.spoof) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.medical) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.violence) }()
      case 9: try { try decoder.decodeSingularEnumField(value: &self.racy) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.adult != .unknown {
      try visitor.visitSingularEnumField(value: self.adult, fieldNumber: 1)
    }
    if self.spoof != .unknown {
      try visitor.visitSingularEnumField(value: self.spoof, fieldNumber: 2)
    }
    if self.medical != .unknown {
      try visitor.visitSingularEnumField(value: self.medical, fieldNumber: 3)
    }
    if self.violence != .unknown {
      try visitor.visitSingularEnumField(value: self.violence, fieldNumber: 4)
    }
    if self.racy != .unknown {
      try visitor.visitSingularEnumField(value: self.racy, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_SafeSearchAnnotation, rhs: Google_Cloud_Vision_V1p1beta1_SafeSearchAnnotation) -> Bool {
    if lhs.adult != rhs.adult {return false}
    if lhs.spoof != rhs.spoof {return false}
    if lhs.medical != rhs.medical {return false}
    if lhs.violence != rhs.violence {return false}
    if lhs.racy != rhs.racy {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_LatLongRect: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".LatLongRect"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "min_lat_lng"),
    2: .standard(proto: "max_lat_lng"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._minLatLng) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._maxLatLng) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._minLatLng {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._maxLatLng {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_LatLongRect, rhs: Google_Cloud_Vision_V1p1beta1_LatLongRect) -> Bool {
    if lhs._minLatLng != rhs._minLatLng {return false}
    if lhs._maxLatLng != rhs._maxLatLng {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_ColorInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ColorInfo"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "color"),
    2: .same(proto: "score"),
    3: .standard(proto: "pixel_fraction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._color) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.score) }()
      case 3: try { try decoder.decodeSingularFloatField(value: &self.pixelFraction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._color {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if self.score != 0 {
      try visitor.visitSingularFloatField(value: self.score, fieldNumber: 2)
    }
    if self.pixelFraction != 0 {
      try visitor.visitSingularFloatField(value: self.pixelFraction, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_ColorInfo, rhs: Google_Cloud_Vision_V1p1beta1_ColorInfo) -> Bool {
    if lhs._color != rhs._color {return false}
    if lhs.score != rhs.score {return false}
    if lhs.pixelFraction != rhs.pixelFraction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_DominantColorsAnnotation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DominantColorsAnnotation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "colors"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.colors) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.colors.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.colors, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_DominantColorsAnnotation, rhs: Google_Cloud_Vision_V1p1beta1_DominantColorsAnnotation) -> Bool {
    if lhs.colors != rhs.colors {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_ImageProperties: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ImageProperties"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "dominant_colors"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._dominantColors) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._dominantColors {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_ImageProperties, rhs: Google_Cloud_Vision_V1p1beta1_ImageProperties) -> Bool {
    if lhs._dominantColors != rhs._dominantColors {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_CropHint: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CropHint"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "bounding_poly"),
    2: .same(proto: "confidence"),
    3: .standard(proto: "importance_fraction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._boundingPoly) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.confidence) }()
      case 3: try { try decoder.decodeSingularFloatField(value: &self.importanceFraction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._boundingPoly {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if self.confidence != 0 {
      try visitor.visitSingularFloatField(value: self.confidence, fieldNumber: 2)
    }
    if self.importanceFraction != 0 {
      try visitor.visitSingularFloatField(value: self.importanceFraction, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_CropHint, rhs: Google_Cloud_Vision_V1p1beta1_CropHint) -> Bool {
    if lhs._boundingPoly != rhs._boundingPoly {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.importanceFraction != rhs.importanceFraction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_CropHintsAnnotation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CropHintsAnnotation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "crop_hints"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.cropHints) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.cropHints.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.cropHints, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_CropHintsAnnotation, rhs: Google_Cloud_Vision_V1p1beta1_CropHintsAnnotation) -> Bool {
    if lhs.cropHints != rhs.cropHints {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_CropHintsParams: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CropHintsParams"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "aspect_ratios"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedFloatField(value: &self.aspectRatios) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.aspectRatios.isEmpty {
      try visitor.visitPackedFloatField(value: self.aspectRatios, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_CropHintsParams, rhs: Google_Cloud_Vision_V1p1beta1_CropHintsParams) -> Bool {
    if lhs.aspectRatios != rhs.aspectRatios {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_WebDetectionParams: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".WebDetectionParams"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .standard(proto: "include_geo_results"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularBoolField(value: &self.includeGeoResults) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.includeGeoResults != false {
      try visitor.visitSingularBoolField(value: self.includeGeoResults, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_WebDetectionParams, rhs: Google_Cloud_Vision_V1p1beta1_WebDetectionParams) -> Bool {
    if lhs.includeGeoResults != rhs.includeGeoResults {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_ImageContext: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ImageContext"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "lat_long_rect"),
    2: .standard(proto: "language_hints"),
    4: .standard(proto: "crop_hints_params"),
    6: .standard(proto: "web_detection_params"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._latLongRect) }()
      case 2: try { try decoder.decodeRepeatedStringField(value: &self.languageHints) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._cropHintsParams) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._webDetectionParams) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._latLongRect {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.languageHints.isEmpty {
      try visitor.visitRepeatedStringField(value: self.languageHints, fieldNumber: 2)
    }
    if let v = self._cropHintsParams {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    if let v = self._webDetectionParams {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_ImageContext, rhs: Google_Cloud_Vision_V1p1beta1_ImageContext) -> Bool {
    if lhs._latLongRect != rhs._latLongRect {return false}
    if lhs.languageHints != rhs.languageHints {return false}
    if lhs._cropHintsParams != rhs._cropHintsParams {return false}
    if lhs._webDetectionParams != rhs._webDetectionParams {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_AnnotateImageRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AnnotateImageRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "image"),
    2: .same(proto: "features"),
    3: .standard(proto: "image_context"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._image) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.features) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._imageContext) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._image {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.features.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.features, fieldNumber: 2)
    }
    if let v = self._imageContext {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_AnnotateImageRequest, rhs: Google_Cloud_Vision_V1p1beta1_AnnotateImageRequest) -> Bool {
    if lhs._image != rhs._image {return false}
    if lhs.features != rhs.features {return false}
    if lhs._imageContext != rhs._imageContext {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_AnnotateImageResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AnnotateImageResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "face_annotations"),
    2: .standard(proto: "landmark_annotations"),
    3: .standard(proto: "logo_annotations"),
    4: .standard(proto: "label_annotations"),
    5: .standard(proto: "text_annotations"),
    12: .standard(proto: "full_text_annotation"),
    6: .standard(proto: "safe_search_annotation"),
    8: .standard(proto: "image_properties_annotation"),
    11: .standard(proto: "crop_hints_annotation"),
    13: .standard(proto: "web_detection"),
    9: .same(proto: "error"),
  ]

  fileprivate class _StorageClass {
    var _faceAnnotations: [Google_Cloud_Vision_V1p1beta1_FaceAnnotation] = []
    var _landmarkAnnotations: [Google_Cloud_Vision_V1p1beta1_EntityAnnotation] = []
    var _logoAnnotations: [Google_Cloud_Vision_V1p1beta1_EntityAnnotation] = []
    var _labelAnnotations: [Google_Cloud_Vision_V1p1beta1_EntityAnnotation] = []
    var _textAnnotations: [Google_Cloud_Vision_V1p1beta1_EntityAnnotation] = []
    var _fullTextAnnotation: Google_Cloud_Vision_V1p1beta1_TextAnnotation? = nil
    var _safeSearchAnnotation: Google_Cloud_Vision_V1p1beta1_SafeSearchAnnotation? = nil
    var _imagePropertiesAnnotation: Google_Cloud_Vision_V1p1beta1_ImageProperties? = nil
    var _cropHintsAnnotation: Google_Cloud_Vision_V1p1beta1_CropHintsAnnotation? = nil
    var _webDetection: Google_Cloud_Vision_V1p1beta1_WebDetection? = nil
    var _error: Google_Rpc_Status? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _faceAnnotations = source._faceAnnotations
      _landmarkAnnotations = source._landmarkAnnotations
      _logoAnnotations = source._logoAnnotations
      _labelAnnotations = source._labelAnnotations
      _textAnnotations = source._textAnnotations
      _fullTextAnnotation = source._fullTextAnnotation
      _safeSearchAnnotation = source._safeSearchAnnotation
      _imagePropertiesAnnotation = source._imagePropertiesAnnotation
      _cropHintsAnnotation = source._cropHintsAnnotation
      _webDetection = source._webDetection
      _error = source._error
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeRepeatedMessageField(value: &_storage._faceAnnotations) }()
        case 2: try { try decoder.decodeRepeatedMessageField(value: &_storage._landmarkAnnotations) }()
        case 3: try { try decoder.decodeRepeatedMessageField(value: &_storage._logoAnnotations) }()
        case 4: try { try decoder.decodeRepeatedMessageField(value: &_storage._labelAnnotations) }()
        case 5: try { try decoder.decodeRepeatedMessageField(value: &_storage._textAnnotations) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._safeSearchAnnotation) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._imagePropertiesAnnotation) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._error) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._cropHintsAnnotation) }()
        case 12: try { try decoder.decodeSingularMessageField(value: &_storage._fullTextAnnotation) }()
        case 13: try { try decoder.decodeSingularMessageField(value: &_storage._webDetection) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._faceAnnotations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._faceAnnotations, fieldNumber: 1)
      }
      if !_storage._landmarkAnnotations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._landmarkAnnotations, fieldNumber: 2)
      }
      if !_storage._logoAnnotations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._logoAnnotations, fieldNumber: 3)
      }
      if !_storage._labelAnnotations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._labelAnnotations, fieldNumber: 4)
      }
      if !_storage._textAnnotations.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._textAnnotations, fieldNumber: 5)
      }
      if let v = _storage._safeSearchAnnotation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      }
      if let v = _storage._imagePropertiesAnnotation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      }
      if let v = _storage._error {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      }
      if let v = _storage._cropHintsAnnotation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      }
      if let v = _storage._fullTextAnnotation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      }
      if let v = _storage._webDetection {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_AnnotateImageResponse, rhs: Google_Cloud_Vision_V1p1beta1_AnnotateImageResponse) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._faceAnnotations != rhs_storage._faceAnnotations {return false}
        if _storage._landmarkAnnotations != rhs_storage._landmarkAnnotations {return false}
        if _storage._logoAnnotations != rhs_storage._logoAnnotations {return false}
        if _storage._labelAnnotations != rhs_storage._labelAnnotations {return false}
        if _storage._textAnnotations != rhs_storage._textAnnotations {return false}
        if _storage._fullTextAnnotation != rhs_storage._fullTextAnnotation {return false}
        if _storage._safeSearchAnnotation != rhs_storage._safeSearchAnnotation {return false}
        if _storage._imagePropertiesAnnotation != rhs_storage._imagePropertiesAnnotation {return false}
        if _storage._cropHintsAnnotation != rhs_storage._cropHintsAnnotation {return false}
        if _storage._webDetection != rhs_storage._webDetection {return false}
        if _storage._error != rhs_storage._error {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_BatchAnnotateImagesRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchAnnotateImagesRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "requests"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.requests) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.requests.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.requests, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_BatchAnnotateImagesRequest, rhs: Google_Cloud_Vision_V1p1beta1_BatchAnnotateImagesRequest) -> Bool {
    if lhs.requests != rhs.requests {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Vision_V1p1beta1_BatchAnnotateImagesResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchAnnotateImagesResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "responses"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.responses) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.responses.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.responses, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Vision_V1p1beta1_BatchAnnotateImagesResponse, rhs: Google_Cloud_Vision_V1p1beta1_BatchAnnotateImagesResponse) -> Bool {
    if lhs.responses != rhs.responses {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
