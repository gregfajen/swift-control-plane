// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/dataproc/v1beta2/autoscaling_policies.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Describes an autoscaling policy for Dataproc cluster autoscaler.
public struct Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The policy id.
  ///
  /// The id must contain only letters (a-z, A-Z), numbers (0-9),
  /// underscores (_), and hyphens (-). Cannot begin or end with underscore
  /// or hyphen. Must consist of between 3 and 50 characters.
  public var id: String = String()

  /// Output only. The "resource name" of the autoscaling policy, as described
  /// in https://cloud.google.com/apis/design/resource_names.
  ///
  /// * For `projects.regions.autoscalingPolicies`, the resource name of the
  ///   policy has the following format:
  ///   `projects/{project_id}/regions/{region}/autoscalingPolicies/{policy_id}`
  ///
  /// * For `projects.locations.autoscalingPolicies`, the resource name of the
  ///   policy has the following format:
  ///   `projects/{project_id}/locations/{location}/autoscalingPolicies/{policy_id}`
  public var name: String = String()

  /// Required. Autoscaling algorithm for policy.
  public var algorithm: Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy.OneOf_Algorithm? = nil

  public var basicAlgorithm: Google_Cloud_Dataproc_V1beta2_BasicAutoscalingAlgorithm {
    get {
      if case .basicAlgorithm(let v)? = algorithm {return v}
      return Google_Cloud_Dataproc_V1beta2_BasicAutoscalingAlgorithm()
    }
    set {algorithm = .basicAlgorithm(newValue)}
  }

  /// Required. Describes how the autoscaler will operate for primary workers.
  public var workerConfig: Google_Cloud_Dataproc_V1beta2_InstanceGroupAutoscalingPolicyConfig {
    get {return _workerConfig ?? Google_Cloud_Dataproc_V1beta2_InstanceGroupAutoscalingPolicyConfig()}
    set {_workerConfig = newValue}
  }
  /// Returns true if `workerConfig` has been explicitly set.
  public var hasWorkerConfig: Bool {return self._workerConfig != nil}
  /// Clears the value of `workerConfig`. Subsequent reads from it will return its default value.
  public mutating func clearWorkerConfig() {self._workerConfig = nil}

  /// Optional. Describes how the autoscaler will operate for secondary workers.
  public var secondaryWorkerConfig: Google_Cloud_Dataproc_V1beta2_InstanceGroupAutoscalingPolicyConfig {
    get {return _secondaryWorkerConfig ?? Google_Cloud_Dataproc_V1beta2_InstanceGroupAutoscalingPolicyConfig()}
    set {_secondaryWorkerConfig = newValue}
  }
  /// Returns true if `secondaryWorkerConfig` has been explicitly set.
  public var hasSecondaryWorkerConfig: Bool {return self._secondaryWorkerConfig != nil}
  /// Clears the value of `secondaryWorkerConfig`. Subsequent reads from it will return its default value.
  public mutating func clearSecondaryWorkerConfig() {self._secondaryWorkerConfig = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Required. Autoscaling algorithm for policy.
  public enum OneOf_Algorithm: Equatable {
    case basicAlgorithm(Google_Cloud_Dataproc_V1beta2_BasicAutoscalingAlgorithm)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy.OneOf_Algorithm, rhs: Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy.OneOf_Algorithm) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.basicAlgorithm, .basicAlgorithm): return {
        guard case .basicAlgorithm(let l) = lhs, case .basicAlgorithm(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _workerConfig: Google_Cloud_Dataproc_V1beta2_InstanceGroupAutoscalingPolicyConfig? = nil
  fileprivate var _secondaryWorkerConfig: Google_Cloud_Dataproc_V1beta2_InstanceGroupAutoscalingPolicyConfig? = nil
}

/// Basic algorithm for autoscaling.
public struct Google_Cloud_Dataproc_V1beta2_BasicAutoscalingAlgorithm {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. YARN autoscaling configuration.
  public var yarnConfig: Google_Cloud_Dataproc_V1beta2_BasicYarnAutoscalingConfig {
    get {return _yarnConfig ?? Google_Cloud_Dataproc_V1beta2_BasicYarnAutoscalingConfig()}
    set {_yarnConfig = newValue}
  }
  /// Returns true if `yarnConfig` has been explicitly set.
  public var hasYarnConfig: Bool {return self._yarnConfig != nil}
  /// Clears the value of `yarnConfig`. Subsequent reads from it will return its default value.
  public mutating func clearYarnConfig() {self._yarnConfig = nil}

  /// Optional. Duration between scaling events. A scaling period starts after
  /// the update operation from the previous event has completed.
  ///
  /// Bounds: [2m, 1d]. Default: 2m.
  public var cooldownPeriod: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _cooldownPeriod ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_cooldownPeriod = newValue}
  }
  /// Returns true if `cooldownPeriod` has been explicitly set.
  public var hasCooldownPeriod: Bool {return self._cooldownPeriod != nil}
  /// Clears the value of `cooldownPeriod`. Subsequent reads from it will return its default value.
  public mutating func clearCooldownPeriod() {self._cooldownPeriod = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _yarnConfig: Google_Cloud_Dataproc_V1beta2_BasicYarnAutoscalingConfig? = nil
  fileprivate var _cooldownPeriod: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

/// Basic autoscaling configurations for YARN.
public struct Google_Cloud_Dataproc_V1beta2_BasicYarnAutoscalingConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Timeout for YARN graceful decommissioning of Node Managers.
  /// Specifies the duration to wait for jobs to complete before forcefully
  /// removing workers (and potentially interrupting jobs). Only applicable to
  /// downscaling operations.
  ///
  /// Bounds: [0s, 1d].
  public var gracefulDecommissionTimeout: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _gracefulDecommissionTimeout ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_gracefulDecommissionTimeout = newValue}
  }
  /// Returns true if `gracefulDecommissionTimeout` has been explicitly set.
  public var hasGracefulDecommissionTimeout: Bool {return self._gracefulDecommissionTimeout != nil}
  /// Clears the value of `gracefulDecommissionTimeout`. Subsequent reads from it will return its default value.
  public mutating func clearGracefulDecommissionTimeout() {self._gracefulDecommissionTimeout = nil}

  /// Required. Fraction of average pending memory in the last cooldown period
  /// for which to add workers. A scale-up factor of 1.0 will result in scaling
  /// up so that there is no pending memory remaining after the update (more
  /// aggressive scaling). A scale-up factor closer to 0 will result in a smaller
  /// magnitude of scaling up (less aggressive scaling).
  ///
  /// Bounds: [0.0, 1.0].
  public var scaleUpFactor: Double = 0

  /// Required. Fraction of average pending memory in the last cooldown period
  /// for which to remove workers. A scale-down factor of 1 will result in
  /// scaling down so that there is no available memory remaining after the
  /// update (more aggressive scaling). A scale-down factor of 0 disables
  /// removing workers, which can be beneficial for autoscaling a single job.
  ///
  /// Bounds: [0.0, 1.0].
  public var scaleDownFactor: Double = 0

  /// Optional. Minimum scale-up threshold as a fraction of total cluster size
  /// before scaling occurs. For example, in a 20-worker cluster, a threshold of
  /// 0.1 means the autoscaler must recommend at least a 2-worker scale-up for
  /// the cluster to scale. A threshold of 0 means the autoscaler will scale up
  /// on any recommended change.
  ///
  /// Bounds: [0.0, 1.0]. Default: 0.0.
  public var scaleUpMinWorkerFraction: Double = 0

  /// Optional. Minimum scale-down threshold as a fraction of total cluster size
  /// before scaling occurs. For example, in a 20-worker cluster, a threshold of
  /// 0.1 means the autoscaler must recommend at least a 2 worker scale-down for
  /// the cluster to scale. A threshold of 0 means the autoscaler will scale down
  /// on any recommended change.
  ///
  /// Bounds: [0.0, 1.0]. Default: 0.0.
  public var scaleDownMinWorkerFraction: Double = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _gracefulDecommissionTimeout: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

/// Configuration for the size bounds of an instance group, including its
/// proportional size to other groups.
public struct Google_Cloud_Dataproc_V1beta2_InstanceGroupAutoscalingPolicyConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Optional. Minimum number of instances for this group.
  ///
  /// Primary workers - Bounds: [2, max_instances]. Default: 2.
  /// Secondary workers - Bounds: [0, max_instances]. Default: 0.
  public var minInstances: Int32 = 0

  /// Optional. Maximum number of instances for this group. Required for primary
  /// workers. Note that by default, clusters will not use secondary workers.
  /// Required for secondary workers if the minimum secondary instances is set.
  ///
  /// Primary workers - Bounds: [min_instances, ). Required.
  /// Secondary workers - Bounds: [min_instances, ). Default: 0.
  public var maxInstances: Int32 = 0

  /// Optional. Weight for the instance group, which is used to determine the
  /// fraction of total workers in the cluster from this instance group.
  /// For example, if primary workers have weight 2, and secondary workers have
  /// weight 1, the cluster will have approximately 2 primary workers for each
  /// secondary worker.
  ///
  /// The cluster may not reach the specified balance if constrained
  /// by min/max bounds or other autoscaling settings. For example, if
  /// `max_instances` for secondary workers is 0, then only primary workers will
  /// be added. The cluster can also be out of balance when created.
  ///
  /// If weight is not set on any instance group, the cluster will default to
  /// equal weight for all groups: the cluster will attempt to maintain an equal
  /// number of workers in each group within the configured size bounds for each
  /// group. If weight is set for one group only, the cluster will default to
  /// zero weight on the unset group. For example if weight is set only on
  /// primary workers, the cluster will use primary workers only and no
  /// secondary workers.
  public var weight: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// A request to create an autoscaling policy.
public struct Google_Cloud_Dataproc_V1beta2_CreateAutoscalingPolicyRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The "resource name" of the region or location, as described
  /// in https://cloud.google.com/apis/design/resource_names.
  ///
  /// * For `projects.regions.autoscalingPolicies.create`, the resource name
  ///   has the following format:
  ///   `projects/{project_id}/regions/{region}`
  ///
  /// * For `projects.locations.autoscalingPolicies.create`, the resource name
  ///   has the following format:
  ///   `projects/{project_id}/locations/{location}`
  public var parent: String {
    get {return _storage._parent}
    set {_uniqueStorage()._parent = newValue}
  }

  /// Required. The autoscaling policy to create.
  public var policy: Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy {
    get {return _storage._policy ?? Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy()}
    set {_uniqueStorage()._policy = newValue}
  }
  /// Returns true if `policy` has been explicitly set.
  public var hasPolicy: Bool {return _storage._policy != nil}
  /// Clears the value of `policy`. Subsequent reads from it will return its default value.
  public mutating func clearPolicy() {_uniqueStorage()._policy = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// A request to fetch an autoscaling policy.
public struct Google_Cloud_Dataproc_V1beta2_GetAutoscalingPolicyRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The "resource name" of the autoscaling policy, as described
  /// in https://cloud.google.com/apis/design/resource_names.
  ///
  /// * For `projects.regions.autoscalingPolicies.get`, the resource name
  ///   of the policy has the following format:
  ///   `projects/{project_id}/regions/{region}/autoscalingPolicies/{policy_id}`
  ///
  /// * For `projects.locations.autoscalingPolicies.get`, the resource name
  ///   of the policy has the following format:
  ///   `projects/{project_id}/locations/{location}/autoscalingPolicies/{policy_id}`
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// A request to update an autoscaling policy.
public struct Google_Cloud_Dataproc_V1beta2_UpdateAutoscalingPolicyRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The updated autoscaling policy.
  public var policy: Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy {
    get {return _policy ?? Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy()}
    set {_policy = newValue}
  }
  /// Returns true if `policy` has been explicitly set.
  public var hasPolicy: Bool {return self._policy != nil}
  /// Clears the value of `policy`. Subsequent reads from it will return its default value.
  public mutating func clearPolicy() {self._policy = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _policy: Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy? = nil
}

/// A request to delete an autoscaling policy.
///
/// Autoscaling policies in use by one or more clusters will not be deleted.
public struct Google_Cloud_Dataproc_V1beta2_DeleteAutoscalingPolicyRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The "resource name" of the autoscaling policy, as described
  /// in https://cloud.google.com/apis/design/resource_names.
  ///
  /// * For `projects.regions.autoscalingPolicies.delete`, the resource name
  ///   of the policy has the following format:
  ///   `projects/{project_id}/regions/{region}/autoscalingPolicies/{policy_id}`
  ///
  /// * For `projects.locations.autoscalingPolicies.delete`, the resource name
  ///   of the policy has the following format:
  ///   `projects/{project_id}/locations/{location}/autoscalingPolicies/{policy_id}`
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// A request to list autoscaling policies in a project.
public struct Google_Cloud_Dataproc_V1beta2_ListAutoscalingPoliciesRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The "resource name" of the region or location, as described
  /// in https://cloud.google.com/apis/design/resource_names.
  ///
  /// * For `projects.regions.autoscalingPolicies.list`, the resource name
  ///   of the region has the following format:
  ///   `projects/{project_id}/regions/{region}`
  ///
  /// * For `projects.locations.autoscalingPolicies.list`, the resource name
  ///   of the location has the following format:
  ///   `projects/{project_id}/locations/{location}`
  public var parent: String = String()

  /// Optional. The maximum number of results to return in each response.
  /// Must be less than or equal to 1000. Defaults to 100.
  public var pageSize: Int32 = 0

  /// Optional. The page token, returned by a previous call, to request the
  /// next page of results.
  public var pageToken: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// A response to a request to list autoscaling policies in a project.
public struct Google_Cloud_Dataproc_V1beta2_ListAutoscalingPoliciesResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. Autoscaling policies list.
  public var policies: [Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy] = []

  /// Output only. This token is included in the response if there are more
  /// results to fetch.
  public var nextPageToken: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.dataproc.v1beta2"

extension Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AutoscalingPolicy"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "id"),
    2: .same(proto: "name"),
    3: .standard(proto: "basic_algorithm"),
    4: .standard(proto: "worker_config"),
    5: .standard(proto: "secondary_worker_config"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.id) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 3: try {
        var v: Google_Cloud_Dataproc_V1beta2_BasicAutoscalingAlgorithm?
        if let current = self.algorithm {
          try decoder.handleConflictingOneOf()
          if case .basicAlgorithm(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.algorithm = .basicAlgorithm(v)}
      }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._workerConfig) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._secondaryWorkerConfig) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.id.isEmpty {
      try visitor.visitSingularStringField(value: self.id, fieldNumber: 1)
    }
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 2)
    }
    if case .basicAlgorithm(let v)? = self.algorithm {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }
    if let v = self._workerConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    if let v = self._secondaryWorkerConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy, rhs: Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy) -> Bool {
    if lhs.id != rhs.id {return false}
    if lhs.name != rhs.name {return false}
    if lhs.algorithm != rhs.algorithm {return false}
    if lhs._workerConfig != rhs._workerConfig {return false}
    if lhs._secondaryWorkerConfig != rhs._secondaryWorkerConfig {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dataproc_V1beta2_BasicAutoscalingAlgorithm: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BasicAutoscalingAlgorithm"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "yarn_config"),
    2: .standard(proto: "cooldown_period"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._yarnConfig) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._cooldownPeriod) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._yarnConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._cooldownPeriod {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_BasicAutoscalingAlgorithm, rhs: Google_Cloud_Dataproc_V1beta2_BasicAutoscalingAlgorithm) -> Bool {
    if lhs._yarnConfig != rhs._yarnConfig {return false}
    if lhs._cooldownPeriod != rhs._cooldownPeriod {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dataproc_V1beta2_BasicYarnAutoscalingConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BasicYarnAutoscalingConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    5: .standard(proto: "graceful_decommission_timeout"),
    1: .standard(proto: "scale_up_factor"),
    2: .standard(proto: "scale_down_factor"),
    3: .standard(proto: "scale_up_min_worker_fraction"),
    4: .standard(proto: "scale_down_min_worker_fraction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularDoubleField(value: &self.scaleUpFactor) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.scaleDownFactor) }()
      case 3: try { try decoder.decodeSingularDoubleField(value: &self.scaleUpMinWorkerFraction) }()
      case 4: try { try decoder.decodeSingularDoubleField(value: &self.scaleDownMinWorkerFraction) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._gracefulDecommissionTimeout) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.scaleUpFactor != 0 {
      try visitor.visitSingularDoubleField(value: self.scaleUpFactor, fieldNumber: 1)
    }
    if self.scaleDownFactor != 0 {
      try visitor.visitSingularDoubleField(value: self.scaleDownFactor, fieldNumber: 2)
    }
    if self.scaleUpMinWorkerFraction != 0 {
      try visitor.visitSingularDoubleField(value: self.scaleUpMinWorkerFraction, fieldNumber: 3)
    }
    if self.scaleDownMinWorkerFraction != 0 {
      try visitor.visitSingularDoubleField(value: self.scaleDownMinWorkerFraction, fieldNumber: 4)
    }
    if let v = self._gracefulDecommissionTimeout {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_BasicYarnAutoscalingConfig, rhs: Google_Cloud_Dataproc_V1beta2_BasicYarnAutoscalingConfig) -> Bool {
    if lhs._gracefulDecommissionTimeout != rhs._gracefulDecommissionTimeout {return false}
    if lhs.scaleUpFactor != rhs.scaleUpFactor {return false}
    if lhs.scaleDownFactor != rhs.scaleDownFactor {return false}
    if lhs.scaleUpMinWorkerFraction != rhs.scaleUpMinWorkerFraction {return false}
    if lhs.scaleDownMinWorkerFraction != rhs.scaleDownMinWorkerFraction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dataproc_V1beta2_InstanceGroupAutoscalingPolicyConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".InstanceGroupAutoscalingPolicyConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "min_instances"),
    2: .standard(proto: "max_instances"),
    3: .same(proto: "weight"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.minInstances) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.maxInstances) }()
      case 3: try { try decoder.decodeSingularInt32Field(value: &self.weight) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.minInstances != 0 {
      try visitor.visitSingularInt32Field(value: self.minInstances, fieldNumber: 1)
    }
    if self.maxInstances != 0 {
      try visitor.visitSingularInt32Field(value: self.maxInstances, fieldNumber: 2)
    }
    if self.weight != 0 {
      try visitor.visitSingularInt32Field(value: self.weight, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_InstanceGroupAutoscalingPolicyConfig, rhs: Google_Cloud_Dataproc_V1beta2_InstanceGroupAutoscalingPolicyConfig) -> Bool {
    if lhs.minInstances != rhs.minInstances {return false}
    if lhs.maxInstances != rhs.maxInstances {return false}
    if lhs.weight != rhs.weight {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dataproc_V1beta2_CreateAutoscalingPolicyRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateAutoscalingPolicyRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .same(proto: "policy"),
  ]

  fileprivate class _StorageClass {
    var _parent: String = String()
    var _policy: Google_Cloud_Dataproc_V1beta2_AutoscalingPolicy? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _parent = source._parent
      _policy = source._policy
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._parent) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._policy) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._parent.isEmpty {
        try visitor.visitSingularStringField(value: _storage._parent, fieldNumber: 1)
      }
      if let v = _storage._policy {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_CreateAutoscalingPolicyRequest, rhs: Google_Cloud_Dataproc_V1beta2_CreateAutoscalingPolicyRequest) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._parent != rhs_storage._parent {return false}
        if _storage._policy != rhs_storage._policy {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dataproc_V1beta2_GetAutoscalingPolicyRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetAutoscalingPolicyRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_GetAutoscalingPolicyRequest, rhs: Google_Cloud_Dataproc_V1beta2_GetAutoscalingPolicyRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dataproc_V1beta2_UpdateAutoscalingPolicyRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".UpdateAutoscalingPolicyRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "policy"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._policy) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._policy {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_UpdateAutoscalingPolicyRequest, rhs: Google_Cloud_Dataproc_V1beta2_UpdateAutoscalingPolicyRequest) -> Bool {
    if lhs._policy != rhs._policy {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dataproc_V1beta2_DeleteAutoscalingPolicyRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DeleteAutoscalingPolicyRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_DeleteAutoscalingPolicyRequest, rhs: Google_Cloud_Dataproc_V1beta2_DeleteAutoscalingPolicyRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dataproc_V1beta2_ListAutoscalingPoliciesRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ListAutoscalingPoliciesRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .standard(proto: "page_size"),
    3: .standard(proto: "page_token"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.pageSize) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.pageToken) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 1)
    }
    if self.pageSize != 0 {
      try visitor.visitSingularInt32Field(value: self.pageSize, fieldNumber: 2)
    }
    if !self.pageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.pageToken, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_ListAutoscalingPoliciesRequest, rhs: Google_Cloud_Dataproc_V1beta2_ListAutoscalingPoliciesRequest) -> Bool {
    if lhs.parent != rhs.parent {return false}
    if lhs.pageSize != rhs.pageSize {return false}
    if lhs.pageToken != rhs.pageToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dataproc_V1beta2_ListAutoscalingPoliciesResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ListAutoscalingPoliciesResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "policies"),
    2: .standard(proto: "next_page_token"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.policies) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.nextPageToken) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.policies.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.policies, fieldNumber: 1)
    }
    if !self.nextPageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.nextPageToken, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dataproc_V1beta2_ListAutoscalingPoliciesResponse, rhs: Google_Cloud_Dataproc_V1beta2_ListAutoscalingPoliciesResponse) -> Bool {
    if lhs.policies != rhs.policies {return false}
    if lhs.nextPageToken != rhs.nextPageToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
