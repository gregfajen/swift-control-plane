// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/dialogflow/v2/session.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// The request to detect user's intent.
public struct Google_Cloud_Dialogflow_V2_DetectIntentRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the session this query is sent to. Format:
  /// `projects/<Project ID>/agent/sessions/<Session ID>`, or
  /// `projects/<Project ID>/agent/environments/<Environment ID>/users/<User
  /// ID>/sessions/<Session ID>`. If `Environment ID` is not specified, we assume
  /// default 'draft' environment. If `User ID` is not specified, we are using
  /// "-". It's up to the API caller to choose an appropriate `Session ID` and
  /// `User Id`. They can be a random number or some type of user and session
  /// identifiers (preferably hashed). The length of the `Session ID` and
  /// `User ID` must not exceed 36 characters.
  ///
  /// For more information, see the [API interactions
  /// guide](https://cloud.google.com/dialogflow/docs/api-overview).
  public var session: String {
    get {return _storage._session}
    set {_uniqueStorage()._session = newValue}
  }

  /// The parameters of this query.
  public var queryParams: Google_Cloud_Dialogflow_V2_QueryParameters {
    get {return _storage._queryParams ?? Google_Cloud_Dialogflow_V2_QueryParameters()}
    set {_uniqueStorage()._queryParams = newValue}
  }
  /// Returns true if `queryParams` has been explicitly set.
  public var hasQueryParams: Bool {return _storage._queryParams != nil}
  /// Clears the value of `queryParams`. Subsequent reads from it will return its default value.
  public mutating func clearQueryParams() {_uniqueStorage()._queryParams = nil}

  /// Required. The input specification. It can be set to:
  ///
  /// 1.  an audio config
  ///     which instructs the speech recognizer how to process the speech audio,
  ///
  /// 2.  a conversational query in the form of text, or
  ///
  /// 3.  an event that specifies which intent to trigger.
  public var queryInput: Google_Cloud_Dialogflow_V2_QueryInput {
    get {return _storage._queryInput ?? Google_Cloud_Dialogflow_V2_QueryInput()}
    set {_uniqueStorage()._queryInput = newValue}
  }
  /// Returns true if `queryInput` has been explicitly set.
  public var hasQueryInput: Bool {return _storage._queryInput != nil}
  /// Clears the value of `queryInput`. Subsequent reads from it will return its default value.
  public mutating func clearQueryInput() {_uniqueStorage()._queryInput = nil}

  /// Instructs the speech synthesizer how to generate the output
  /// audio. If this field is not set and agent-level speech synthesizer is not
  /// configured, no output audio is generated.
  public var outputAudioConfig: Google_Cloud_Dialogflow_V2_OutputAudioConfig {
    get {return _storage._outputAudioConfig ?? Google_Cloud_Dialogflow_V2_OutputAudioConfig()}
    set {_uniqueStorage()._outputAudioConfig = newValue}
  }
  /// Returns true if `outputAudioConfig` has been explicitly set.
  public var hasOutputAudioConfig: Bool {return _storage._outputAudioConfig != nil}
  /// Clears the value of `outputAudioConfig`. Subsequent reads from it will return its default value.
  public mutating func clearOutputAudioConfig() {_uniqueStorage()._outputAudioConfig = nil}

  /// Mask for [output_audio_config][google.cloud.dialogflow.v2.DetectIntentRequest.output_audio_config] indicating which settings in this
  /// request-level config should override speech synthesizer settings defined at
  /// agent-level.
  ///
  /// If unspecified or empty, [output_audio_config][google.cloud.dialogflow.v2.DetectIntentRequest.output_audio_config] replaces the agent-level
  /// config in its entirety.
  public var outputAudioConfigMask: SwiftProtobuf.Google_Protobuf_FieldMask {
    get {return _storage._outputAudioConfigMask ?? SwiftProtobuf.Google_Protobuf_FieldMask()}
    set {_uniqueStorage()._outputAudioConfigMask = newValue}
  }
  /// Returns true if `outputAudioConfigMask` has been explicitly set.
  public var hasOutputAudioConfigMask: Bool {return _storage._outputAudioConfigMask != nil}
  /// Clears the value of `outputAudioConfigMask`. Subsequent reads from it will return its default value.
  public mutating func clearOutputAudioConfigMask() {_uniqueStorage()._outputAudioConfigMask = nil}

  /// The natural language speech audio to be processed. This field
  /// should be populated iff `query_input` is set to an input audio config.
  /// A single request can contain up to 1 minute of speech audio data.
  public var inputAudio: Data {
    get {return _storage._inputAudio}
    set {_uniqueStorage()._inputAudio = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// The message returned from the DetectIntent method.
public struct Google_Cloud_Dialogflow_V2_DetectIntentResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The unique identifier of the response. It can be used to
  /// locate a response in the training example set or for reporting issues.
  public var responseID: String {
    get {return _storage._responseID}
    set {_uniqueStorage()._responseID = newValue}
  }

  /// The selected results of the conversational query or event processing.
  /// See `alternative_query_results` for additional potential results.
  public var queryResult: Google_Cloud_Dialogflow_V2_QueryResult {
    get {return _storage._queryResult ?? Google_Cloud_Dialogflow_V2_QueryResult()}
    set {_uniqueStorage()._queryResult = newValue}
  }
  /// Returns true if `queryResult` has been explicitly set.
  public var hasQueryResult: Bool {return _storage._queryResult != nil}
  /// Clears the value of `queryResult`. Subsequent reads from it will return its default value.
  public mutating func clearQueryResult() {_uniqueStorage()._queryResult = nil}

  /// Specifies the status of the webhook request.
  public var webhookStatus: Google_Rpc_Status {
    get {return _storage._webhookStatus ?? Google_Rpc_Status()}
    set {_uniqueStorage()._webhookStatus = newValue}
  }
  /// Returns true if `webhookStatus` has been explicitly set.
  public var hasWebhookStatus: Bool {return _storage._webhookStatus != nil}
  /// Clears the value of `webhookStatus`. Subsequent reads from it will return its default value.
  public mutating func clearWebhookStatus() {_uniqueStorage()._webhookStatus = nil}

  /// The audio data bytes encoded as specified in the request.
  /// Note: The output audio is generated based on the values of default platform
  /// text responses found in the `query_result.fulfillment_messages` field. If
  /// multiple default text responses exist, they will be concatenated when
  /// generating audio. If no default platform text responses exist, the
  /// generated audio content will be empty.
  ///
  /// In some scenarios, multiple output audio fields may be present in the
  /// response structure. In these cases, only the top-most-level audio output
  /// has content.
  public var outputAudio: Data {
    get {return _storage._outputAudio}
    set {_uniqueStorage()._outputAudio = newValue}
  }

  /// The config used by the speech synthesizer to generate the output audio.
  public var outputAudioConfig: Google_Cloud_Dialogflow_V2_OutputAudioConfig {
    get {return _storage._outputAudioConfig ?? Google_Cloud_Dialogflow_V2_OutputAudioConfig()}
    set {_uniqueStorage()._outputAudioConfig = newValue}
  }
  /// Returns true if `outputAudioConfig` has been explicitly set.
  public var hasOutputAudioConfig: Bool {return _storage._outputAudioConfig != nil}
  /// Clears the value of `outputAudioConfig`. Subsequent reads from it will return its default value.
  public mutating func clearOutputAudioConfig() {_uniqueStorage()._outputAudioConfig = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Represents the parameters of the conversational query.
public struct Google_Cloud_Dialogflow_V2_QueryParameters {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The time zone of this conversational query from the
  /// [time zone database](https://www.iana.org/time-zones), e.g.,
  /// America/New_York, Europe/Paris. If not provided, the time zone specified in
  /// agent settings is used.
  public var timeZone: String = String()

  /// The geo location of this conversational query.
  public var geoLocation: Google_Type_LatLng {
    get {return _geoLocation ?? Google_Type_LatLng()}
    set {_geoLocation = newValue}
  }
  /// Returns true if `geoLocation` has been explicitly set.
  public var hasGeoLocation: Bool {return self._geoLocation != nil}
  /// Clears the value of `geoLocation`. Subsequent reads from it will return its default value.
  public mutating func clearGeoLocation() {self._geoLocation = nil}

  /// The collection of contexts to be activated before this query is
  /// executed.
  public var contexts: [Google_Cloud_Dialogflow_V2_Context] = []

  /// Specifies whether to delete all contexts in the current session
  /// before the new ones are activated.
  public var resetContexts: Bool = false

  /// Additional session entity types to replace or extend developer
  /// entity types with. The entity synonyms apply to all languages and persist
  /// for the session of this query.
  public var sessionEntityTypes: [Google_Cloud_Dialogflow_V2_SessionEntityType] = []

  /// This field can be used to pass custom data to your webhook.
  /// Arbitrary JSON objects are supported.
  /// If supplied, the value is used to populate the
  /// `WebhookRequest.original_detect_intent_request.payload`
  /// field sent to your webhook.
  public var payload: SwiftProtobuf.Google_Protobuf_Struct {
    get {return _payload ?? SwiftProtobuf.Google_Protobuf_Struct()}
    set {_payload = newValue}
  }
  /// Returns true if `payload` has been explicitly set.
  public var hasPayload: Bool {return self._payload != nil}
  /// Clears the value of `payload`. Subsequent reads from it will return its default value.
  public mutating func clearPayload() {self._payload = nil}

  /// Configures the type of sentiment analysis to perform. If not
  /// provided, sentiment analysis is not performed.
  public var sentimentAnalysisRequestConfig: Google_Cloud_Dialogflow_V2_SentimentAnalysisRequestConfig {
    get {return _sentimentAnalysisRequestConfig ?? Google_Cloud_Dialogflow_V2_SentimentAnalysisRequestConfig()}
    set {_sentimentAnalysisRequestConfig = newValue}
  }
  /// Returns true if `sentimentAnalysisRequestConfig` has been explicitly set.
  public var hasSentimentAnalysisRequestConfig: Bool {return self._sentimentAnalysisRequestConfig != nil}
  /// Clears the value of `sentimentAnalysisRequestConfig`. Subsequent reads from it will return its default value.
  public mutating func clearSentimentAnalysisRequestConfig() {self._sentimentAnalysisRequestConfig = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _geoLocation: Google_Type_LatLng? = nil
  fileprivate var _payload: SwiftProtobuf.Google_Protobuf_Struct? = nil
  fileprivate var _sentimentAnalysisRequestConfig: Google_Cloud_Dialogflow_V2_SentimentAnalysisRequestConfig? = nil
}

/// Represents the query input. It can contain either:
///
/// 1.  An audio config which
///     instructs the speech recognizer how to process the speech audio.
///
/// 2.  A conversational query in the form of text,.
///
/// 3.  An event that specifies which intent to trigger.
public struct Google_Cloud_Dialogflow_V2_QueryInput {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The input specification.
  public var input: Google_Cloud_Dialogflow_V2_QueryInput.OneOf_Input? = nil

  /// Instructs the speech recognizer how to process the speech audio.
  public var audioConfig: Google_Cloud_Dialogflow_V2_InputAudioConfig {
    get {
      if case .audioConfig(let v)? = input {return v}
      return Google_Cloud_Dialogflow_V2_InputAudioConfig()
    }
    set {input = .audioConfig(newValue)}
  }

  /// The natural language text to be processed.
  public var text: Google_Cloud_Dialogflow_V2_TextInput {
    get {
      if case .text(let v)? = input {return v}
      return Google_Cloud_Dialogflow_V2_TextInput()
    }
    set {input = .text(newValue)}
  }

  /// The event to be processed.
  public var event: Google_Cloud_Dialogflow_V2_EventInput {
    get {
      if case .event(let v)? = input {return v}
      return Google_Cloud_Dialogflow_V2_EventInput()
    }
    set {input = .event(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Required. The input specification.
  public enum OneOf_Input: Equatable {
    /// Instructs the speech recognizer how to process the speech audio.
    case audioConfig(Google_Cloud_Dialogflow_V2_InputAudioConfig)
    /// The natural language text to be processed.
    case text(Google_Cloud_Dialogflow_V2_TextInput)
    /// The event to be processed.
    case event(Google_Cloud_Dialogflow_V2_EventInput)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Dialogflow_V2_QueryInput.OneOf_Input, rhs: Google_Cloud_Dialogflow_V2_QueryInput.OneOf_Input) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.audioConfig, .audioConfig): return {
        guard case .audioConfig(let l) = lhs, case .audioConfig(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.text, .text): return {
        guard case .text(let l) = lhs, case .text(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.event, .event): return {
        guard case .event(let l) = lhs, case .event(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// Represents the result of conversational query or event processing.
public struct Google_Cloud_Dialogflow_V2_QueryResult {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The original conversational query text:
  ///
  /// - If natural language text was provided as input, `query_text` contains
  ///   a copy of the input.
  /// - If natural language speech audio was provided as input, `query_text`
  ///   contains the speech recognition result. If speech recognizer produced
  ///   multiple alternatives, a particular one is picked.
  /// - If automatic spell correction is enabled, `query_text` will contain the
  ///   corrected user input.
  public var queryText: String = String()

  /// The language that was triggered during intent detection.
  /// See [Language
  /// Support](https://cloud.google.com/dialogflow/docs/reference/language)
  /// for a list of the currently supported language codes.
  public var languageCode: String = String()

  /// The Speech recognition confidence between 0.0 and 1.0. A higher number
  /// indicates an estimated greater likelihood that the recognized words are
  /// correct. The default of 0.0 is a sentinel value indicating that confidence
  /// was not set.
  ///
  /// This field is not guaranteed to be accurate or set. In particular this
  /// field isn't set for StreamingDetectIntent since the streaming endpoint has
  /// separate confidence estimates per portion of the audio in
  /// StreamingRecognitionResult.
  public var speechRecognitionConfidence: Float = 0

  /// The action name from the matched intent.
  public var action: String = String()

  /// The collection of extracted parameters.
  ///
  /// Depending on your protocol or client library language, this is a
  /// map, associative array, symbol table, dictionary, or JSON object
  /// composed of a collection of (MapKey, MapValue) pairs:
  ///
  /// -   MapKey type: string
  /// -   MapKey value: parameter name
  /// -   MapValue type:
  ///     -   If parameter's entity type is a composite entity: map
  ///     -   Else: string or number, depending on parameter value type
  /// -   MapValue value:
  ///     -   If parameter's entity type is a composite entity:
  ///         map from composite entity property names to property values
  ///     -   Else: parameter value
  public var parameters: SwiftProtobuf.Google_Protobuf_Struct {
    get {return _parameters ?? SwiftProtobuf.Google_Protobuf_Struct()}
    set {_parameters = newValue}
  }
  /// Returns true if `parameters` has been explicitly set.
  public var hasParameters: Bool {return self._parameters != nil}
  /// Clears the value of `parameters`. Subsequent reads from it will return its default value.
  public mutating func clearParameters() {self._parameters = nil}

  /// This field is set to:
  ///
  /// - `false` if the matched intent has required parameters and not all of
  ///    the required parameter values have been collected.
  /// - `true` if all required parameter values have been collected, or if the
  ///    matched intent doesn't contain any required parameters.
  public var allRequiredParamsPresent: Bool = false

  /// The text to be pronounced to the user or shown on the screen.
  /// Note: This is a legacy field, `fulfillment_messages` should be preferred.
  public var fulfillmentText: String = String()

  /// The collection of rich messages to present to the user.
  public var fulfillmentMessages: [Google_Cloud_Dialogflow_V2_Intent.Message] = []

  /// If the query was fulfilled by a webhook call, this field is set to the
  /// value of the `source` field returned in the webhook response.
  public var webhookSource: String = String()

  /// If the query was fulfilled by a webhook call, this field is set to the
  /// value of the `payload` field returned in the webhook response.
  public var webhookPayload: SwiftProtobuf.Google_Protobuf_Struct {
    get {return _webhookPayload ?? SwiftProtobuf.Google_Protobuf_Struct()}
    set {_webhookPayload = newValue}
  }
  /// Returns true if `webhookPayload` has been explicitly set.
  public var hasWebhookPayload: Bool {return self._webhookPayload != nil}
  /// Clears the value of `webhookPayload`. Subsequent reads from it will return its default value.
  public mutating func clearWebhookPayload() {self._webhookPayload = nil}

  /// The collection of output contexts. If applicable,
  /// `output_contexts.parameters` contains entries with name
  /// `<parameter name>.original` containing the original parameter values
  /// before the query.
  public var outputContexts: [Google_Cloud_Dialogflow_V2_Context] = []

  /// The intent that matched the conversational query. Some, not
  /// all fields are filled in this message, including but not limited to:
  /// `name`, `display_name`, `end_interaction` and `is_fallback`.
  public var intent: Google_Cloud_Dialogflow_V2_Intent {
    get {return _intent ?? Google_Cloud_Dialogflow_V2_Intent()}
    set {_intent = newValue}
  }
  /// Returns true if `intent` has been explicitly set.
  public var hasIntent: Bool {return self._intent != nil}
  /// Clears the value of `intent`. Subsequent reads from it will return its default value.
  public mutating func clearIntent() {self._intent = nil}

  /// The intent detection confidence. Values range from 0.0
  /// (completely uncertain) to 1.0 (completely certain).
  /// This value is for informational purpose only and is only used to
  /// help match the best intent within the classification threshold.
  /// This value may change for the same end-user expression at any time due to a
  /// model retraining or change in implementation.
  /// If there are `multiple knowledge_answers` messages, this value is set to
  /// the greatest `knowledgeAnswers.match_confidence` value in the list.
  public var intentDetectionConfidence: Float = 0

  /// Free-form diagnostic information for the associated detect intent request.
  /// The fields of this data can change without notice, so you should not write
  /// code that depends on its structure.
  /// The data may contain:
  ///
  /// - webhook call latency
  /// - webhook errors
  public var diagnosticInfo: SwiftProtobuf.Google_Protobuf_Struct {
    get {return _diagnosticInfo ?? SwiftProtobuf.Google_Protobuf_Struct()}
    set {_diagnosticInfo = newValue}
  }
  /// Returns true if `diagnosticInfo` has been explicitly set.
  public var hasDiagnosticInfo: Bool {return self._diagnosticInfo != nil}
  /// Clears the value of `diagnosticInfo`. Subsequent reads from it will return its default value.
  public mutating func clearDiagnosticInfo() {self._diagnosticInfo = nil}

  /// The sentiment analysis result, which depends on the
  /// `sentiment_analysis_request_config` specified in the request.
  public var sentimentAnalysisResult: Google_Cloud_Dialogflow_V2_SentimentAnalysisResult {
    get {return _sentimentAnalysisResult ?? Google_Cloud_Dialogflow_V2_SentimentAnalysisResult()}
    set {_sentimentAnalysisResult = newValue}
  }
  /// Returns true if `sentimentAnalysisResult` has been explicitly set.
  public var hasSentimentAnalysisResult: Bool {return self._sentimentAnalysisResult != nil}
  /// Clears the value of `sentimentAnalysisResult`. Subsequent reads from it will return its default value.
  public mutating func clearSentimentAnalysisResult() {self._sentimentAnalysisResult = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _parameters: SwiftProtobuf.Google_Protobuf_Struct? = nil
  fileprivate var _webhookPayload: SwiftProtobuf.Google_Protobuf_Struct? = nil
  fileprivate var _intent: Google_Cloud_Dialogflow_V2_Intent? = nil
  fileprivate var _diagnosticInfo: SwiftProtobuf.Google_Protobuf_Struct? = nil
  fileprivate var _sentimentAnalysisResult: Google_Cloud_Dialogflow_V2_SentimentAnalysisResult? = nil
}

/// The top-level message sent by the client to the
/// [Sessions.StreamingDetectIntent][google.cloud.dialogflow.v2.Sessions.StreamingDetectIntent] method.
///
/// Multiple request messages should be sent in order:
///
/// 1.  The first message must contain
/// [session][google.cloud.dialogflow.v2.StreamingDetectIntentRequest.session],
///     [query_input][google.cloud.dialogflow.v2.StreamingDetectIntentRequest.query_input] plus optionally
///     [query_params][google.cloud.dialogflow.v2.StreamingDetectIntentRequest.query_params]. If the client
///     wants to receive an audio response, it should also contain
///     [output_audio_config][google.cloud.dialogflow.v2.StreamingDetectIntentRequest.output_audio_config].
///     The message must not contain
///     [input_audio][google.cloud.dialogflow.v2.StreamingDetectIntentRequest.input_audio].
/// 2.  If [query_input][google.cloud.dialogflow.v2.StreamingDetectIntentRequest.query_input] was set to
///     [query_input.audio_config][google.cloud.dialogflow.v2.InputAudioConfig], all subsequent
///     messages must contain
///     [input_audio][google.cloud.dialogflow.v2.StreamingDetectIntentRequest.input_audio] to continue with
///     Speech recognition.
///     If you decide to rather detect an intent from text input after you
///     already started Speech recognition, please send a message with
///     [query_input.text][google.cloud.dialogflow.v2.QueryInput.text].
///
///     However, note that:
///
///     * Dialogflow will bill you for the audio duration so far.
///     * Dialogflow discards all Speech recognition results in favor of the
///       input text.
///     * Dialogflow will use the language code from the first message.
///
/// After you sent all input, you must half-close or abort the request stream.
public struct Google_Cloud_Dialogflow_V2_StreamingDetectIntentRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the session the query is sent to.
  /// Format of the session name:
  /// `projects/<Project ID>/agent/sessions/<Session ID>`, or
  /// `projects/<Project ID>/agent/environments/<Environment ID>/users/<User
  /// ID>/sessions/<Session ID>`. If `Environment ID` is not specified, we assume
  /// default 'draft' environment. If `User ID` is not specified, we are using
  /// "-". It's up to the API caller to choose an appropriate `Session ID` and
  /// `User Id`. They can be a random number or some type of user and session
  /// identifiers (preferably hashed). The length of the `Session ID` and
  /// `User ID` must not exceed 36 characters.
  ///
  /// For more information, see the [API interactions
  /// guide](https://cloud.google.com/dialogflow/docs/api-overview).
  public var session: String {
    get {return _storage._session}
    set {_uniqueStorage()._session = newValue}
  }

  /// The parameters of this query.
  public var queryParams: Google_Cloud_Dialogflow_V2_QueryParameters {
    get {return _storage._queryParams ?? Google_Cloud_Dialogflow_V2_QueryParameters()}
    set {_uniqueStorage()._queryParams = newValue}
  }
  /// Returns true if `queryParams` has been explicitly set.
  public var hasQueryParams: Bool {return _storage._queryParams != nil}
  /// Clears the value of `queryParams`. Subsequent reads from it will return its default value.
  public mutating func clearQueryParams() {_uniqueStorage()._queryParams = nil}

  /// Required. The input specification. It can be set to:
  ///
  /// 1.  an audio config which instructs the speech recognizer how to process
  ///     the speech audio,
  ///
  /// 2.  a conversational query in the form of text, or
  ///
  /// 3.  an event that specifies which intent to trigger.
  public var queryInput: Google_Cloud_Dialogflow_V2_QueryInput {
    get {return _storage._queryInput ?? Google_Cloud_Dialogflow_V2_QueryInput()}
    set {_uniqueStorage()._queryInput = newValue}
  }
  /// Returns true if `queryInput` has been explicitly set.
  public var hasQueryInput: Bool {return _storage._queryInput != nil}
  /// Clears the value of `queryInput`. Subsequent reads from it will return its default value.
  public mutating func clearQueryInput() {_uniqueStorage()._queryInput = nil}

  /// Please use [InputAudioConfig.single_utterance][google.cloud.dialogflow.v2.InputAudioConfig.single_utterance] instead.
  /// If `false` (default), recognition does not cease until
  /// the client closes the stream. If `true`, the recognizer will detect a
  /// single spoken utterance in input audio. Recognition ceases when it detects
  /// the audio's voice has stopped or paused. In this case, once a detected
  /// intent is received, the client should close the stream and start a new
  /// request with a new stream as needed.
  /// This setting is ignored when `query_input` is a piece of text or an event.
  public var singleUtterance: Bool {
    get {return _storage._singleUtterance}
    set {_uniqueStorage()._singleUtterance = newValue}
  }

  /// Instructs the speech synthesizer how to generate the output
  /// audio. If this field is not set and agent-level speech synthesizer is not
  /// configured, no output audio is generated.
  public var outputAudioConfig: Google_Cloud_Dialogflow_V2_OutputAudioConfig {
    get {return _storage._outputAudioConfig ?? Google_Cloud_Dialogflow_V2_OutputAudioConfig()}
    set {_uniqueStorage()._outputAudioConfig = newValue}
  }
  /// Returns true if `outputAudioConfig` has been explicitly set.
  public var hasOutputAudioConfig: Bool {return _storage._outputAudioConfig != nil}
  /// Clears the value of `outputAudioConfig`. Subsequent reads from it will return its default value.
  public mutating func clearOutputAudioConfig() {_uniqueStorage()._outputAudioConfig = nil}

  /// Mask for [output_audio_config][google.cloud.dialogflow.v2.StreamingDetectIntentRequest.output_audio_config] indicating which settings in this
  /// request-level config should override speech synthesizer settings defined at
  /// agent-level.
  ///
  /// If unspecified or empty, [output_audio_config][google.cloud.dialogflow.v2.StreamingDetectIntentRequest.output_audio_config] replaces the agent-level
  /// config in its entirety.
  public var outputAudioConfigMask: SwiftProtobuf.Google_Protobuf_FieldMask {
    get {return _storage._outputAudioConfigMask ?? SwiftProtobuf.Google_Protobuf_FieldMask()}
    set {_uniqueStorage()._outputAudioConfigMask = newValue}
  }
  /// Returns true if `outputAudioConfigMask` has been explicitly set.
  public var hasOutputAudioConfigMask: Bool {return _storage._outputAudioConfigMask != nil}
  /// Clears the value of `outputAudioConfigMask`. Subsequent reads from it will return its default value.
  public mutating func clearOutputAudioConfigMask() {_uniqueStorage()._outputAudioConfigMask = nil}

  /// The input audio content to be recognized. Must be sent if
  /// `query_input` was set to a streaming input audio config. The complete audio
  /// over all streaming messages must not exceed 1 minute.
  public var inputAudio: Data {
    get {return _storage._inputAudio}
    set {_uniqueStorage()._inputAudio = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// The top-level message returned from the
/// `StreamingDetectIntent` method.
///
/// Multiple response messages can be returned in order:
///
/// 1.  If the input was set to streaming audio, the first one or more messages
///     contain `recognition_result`. Each `recognition_result` represents a more
///     complete transcript of what the user said. The last `recognition_result`
///     has `is_final` set to `true`.
///
/// 2.  The next message contains `response_id`, `query_result`
///     and optionally `webhook_status` if a WebHook was called.
public struct Google_Cloud_Dialogflow_V2_StreamingDetectIntentResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The unique identifier of the response. It can be used to
  /// locate a response in the training example set or for reporting issues.
  public var responseID: String {
    get {return _storage._responseID}
    set {_uniqueStorage()._responseID = newValue}
  }

  /// The result of speech recognition.
  public var recognitionResult: Google_Cloud_Dialogflow_V2_StreamingRecognitionResult {
    get {return _storage._recognitionResult ?? Google_Cloud_Dialogflow_V2_StreamingRecognitionResult()}
    set {_uniqueStorage()._recognitionResult = newValue}
  }
  /// Returns true if `recognitionResult` has been explicitly set.
  public var hasRecognitionResult: Bool {return _storage._recognitionResult != nil}
  /// Clears the value of `recognitionResult`. Subsequent reads from it will return its default value.
  public mutating func clearRecognitionResult() {_uniqueStorage()._recognitionResult = nil}

  /// The result of the conversational query or event processing.
  public var queryResult: Google_Cloud_Dialogflow_V2_QueryResult {
    get {return _storage._queryResult ?? Google_Cloud_Dialogflow_V2_QueryResult()}
    set {_uniqueStorage()._queryResult = newValue}
  }
  /// Returns true if `queryResult` has been explicitly set.
  public var hasQueryResult: Bool {return _storage._queryResult != nil}
  /// Clears the value of `queryResult`. Subsequent reads from it will return its default value.
  public mutating func clearQueryResult() {_uniqueStorage()._queryResult = nil}

  /// Specifies the status of the webhook request.
  public var webhookStatus: Google_Rpc_Status {
    get {return _storage._webhookStatus ?? Google_Rpc_Status()}
    set {_uniqueStorage()._webhookStatus = newValue}
  }
  /// Returns true if `webhookStatus` has been explicitly set.
  public var hasWebhookStatus: Bool {return _storage._webhookStatus != nil}
  /// Clears the value of `webhookStatus`. Subsequent reads from it will return its default value.
  public mutating func clearWebhookStatus() {_uniqueStorage()._webhookStatus = nil}

  /// The audio data bytes encoded as specified in the request.
  /// Note: The output audio is generated based on the values of default platform
  /// text responses found in the `query_result.fulfillment_messages` field. If
  /// multiple default text responses exist, they will be concatenated when
  /// generating audio. If no default platform text responses exist, the
  /// generated audio content will be empty.
  ///
  /// In some scenarios, multiple output audio fields may be present in the
  /// response structure. In these cases, only the top-most-level audio output
  /// has content.
  public var outputAudio: Data {
    get {return _storage._outputAudio}
    set {_uniqueStorage()._outputAudio = newValue}
  }

  /// The config used by the speech synthesizer to generate the output audio.
  public var outputAudioConfig: Google_Cloud_Dialogflow_V2_OutputAudioConfig {
    get {return _storage._outputAudioConfig ?? Google_Cloud_Dialogflow_V2_OutputAudioConfig()}
    set {_uniqueStorage()._outputAudioConfig = newValue}
  }
  /// Returns true if `outputAudioConfig` has been explicitly set.
  public var hasOutputAudioConfig: Bool {return _storage._outputAudioConfig != nil}
  /// Clears the value of `outputAudioConfig`. Subsequent reads from it will return its default value.
  public mutating func clearOutputAudioConfig() {_uniqueStorage()._outputAudioConfig = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Contains a speech recognition result corresponding to a portion of the audio
/// that is currently being processed or an indication that this is the end
/// of the single requested utterance.
///
/// Example:
///
/// 1.  transcript: "tube"
///
/// 2.  transcript: "to be a"
///
/// 3.  transcript: "to be"
///
/// 4.  transcript: "to be or not to be"
///     is_final: true
///
/// 5.  transcript: " that's"
///
/// 6.  transcript: " that is"
///
/// 7.  message_type: `END_OF_SINGLE_UTTERANCE`
///
/// 8.  transcript: " that is the question"
///     is_final: true
///
/// Only two of the responses contain final results (#4 and #8 indicated by
/// `is_final: true`). Concatenating these generates the full transcript: "to be
/// or not to be that is the question".
///
/// In each response we populate:
///
/// *  for `TRANSCRIPT`: `transcript` and possibly `is_final`.
///
/// *  for `END_OF_SINGLE_UTTERANCE`: only `message_type`.
public struct Google_Cloud_Dialogflow_V2_StreamingRecognitionResult {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Type of the result message.
  public var messageType: Google_Cloud_Dialogflow_V2_StreamingRecognitionResult.MessageType = .unspecified

  /// Transcript text representing the words that the user spoke.
  /// Populated if and only if `message_type` = `TRANSCRIPT`.
  public var transcript: String = String()

  /// If `false`, the `StreamingRecognitionResult` represents an
  /// interim result that may change. If `true`, the recognizer will not return
  /// any further hypotheses about this piece of the audio. May only be populated
  /// for `message_type` = `TRANSCRIPT`.
  public var isFinal: Bool = false

  /// The Speech confidence between 0.0 and 1.0 for the current portion of audio.
  /// A higher number indicates an estimated greater likelihood that the
  /// recognized words are correct. The default of 0.0 is a sentinel value
  /// indicating that confidence was not set.
  ///
  /// This field is typically only provided if `is_final` is true and you should
  /// not rely on it being accurate or even set.
  public var confidence: Float = 0

  /// Word-specific information for the words recognized by Speech in
  /// [transcript][google.cloud.dialogflow.v2.StreamingRecognitionResult.transcript]. Populated if and only if `message_type` = `TRANSCRIPT` and
  /// [InputAudioConfig.enable_word_info] is set.
  public var speechWordInfo: [Google_Cloud_Dialogflow_V2_SpeechWordInfo] = []

  /// Time offset of the end of this Speech recognition result relative to the
  /// beginning of the audio. Only populated for `message_type` = `TRANSCRIPT`.
  public var speechEndOffset: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _speechEndOffset ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_speechEndOffset = newValue}
  }
  /// Returns true if `speechEndOffset` has been explicitly set.
  public var hasSpeechEndOffset: Bool {return self._speechEndOffset != nil}
  /// Clears the value of `speechEndOffset`. Subsequent reads from it will return its default value.
  public mutating func clearSpeechEndOffset() {self._speechEndOffset = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Type of the response message.
  public enum MessageType: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Not specified. Should never be used.
    case unspecified // = 0

    /// Message contains a (possibly partial) transcript.
    case transcript // = 1

    /// Event indicates that the server has detected the end of the user's speech
    /// utterance and expects no additional inputs.
    /// Therefore, the server will not process additional audio (although it may subsequently return additional results). The
    /// client should stop sending additional audio data, half-close the gRPC
    /// connection, and wait for any additional results until the server closes
    /// the gRPC connection. This message is only sent if `single_utterance` was
    /// set to `true`, and is not used otherwise.
    case endOfSingleUtterance // = 2
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .transcript
      case 2: self = .endOfSingleUtterance
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .transcript: return 1
      case .endOfSingleUtterance: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _speechEndOffset: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

#if swift(>=4.2)

extension Google_Cloud_Dialogflow_V2_StreamingRecognitionResult.MessageType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Dialogflow_V2_StreamingRecognitionResult.MessageType] = [
    .unspecified,
    .transcript,
    .endOfSingleUtterance,
  ]
}

#endif  // swift(>=4.2)

/// Represents the natural language text to be processed.
public struct Google_Cloud_Dialogflow_V2_TextInput {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The UTF-8 encoded natural language text to be processed.
  /// Text length must not exceed 256 characters.
  public var text: String = String()

  /// Required. The language of this conversational query. See [Language
  /// Support](https://cloud.google.com/dialogflow/docs/reference/language)
  /// for a list of the currently supported language codes. Note that queries in
  /// the same session do not necessarily need to specify the same language.
  public var languageCode: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Events allow for matching intents by event name instead of the natural
/// language input. For instance, input `<event: { name: "welcome_event",
/// parameters: { name: "Sam" } }>` can trigger a personalized welcome response.
/// The parameter `name` may be used by the agent in the response:
/// `"Hello #welcome_event.name! What can I do for you today?"`.
public struct Google_Cloud_Dialogflow_V2_EventInput {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The unique identifier of the event.
  public var name: String = String()

  /// The collection of parameters associated with the event.
  ///
  /// Depending on your protocol or client library language, this is a
  /// map, associative array, symbol table, dictionary, or JSON object
  /// composed of a collection of (MapKey, MapValue) pairs:
  ///
  /// -   MapKey type: string
  /// -   MapKey value: parameter name
  /// -   MapValue type:
  ///     -   If parameter's entity type is a composite entity: map
  ///     -   Else: string or number, depending on parameter value type
  /// -   MapValue value:
  ///     -   If parameter's entity type is a composite entity:
  ///         map from composite entity property names to property values
  ///     -   Else: parameter value
  public var parameters: SwiftProtobuf.Google_Protobuf_Struct {
    get {return _parameters ?? SwiftProtobuf.Google_Protobuf_Struct()}
    set {_parameters = newValue}
  }
  /// Returns true if `parameters` has been explicitly set.
  public var hasParameters: Bool {return self._parameters != nil}
  /// Clears the value of `parameters`. Subsequent reads from it will return its default value.
  public mutating func clearParameters() {self._parameters = nil}

  /// Required. The language of this query. See [Language
  /// Support](https://cloud.google.com/dialogflow/docs/reference/language)
  /// for a list of the currently supported language codes. Note that queries in
  /// the same session do not necessarily need to specify the same language.
  public var languageCode: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _parameters: SwiftProtobuf.Google_Protobuf_Struct? = nil
}

/// Configures the types of sentiment analysis to perform.
public struct Google_Cloud_Dialogflow_V2_SentimentAnalysisRequestConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Instructs the service to perform sentiment analysis on
  /// `query_text`. If not provided, sentiment analysis is not performed on
  /// `query_text`.
  public var analyzeQueryTextSentiment: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// The result of sentiment analysis. Sentiment analysis inspects user input
/// and identifies the prevailing subjective opinion, especially to determine a
/// user's attitude as positive, negative, or neutral.
/// For [Participants.DetectIntent][], it needs to be configured in
/// [DetectIntentRequest.query_params][google.cloud.dialogflow.v2.DetectIntentRequest.query_params]. For
/// [Participants.StreamingDetectIntent][], it needs to be configured in
/// [StreamingDetectIntentRequest.query_params][google.cloud.dialogflow.v2.StreamingDetectIntentRequest.query_params].
/// And for [Participants.AnalyzeContent][google.cloud.dialogflow.v2.Participants.AnalyzeContent] and
/// [Participants.StreamingAnalyzeContent][google.cloud.dialogflow.v2.Participants.StreamingAnalyzeContent], it needs to be configured in
/// [ConversationProfile.human_agent_assistant_config][google.cloud.dialogflow.v2.ConversationProfile.human_agent_assistant_config]
public struct Google_Cloud_Dialogflow_V2_SentimentAnalysisResult {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The sentiment analysis result for `query_text`.
  public var queryTextSentiment: Google_Cloud_Dialogflow_V2_Sentiment {
    get {return _queryTextSentiment ?? Google_Cloud_Dialogflow_V2_Sentiment()}
    set {_queryTextSentiment = newValue}
  }
  /// Returns true if `queryTextSentiment` has been explicitly set.
  public var hasQueryTextSentiment: Bool {return self._queryTextSentiment != nil}
  /// Clears the value of `queryTextSentiment`. Subsequent reads from it will return its default value.
  public mutating func clearQueryTextSentiment() {self._queryTextSentiment = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _queryTextSentiment: Google_Cloud_Dialogflow_V2_Sentiment? = nil
}

/// The sentiment, such as positive/negative feeling or association, for a unit
/// of analysis, such as the query text.
public struct Google_Cloud_Dialogflow_V2_Sentiment {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Sentiment score between -1.0 (negative sentiment) and 1.0 (positive
  /// sentiment).
  public var score: Float = 0

  /// A non-negative number in the [0, +inf) range, which represents the absolute
  /// magnitude of sentiment, regardless of score (positive or negative).
  public var magnitude: Float = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.dialogflow.v2"

extension Google_Cloud_Dialogflow_V2_DetectIntentRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DetectIntentRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "session"),
    2: .standard(proto: "query_params"),
    3: .standard(proto: "query_input"),
    4: .standard(proto: "output_audio_config"),
    7: .standard(proto: "output_audio_config_mask"),
    5: .standard(proto: "input_audio"),
  ]

  fileprivate class _StorageClass {
    var _session: String = String()
    var _queryParams: Google_Cloud_Dialogflow_V2_QueryParameters? = nil
    var _queryInput: Google_Cloud_Dialogflow_V2_QueryInput? = nil
    var _outputAudioConfig: Google_Cloud_Dialogflow_V2_OutputAudioConfig? = nil
    var _outputAudioConfigMask: SwiftProtobuf.Google_Protobuf_FieldMask? = nil
    var _inputAudio: Data = Data()

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _session = source._session
      _queryParams = source._queryParams
      _queryInput = source._queryInput
      _outputAudioConfig = source._outputAudioConfig
      _outputAudioConfigMask = source._outputAudioConfigMask
      _inputAudio = source._inputAudio
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._session) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._queryParams) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._queryInput) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._outputAudioConfig) }()
        case 5: try { try decoder.decodeSingularBytesField(value: &_storage._inputAudio) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._outputAudioConfigMask) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._session.isEmpty {
        try visitor.visitSingularStringField(value: _storage._session, fieldNumber: 1)
      }
      if let v = _storage._queryParams {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if let v = _storage._queryInput {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }
      if let v = _storage._outputAudioConfig {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }
      if !_storage._inputAudio.isEmpty {
        try visitor.visitSingularBytesField(value: _storage._inputAudio, fieldNumber: 5)
      }
      if let v = _storage._outputAudioConfigMask {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_DetectIntentRequest, rhs: Google_Cloud_Dialogflow_V2_DetectIntentRequest) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._session != rhs_storage._session {return false}
        if _storage._queryParams != rhs_storage._queryParams {return false}
        if _storage._queryInput != rhs_storage._queryInput {return false}
        if _storage._outputAudioConfig != rhs_storage._outputAudioConfig {return false}
        if _storage._outputAudioConfigMask != rhs_storage._outputAudioConfigMask {return false}
        if _storage._inputAudio != rhs_storage._inputAudio {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_DetectIntentResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DetectIntentResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "response_id"),
    2: .standard(proto: "query_result"),
    3: .standard(proto: "webhook_status"),
    4: .standard(proto: "output_audio"),
    6: .standard(proto: "output_audio_config"),
  ]

  fileprivate class _StorageClass {
    var _responseID: String = String()
    var _queryResult: Google_Cloud_Dialogflow_V2_QueryResult? = nil
    var _webhookStatus: Google_Rpc_Status? = nil
    var _outputAudio: Data = Data()
    var _outputAudioConfig: Google_Cloud_Dialogflow_V2_OutputAudioConfig? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _responseID = source._responseID
      _queryResult = source._queryResult
      _webhookStatus = source._webhookStatus
      _outputAudio = source._outputAudio
      _outputAudioConfig = source._outputAudioConfig
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._responseID) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._queryResult) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._webhookStatus) }()
        case 4: try { try decoder.decodeSingularBytesField(value: &_storage._outputAudio) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._outputAudioConfig) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._responseID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._responseID, fieldNumber: 1)
      }
      if let v = _storage._queryResult {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if let v = _storage._webhookStatus {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }
      if !_storage._outputAudio.isEmpty {
        try visitor.visitSingularBytesField(value: _storage._outputAudio, fieldNumber: 4)
      }
      if let v = _storage._outputAudioConfig {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_DetectIntentResponse, rhs: Google_Cloud_Dialogflow_V2_DetectIntentResponse) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._responseID != rhs_storage._responseID {return false}
        if _storage._queryResult != rhs_storage._queryResult {return false}
        if _storage._webhookStatus != rhs_storage._webhookStatus {return false}
        if _storage._outputAudio != rhs_storage._outputAudio {return false}
        if _storage._outputAudioConfig != rhs_storage._outputAudioConfig {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_QueryParameters: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".QueryParameters"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "time_zone"),
    2: .standard(proto: "geo_location"),
    3: .same(proto: "contexts"),
    4: .standard(proto: "reset_contexts"),
    5: .standard(proto: "session_entity_types"),
    6: .same(proto: "payload"),
    10: .standard(proto: "sentiment_analysis_request_config"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.timeZone) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._geoLocation) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.contexts) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.resetContexts) }()
      case 5: try { try decoder.decodeRepeatedMessageField(value: &self.sessionEntityTypes) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._payload) }()
      case 10: try { try decoder.decodeSingularMessageField(value: &self._sentimentAnalysisRequestConfig) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.timeZone.isEmpty {
      try visitor.visitSingularStringField(value: self.timeZone, fieldNumber: 1)
    }
    if let v = self._geoLocation {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if !self.contexts.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.contexts, fieldNumber: 3)
    }
    if self.resetContexts != false {
      try visitor.visitSingularBoolField(value: self.resetContexts, fieldNumber: 4)
    }
    if !self.sessionEntityTypes.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.sessionEntityTypes, fieldNumber: 5)
    }
    if let v = self._payload {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }
    if let v = self._sentimentAnalysisRequestConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_QueryParameters, rhs: Google_Cloud_Dialogflow_V2_QueryParameters) -> Bool {
    if lhs.timeZone != rhs.timeZone {return false}
    if lhs._geoLocation != rhs._geoLocation {return false}
    if lhs.contexts != rhs.contexts {return false}
    if lhs.resetContexts != rhs.resetContexts {return false}
    if lhs.sessionEntityTypes != rhs.sessionEntityTypes {return false}
    if lhs._payload != rhs._payload {return false}
    if lhs._sentimentAnalysisRequestConfig != rhs._sentimentAnalysisRequestConfig {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_QueryInput: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".QueryInput"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "audio_config"),
    2: .same(proto: "text"),
    3: .same(proto: "event"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Google_Cloud_Dialogflow_V2_InputAudioConfig?
        if let current = self.input {
          try decoder.handleConflictingOneOf()
          if case .audioConfig(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.input = .audioConfig(v)}
      }()
      case 2: try {
        var v: Google_Cloud_Dialogflow_V2_TextInput?
        if let current = self.input {
          try decoder.handleConflictingOneOf()
          if case .text(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.input = .text(v)}
      }()
      case 3: try {
        var v: Google_Cloud_Dialogflow_V2_EventInput?
        if let current = self.input {
          try decoder.handleConflictingOneOf()
          if case .event(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.input = .event(v)}
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.input {
    case .audioConfig?: try {
      guard case .audioConfig(let v)? = self.input else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .text?: try {
      guard case .text(let v)? = self.input else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .event?: try {
      guard case .event(let v)? = self.input else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_QueryInput, rhs: Google_Cloud_Dialogflow_V2_QueryInput) -> Bool {
    if lhs.input != rhs.input {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_QueryResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".QueryResult"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "query_text"),
    15: .standard(proto: "language_code"),
    2: .standard(proto: "speech_recognition_confidence"),
    3: .same(proto: "action"),
    4: .same(proto: "parameters"),
    5: .standard(proto: "all_required_params_present"),
    6: .standard(proto: "fulfillment_text"),
    7: .standard(proto: "fulfillment_messages"),
    8: .standard(proto: "webhook_source"),
    9: .standard(proto: "webhook_payload"),
    10: .standard(proto: "output_contexts"),
    11: .same(proto: "intent"),
    12: .standard(proto: "intent_detection_confidence"),
    14: .standard(proto: "diagnostic_info"),
    17: .standard(proto: "sentiment_analysis_result"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.queryText) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.speechRecognitionConfidence) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.action) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._parameters) }()
      case 5: try { try decoder.decodeSingularBoolField(value: &self.allRequiredParamsPresent) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.fulfillmentText) }()
      case 7: try { try decoder.decodeRepeatedMessageField(value: &self.fulfillmentMessages) }()
      case 8: try { try decoder.decodeSingularStringField(value: &self.webhookSource) }()
      case 9: try { try decoder.decodeSingularMessageField(value: &self._webhookPayload) }()
      case 10: try { try decoder.decodeRepeatedMessageField(value: &self.outputContexts) }()
      case 11: try { try decoder.decodeSingularMessageField(value: &self._intent) }()
      case 12: try { try decoder.decodeSingularFloatField(value: &self.intentDetectionConfidence) }()
      case 14: try { try decoder.decodeSingularMessageField(value: &self._diagnosticInfo) }()
      case 15: try { try decoder.decodeSingularStringField(value: &self.languageCode) }()
      case 17: try { try decoder.decodeSingularMessageField(value: &self._sentimentAnalysisResult) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.queryText.isEmpty {
      try visitor.visitSingularStringField(value: self.queryText, fieldNumber: 1)
    }
    if self.speechRecognitionConfidence != 0 {
      try visitor.visitSingularFloatField(value: self.speechRecognitionConfidence, fieldNumber: 2)
    }
    if !self.action.isEmpty {
      try visitor.visitSingularStringField(value: self.action, fieldNumber: 3)
    }
    if let v = self._parameters {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    if self.allRequiredParamsPresent != false {
      try visitor.visitSingularBoolField(value: self.allRequiredParamsPresent, fieldNumber: 5)
    }
    if !self.fulfillmentText.isEmpty {
      try visitor.visitSingularStringField(value: self.fulfillmentText, fieldNumber: 6)
    }
    if !self.fulfillmentMessages.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.fulfillmentMessages, fieldNumber: 7)
    }
    if !self.webhookSource.isEmpty {
      try visitor.visitSingularStringField(value: self.webhookSource, fieldNumber: 8)
    }
    if let v = self._webhookPayload {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
    }
    if !self.outputContexts.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.outputContexts, fieldNumber: 10)
    }
    if let v = self._intent {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
    }
    if self.intentDetectionConfidence != 0 {
      try visitor.visitSingularFloatField(value: self.intentDetectionConfidence, fieldNumber: 12)
    }
    if let v = self._diagnosticInfo {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
    }
    if !self.languageCode.isEmpty {
      try visitor.visitSingularStringField(value: self.languageCode, fieldNumber: 15)
    }
    if let v = self._sentimentAnalysisResult {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_QueryResult, rhs: Google_Cloud_Dialogflow_V2_QueryResult) -> Bool {
    if lhs.queryText != rhs.queryText {return false}
    if lhs.languageCode != rhs.languageCode {return false}
    if lhs.speechRecognitionConfidence != rhs.speechRecognitionConfidence {return false}
    if lhs.action != rhs.action {return false}
    if lhs._parameters != rhs._parameters {return false}
    if lhs.allRequiredParamsPresent != rhs.allRequiredParamsPresent {return false}
    if lhs.fulfillmentText != rhs.fulfillmentText {return false}
    if lhs.fulfillmentMessages != rhs.fulfillmentMessages {return false}
    if lhs.webhookSource != rhs.webhookSource {return false}
    if lhs._webhookPayload != rhs._webhookPayload {return false}
    if lhs.outputContexts != rhs.outputContexts {return false}
    if lhs._intent != rhs._intent {return false}
    if lhs.intentDetectionConfidence != rhs.intentDetectionConfidence {return false}
    if lhs._diagnosticInfo != rhs._diagnosticInfo {return false}
    if lhs._sentimentAnalysisResult != rhs._sentimentAnalysisResult {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_StreamingDetectIntentRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamingDetectIntentRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "session"),
    2: .standard(proto: "query_params"),
    3: .standard(proto: "query_input"),
    4: .standard(proto: "single_utterance"),
    5: .standard(proto: "output_audio_config"),
    7: .standard(proto: "output_audio_config_mask"),
    6: .standard(proto: "input_audio"),
  ]

  fileprivate class _StorageClass {
    var _session: String = String()
    var _queryParams: Google_Cloud_Dialogflow_V2_QueryParameters? = nil
    var _queryInput: Google_Cloud_Dialogflow_V2_QueryInput? = nil
    var _singleUtterance: Bool = false
    var _outputAudioConfig: Google_Cloud_Dialogflow_V2_OutputAudioConfig? = nil
    var _outputAudioConfigMask: SwiftProtobuf.Google_Protobuf_FieldMask? = nil
    var _inputAudio: Data = Data()

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _session = source._session
      _queryParams = source._queryParams
      _queryInput = source._queryInput
      _singleUtterance = source._singleUtterance
      _outputAudioConfig = source._outputAudioConfig
      _outputAudioConfigMask = source._outputAudioConfigMask
      _inputAudio = source._inputAudio
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._session) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._queryParams) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._queryInput) }()
        case 4: try { try decoder.decodeSingularBoolField(value: &_storage._singleUtterance) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._outputAudioConfig) }()
        case 6: try { try decoder.decodeSingularBytesField(value: &_storage._inputAudio) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._outputAudioConfigMask) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._session.isEmpty {
        try visitor.visitSingularStringField(value: _storage._session, fieldNumber: 1)
      }
      if let v = _storage._queryParams {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if let v = _storage._queryInput {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }
      if _storage._singleUtterance != false {
        try visitor.visitSingularBoolField(value: _storage._singleUtterance, fieldNumber: 4)
      }
      if let v = _storage._outputAudioConfig {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      }
      if !_storage._inputAudio.isEmpty {
        try visitor.visitSingularBytesField(value: _storage._inputAudio, fieldNumber: 6)
      }
      if let v = _storage._outputAudioConfigMask {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_StreamingDetectIntentRequest, rhs: Google_Cloud_Dialogflow_V2_StreamingDetectIntentRequest) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._session != rhs_storage._session {return false}
        if _storage._queryParams != rhs_storage._queryParams {return false}
        if _storage._queryInput != rhs_storage._queryInput {return false}
        if _storage._singleUtterance != rhs_storage._singleUtterance {return false}
        if _storage._outputAudioConfig != rhs_storage._outputAudioConfig {return false}
        if _storage._outputAudioConfigMask != rhs_storage._outputAudioConfigMask {return false}
        if _storage._inputAudio != rhs_storage._inputAudio {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_StreamingDetectIntentResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamingDetectIntentResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "response_id"),
    2: .standard(proto: "recognition_result"),
    3: .standard(proto: "query_result"),
    4: .standard(proto: "webhook_status"),
    5: .standard(proto: "output_audio"),
    6: .standard(proto: "output_audio_config"),
  ]

  fileprivate class _StorageClass {
    var _responseID: String = String()
    var _recognitionResult: Google_Cloud_Dialogflow_V2_StreamingRecognitionResult? = nil
    var _queryResult: Google_Cloud_Dialogflow_V2_QueryResult? = nil
    var _webhookStatus: Google_Rpc_Status? = nil
    var _outputAudio: Data = Data()
    var _outputAudioConfig: Google_Cloud_Dialogflow_V2_OutputAudioConfig? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _responseID = source._responseID
      _recognitionResult = source._recognitionResult
      _queryResult = source._queryResult
      _webhookStatus = source._webhookStatus
      _outputAudio = source._outputAudio
      _outputAudioConfig = source._outputAudioConfig
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._responseID) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._recognitionResult) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._queryResult) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._webhookStatus) }()
        case 5: try { try decoder.decodeSingularBytesField(value: &_storage._outputAudio) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._outputAudioConfig) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._responseID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._responseID, fieldNumber: 1)
      }
      if let v = _storage._recognitionResult {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if let v = _storage._queryResult {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }
      if let v = _storage._webhookStatus {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }
      if !_storage._outputAudio.isEmpty {
        try visitor.visitSingularBytesField(value: _storage._outputAudio, fieldNumber: 5)
      }
      if let v = _storage._outputAudioConfig {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_StreamingDetectIntentResponse, rhs: Google_Cloud_Dialogflow_V2_StreamingDetectIntentResponse) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._responseID != rhs_storage._responseID {return false}
        if _storage._recognitionResult != rhs_storage._recognitionResult {return false}
        if _storage._queryResult != rhs_storage._queryResult {return false}
        if _storage._webhookStatus != rhs_storage._webhookStatus {return false}
        if _storage._outputAudio != rhs_storage._outputAudio {return false}
        if _storage._outputAudioConfig != rhs_storage._outputAudioConfig {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_StreamingRecognitionResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamingRecognitionResult"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "message_type"),
    2: .same(proto: "transcript"),
    3: .standard(proto: "is_final"),
    4: .same(proto: "confidence"),
    7: .standard(proto: "speech_word_info"),
    8: .standard(proto: "speech_end_offset"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.messageType) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.transcript) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.isFinal) }()
      case 4: try { try decoder.decodeSingularFloatField(value: &self.confidence) }()
      case 7: try { try decoder.decodeRepeatedMessageField(value: &self.speechWordInfo) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._speechEndOffset) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.messageType != .unspecified {
      try visitor.visitSingularEnumField(value: self.messageType, fieldNumber: 1)
    }
    if !self.transcript.isEmpty {
      try visitor.visitSingularStringField(value: self.transcript, fieldNumber: 2)
    }
    if self.isFinal != false {
      try visitor.visitSingularBoolField(value: self.isFinal, fieldNumber: 3)
    }
    if self.confidence != 0 {
      try visitor.visitSingularFloatField(value: self.confidence, fieldNumber: 4)
    }
    if !self.speechWordInfo.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.speechWordInfo, fieldNumber: 7)
    }
    if let v = self._speechEndOffset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_StreamingRecognitionResult, rhs: Google_Cloud_Dialogflow_V2_StreamingRecognitionResult) -> Bool {
    if lhs.messageType != rhs.messageType {return false}
    if lhs.transcript != rhs.transcript {return false}
    if lhs.isFinal != rhs.isFinal {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.speechWordInfo != rhs.speechWordInfo {return false}
    if lhs._speechEndOffset != rhs._speechEndOffset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_StreamingRecognitionResult.MessageType: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "MESSAGE_TYPE_UNSPECIFIED"),
    1: .same(proto: "TRANSCRIPT"),
    2: .same(proto: "END_OF_SINGLE_UTTERANCE"),
  ]
}

extension Google_Cloud_Dialogflow_V2_TextInput: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TextInput"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "text"),
    2: .standard(proto: "language_code"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.text) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.languageCode) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.text.isEmpty {
      try visitor.visitSingularStringField(value: self.text, fieldNumber: 1)
    }
    if !self.languageCode.isEmpty {
      try visitor.visitSingularStringField(value: self.languageCode, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_TextInput, rhs: Google_Cloud_Dialogflow_V2_TextInput) -> Bool {
    if lhs.text != rhs.text {return false}
    if lhs.languageCode != rhs.languageCode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_EventInput: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".EventInput"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "parameters"),
    3: .standard(proto: "language_code"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._parameters) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.languageCode) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if let v = self._parameters {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if !self.languageCode.isEmpty {
      try visitor.visitSingularStringField(value: self.languageCode, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_EventInput, rhs: Google_Cloud_Dialogflow_V2_EventInput) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs._parameters != rhs._parameters {return false}
    if lhs.languageCode != rhs.languageCode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_SentimentAnalysisRequestConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SentimentAnalysisRequestConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "analyze_query_text_sentiment"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.analyzeQueryTextSentiment) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.analyzeQueryTextSentiment != false {
      try visitor.visitSingularBoolField(value: self.analyzeQueryTextSentiment, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_SentimentAnalysisRequestConfig, rhs: Google_Cloud_Dialogflow_V2_SentimentAnalysisRequestConfig) -> Bool {
    if lhs.analyzeQueryTextSentiment != rhs.analyzeQueryTextSentiment {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_SentimentAnalysisResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SentimentAnalysisResult"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "query_text_sentiment"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._queryTextSentiment) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._queryTextSentiment {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_SentimentAnalysisResult, rhs: Google_Cloud_Dialogflow_V2_SentimentAnalysisResult) -> Bool {
    if lhs._queryTextSentiment != rhs._queryTextSentiment {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Dialogflow_V2_Sentiment: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Sentiment"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "score"),
    2: .same(proto: "magnitude"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularFloatField(value: &self.score) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.magnitude) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.score != 0 {
      try visitor.visitSingularFloatField(value: self.score, fieldNumber: 1)
    }
    if self.magnitude != 0 {
      try visitor.visitSingularFloatField(value: self.magnitude, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Dialogflow_V2_Sentiment, rhs: Google_Cloud_Dialogflow_V2_Sentiment) -> Bool {
    if lhs.score != rhs.score {return false}
    if lhs.magnitude != rhs.magnitude {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
