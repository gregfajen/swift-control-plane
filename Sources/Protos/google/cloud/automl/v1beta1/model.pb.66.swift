// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/automl/v1beta1/model.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// API proto representing a trained machine learning model.
public struct Google_Cloud_Automl_V1beta1_Model {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required.
  /// The model metadata that is specific to the problem type.
  /// Must match the metadata type of the dataset used to train the model.
  public var modelMetadata: OneOf_ModelMetadata? {
    get {return _storage._modelMetadata}
    set {_uniqueStorage()._modelMetadata = newValue}
  }

  /// Metadata for translation models.
  public var translationModelMetadata: Google_Cloud_Automl_V1beta1_TranslationModelMetadata {
    get {
      if case .translationModelMetadata(let v)? = _storage._modelMetadata {return v}
      return Google_Cloud_Automl_V1beta1_TranslationModelMetadata()
    }
    set {_uniqueStorage()._modelMetadata = .translationModelMetadata(newValue)}
  }

  /// Metadata for image classification models.
  public var imageClassificationModelMetadata: Google_Cloud_Automl_V1beta1_ImageClassificationModelMetadata {
    get {
      if case .imageClassificationModelMetadata(let v)? = _storage._modelMetadata {return v}
      return Google_Cloud_Automl_V1beta1_ImageClassificationModelMetadata()
    }
    set {_uniqueStorage()._modelMetadata = .imageClassificationModelMetadata(newValue)}
  }

  /// Metadata for text classification models.
  public var textClassificationModelMetadata: Google_Cloud_Automl_V1beta1_TextClassificationModelMetadata {
    get {
      if case .textClassificationModelMetadata(let v)? = _storage._modelMetadata {return v}
      return Google_Cloud_Automl_V1beta1_TextClassificationModelMetadata()
    }
    set {_uniqueStorage()._modelMetadata = .textClassificationModelMetadata(newValue)}
  }

  /// Metadata for image object detection models.
  public var imageObjectDetectionModelMetadata: Google_Cloud_Automl_V1beta1_ImageObjectDetectionModelMetadata {
    get {
      if case .imageObjectDetectionModelMetadata(let v)? = _storage._modelMetadata {return v}
      return Google_Cloud_Automl_V1beta1_ImageObjectDetectionModelMetadata()
    }
    set {_uniqueStorage()._modelMetadata = .imageObjectDetectionModelMetadata(newValue)}
  }

  /// Metadata for video classification models.
  public var videoClassificationModelMetadata: Google_Cloud_Automl_V1beta1_VideoClassificationModelMetadata {
    get {
      if case .videoClassificationModelMetadata(let v)? = _storage._modelMetadata {return v}
      return Google_Cloud_Automl_V1beta1_VideoClassificationModelMetadata()
    }
    set {_uniqueStorage()._modelMetadata = .videoClassificationModelMetadata(newValue)}
  }

  /// Metadata for video object tracking models.
  public var videoObjectTrackingModelMetadata: Google_Cloud_Automl_V1beta1_VideoObjectTrackingModelMetadata {
    get {
      if case .videoObjectTrackingModelMetadata(let v)? = _storage._modelMetadata {return v}
      return Google_Cloud_Automl_V1beta1_VideoObjectTrackingModelMetadata()
    }
    set {_uniqueStorage()._modelMetadata = .videoObjectTrackingModelMetadata(newValue)}
  }

  /// Metadata for text extraction models.
  public var textExtractionModelMetadata: Google_Cloud_Automl_V1beta1_TextExtractionModelMetadata {
    get {
      if case .textExtractionModelMetadata(let v)? = _storage._modelMetadata {return v}
      return Google_Cloud_Automl_V1beta1_TextExtractionModelMetadata()
    }
    set {_uniqueStorage()._modelMetadata = .textExtractionModelMetadata(newValue)}
  }

  /// Metadata for Tables models.
  public var tablesModelMetadata: Google_Cloud_Automl_V1beta1_TablesModelMetadata {
    get {
      if case .tablesModelMetadata(let v)? = _storage._modelMetadata {return v}
      return Google_Cloud_Automl_V1beta1_TablesModelMetadata()
    }
    set {_uniqueStorage()._modelMetadata = .tablesModelMetadata(newValue)}
  }

  /// Metadata for text sentiment models.
  public var textSentimentModelMetadata: Google_Cloud_Automl_V1beta1_TextSentimentModelMetadata {
    get {
      if case .textSentimentModelMetadata(let v)? = _storage._modelMetadata {return v}
      return Google_Cloud_Automl_V1beta1_TextSentimentModelMetadata()
    }
    set {_uniqueStorage()._modelMetadata = .textSentimentModelMetadata(newValue)}
  }

  /// Output only. Resource name of the model.
  /// Format: `projects/{project_id}/locations/{location_id}/models/{model_id}`
  public var name: String {
    get {return _storage._name}
    set {_uniqueStorage()._name = newValue}
  }

  /// Required. The name of the model to show in the interface. The name can be
  /// up to 32 characters long and can consist only of ASCII Latin letters A-Z
  /// and a-z, underscores
  /// (_), and ASCII digits 0-9. It must start with a letter.
  public var displayName: String {
    get {return _storage._displayName}
    set {_uniqueStorage()._displayName = newValue}
  }

  /// Required. The resource ID of the dataset used to create the model. The dataset must
  /// come from the same ancestor project and location.
  public var datasetID: String {
    get {return _storage._datasetID}
    set {_uniqueStorage()._datasetID = newValue}
  }

  /// Output only. Timestamp when the model training finished  and can be used for prediction.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return _storage._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {_uniqueStorage()._createTime = nil}

  /// Output only. Timestamp when this model was last updated.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return _storage._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {_uniqueStorage()._updateTime = nil}

  /// Output only. Deployment state of the model. A model can only serve
  /// prediction requests after it gets deployed.
  public var deploymentState: Google_Cloud_Automl_V1beta1_Model.DeploymentState {
    get {return _storage._deploymentState}
    set {_uniqueStorage()._deploymentState = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Required.
  /// The model metadata that is specific to the problem type.
  /// Must match the metadata type of the dataset used to train the model.
  public enum OneOf_ModelMetadata: Equatable {
    /// Metadata for translation models.
    case translationModelMetadata(Google_Cloud_Automl_V1beta1_TranslationModelMetadata)
    /// Metadata for image classification models.
    case imageClassificationModelMetadata(Google_Cloud_Automl_V1beta1_ImageClassificationModelMetadata)
    /// Metadata for text classification models.
    case textClassificationModelMetadata(Google_Cloud_Automl_V1beta1_TextClassificationModelMetadata)
    /// Metadata for image object detection models.
    case imageObjectDetectionModelMetadata(Google_Cloud_Automl_V1beta1_ImageObjectDetectionModelMetadata)
    /// Metadata for video classification models.
    case videoClassificationModelMetadata(Google_Cloud_Automl_V1beta1_VideoClassificationModelMetadata)
    /// Metadata for video object tracking models.
    case videoObjectTrackingModelMetadata(Google_Cloud_Automl_V1beta1_VideoObjectTrackingModelMetadata)
    /// Metadata for text extraction models.
    case textExtractionModelMetadata(Google_Cloud_Automl_V1beta1_TextExtractionModelMetadata)
    /// Metadata for Tables models.
    case tablesModelMetadata(Google_Cloud_Automl_V1beta1_TablesModelMetadata)
    /// Metadata for text sentiment models.
    case textSentimentModelMetadata(Google_Cloud_Automl_V1beta1_TextSentimentModelMetadata)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Automl_V1beta1_Model.OneOf_ModelMetadata, rhs: Google_Cloud_Automl_V1beta1_Model.OneOf_ModelMetadata) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.translationModelMetadata, .translationModelMetadata): return {
        guard case .translationModelMetadata(let l) = lhs, case .translationModelMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.imageClassificationModelMetadata, .imageClassificationModelMetadata): return {
        guard case .imageClassificationModelMetadata(let l) = lhs, case .imageClassificationModelMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.textClassificationModelMetadata, .textClassificationModelMetadata): return {
        guard case .textClassificationModelMetadata(let l) = lhs, case .textClassificationModelMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.imageObjectDetectionModelMetadata, .imageObjectDetectionModelMetadata): return {
        guard case .imageObjectDetectionModelMetadata(let l) = lhs, case .imageObjectDetectionModelMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.videoClassificationModelMetadata, .videoClassificationModelMetadata): return {
        guard case .videoClassificationModelMetadata(let l) = lhs, case .videoClassificationModelMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.videoObjectTrackingModelMetadata, .videoObjectTrackingModelMetadata): return {
        guard case .videoObjectTrackingModelMetadata(let l) = lhs, case .videoObjectTrackingModelMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.textExtractionModelMetadata, .textExtractionModelMetadata): return {
        guard case .textExtractionModelMetadata(let l) = lhs, case .textExtractionModelMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.tablesModelMetadata, .tablesModelMetadata): return {
        guard case .tablesModelMetadata(let l) = lhs, case .tablesModelMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.textSentimentModelMetadata, .textSentimentModelMetadata): return {
        guard case .textSentimentModelMetadata(let l) = lhs, case .textSentimentModelMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  /// Deployment state of the model.
  public enum DeploymentState: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Should not be used, an un-set enum has this value by default.
    case unspecified // = 0

    /// Model is deployed.
    case deployed // = 1

    /// Model is not deployed.
    case undeployed // = 2
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .deployed
      case 2: self = .undeployed
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .deployed: return 1
      case .undeployed: return 2
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

#if swift(>=4.2)

extension Google_Cloud_Automl_V1beta1_Model.DeploymentState: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Automl_V1beta1_Model.DeploymentState] = [
    .unspecified,
    .deployed,
    .undeployed,
  ]
}

#endif  // swift(>=4.2)

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.automl.v1beta1"

extension Google_Cloud_Automl_V1beta1_Model: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Model"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    15: .standard(proto: "translation_model_metadata"),
    13: .standard(proto: "image_classification_model_metadata"),
    14: .standard(proto: "text_classification_model_metadata"),
    20: .standard(proto: "image_object_detection_model_metadata"),
    23: .standard(proto: "video_classification_model_metadata"),
    21: .standard(proto: "video_object_tracking_model_metadata"),
    19: .standard(proto: "text_extraction_model_metadata"),
    24: .standard(proto: "tables_model_metadata"),
    22: .standard(proto: "text_sentiment_model_metadata"),
    1: .same(proto: "name"),
    2: .standard(proto: "display_name"),
    3: .standard(proto: "dataset_id"),
    7: .standard(proto: "create_time"),
    11: .standard(proto: "update_time"),
    8: .standard(proto: "deployment_state"),
  ]

  fileprivate class _StorageClass {
    var _modelMetadata: Google_Cloud_Automl_V1beta1_Model.OneOf_ModelMetadata?
    var _name: String = String()
    var _displayName: String = String()
    var _datasetID: String = String()
    var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _deploymentState: Google_Cloud_Automl_V1beta1_Model.DeploymentState = .unspecified

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _modelMetadata = source._modelMetadata
      _name = source._name
      _displayName = source._displayName
      _datasetID = source._datasetID
      _createTime = source._createTime
      _updateTime = source._updateTime
      _deploymentState = source._deploymentState
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._name) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._displayName) }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._datasetID) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._createTime) }()
        case 8: try { try decoder.decodeSingularEnumField(value: &_storage._deploymentState) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._updateTime) }()
        case 13: try {
          var v: Google_Cloud_Automl_V1beta1_ImageClassificationModelMetadata?
          if let current = _storage._modelMetadata {
            try decoder.handleConflictingOneOf()
            if case .imageClassificationModelMetadata(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._modelMetadata = .imageClassificationModelMetadata(v)}
        }()
        case 14: try {
          var v: Google_Cloud_Automl_V1beta1_TextClassificationModelMetadata?
          if let current = _storage._modelMetadata {
            try decoder.handleConflictingOneOf()
            if case .textClassificationModelMetadata(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._modelMetadata = .textClassificationModelMetadata(v)}
        }()
        case 15: try {
          var v: Google_Cloud_Automl_V1beta1_TranslationModelMetadata?
          if let current = _storage._modelMetadata {
            try decoder.handleConflictingOneOf()
            if case .translationModelMetadata(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._modelMetadata = .translationModelMetadata(v)}
        }()
        case 19: try {
          var v: Google_Cloud_Automl_V1beta1_TextExtractionModelMetadata?
          if let current = _storage._modelMetadata {
            try decoder.handleConflictingOneOf()
            if case .textExtractionModelMetadata(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._modelMetadata = .textExtractionModelMetadata(v)}
        }()
        case 20: try {
          var v: Google_Cloud_Automl_V1beta1_ImageObjectDetectionModelMetadata?
          if let current = _storage._modelMetadata {
            try decoder.handleConflictingOneOf()
            if case .imageObjectDetectionModelMetadata(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._modelMetadata = .imageObjectDetectionModelMetadata(v)}
        }()
        case 21: try {
          var v: Google_Cloud_Automl_V1beta1_VideoObjectTrackingModelMetadata?
          if let current = _storage._modelMetadata {
            try decoder.handleConflictingOneOf()
            if case .videoObjectTrackingModelMetadata(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._modelMetadata = .videoObjectTrackingModelMetadata(v)}
        }()
        case 22: try {
          var v: Google_Cloud_Automl_V1beta1_TextSentimentModelMetadata?
          if let current = _storage._modelMetadata {
            try decoder.handleConflictingOneOf()
            if case .textSentimentModelMetadata(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._modelMetadata = .textSentimentModelMetadata(v)}
        }()
        case 23: try {
          var v: Google_Cloud_Automl_V1beta1_VideoClassificationModelMetadata?
          if let current = _storage._modelMetadata {
            try decoder.handleConflictingOneOf()
            if case .videoClassificationModelMetadata(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._modelMetadata = .videoClassificationModelMetadata(v)}
        }()
        case 24: try {
          var v: Google_Cloud_Automl_V1beta1_TablesModelMetadata?
          if let current = _storage._modelMetadata {
            try decoder.handleConflictingOneOf()
            if case .tablesModelMetadata(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._modelMetadata = .tablesModelMetadata(v)}
        }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._name.isEmpty {
        try visitor.visitSingularStringField(value: _storage._name, fieldNumber: 1)
      }
      if !_storage._displayName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._displayName, fieldNumber: 2)
      }
      if !_storage._datasetID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._datasetID, fieldNumber: 3)
      }
      if let v = _storage._createTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      }
      if _storage._deploymentState != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._deploymentState, fieldNumber: 8)
      }
      if let v = _storage._updateTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      }
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch _storage._modelMetadata {
      case .imageClassificationModelMetadata?: try {
        guard case .imageClassificationModelMetadata(let v)? = _storage._modelMetadata else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
      }()
      case .textClassificationModelMetadata?: try {
        guard case .textClassificationModelMetadata(let v)? = _storage._modelMetadata else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      }()
      case .translationModelMetadata?: try {
        guard case .translationModelMetadata(let v)? = _storage._modelMetadata else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 15)
      }()
      case .textExtractionModelMetadata?: try {
        guard case .textExtractionModelMetadata(let v)? = _storage._modelMetadata else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
      }()
      case .imageObjectDetectionModelMetadata?: try {
        guard case .imageObjectDetectionModelMetadata(let v)? = _storage._modelMetadata else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
      }()
      case .videoObjectTrackingModelMetadata?: try {
        guard case .videoObjectTrackingModelMetadata(let v)? = _storage._modelMetadata else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
      }()
      case .textSentimentModelMetadata?: try {
        guard case .textSentimentModelMetadata(let v)? = _storage._modelMetadata else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 22)
      }()
      case .videoClassificationModelMetadata?: try {
        guard case .videoClassificationModelMetadata(let v)? = _storage._modelMetadata else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 23)
      }()
      case .tablesModelMetadata?: try {
        guard case .tablesModelMetadata(let v)? = _storage._modelMetadata else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 24)
      }()
      case nil: break
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Automl_V1beta1_Model, rhs: Google_Cloud_Automl_V1beta1_Model) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._modelMetadata != rhs_storage._modelMetadata {return false}
        if _storage._name != rhs_storage._name {return false}
        if _storage._displayName != rhs_storage._displayName {return false}
        if _storage._datasetID != rhs_storage._datasetID {return false}
        if _storage._createTime != rhs_storage._createTime {return false}
        if _storage._updateTime != rhs_storage._updateTime {return false}
        if _storage._deploymentState != rhs_storage._deploymentState {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Automl_V1beta1_Model.DeploymentState: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DEPLOYMENT_STATE_UNSPECIFIED"),
    1: .same(proto: "DEPLOYED"),
    2: .same(proto: "UNDEPLOYED"),
  ]
}
