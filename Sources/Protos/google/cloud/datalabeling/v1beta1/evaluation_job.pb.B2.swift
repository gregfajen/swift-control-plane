// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/datalabeling/v1beta1/evaluation_job.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2019 Google LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Defines an evaluation job that runs periodically to generate
/// [Evaluations][google.cloud.datalabeling.v1beta1.Evaluation]. [Creating an evaluation
/// job](/ml-engine/docs/continuous-evaluation/create-job) is the starting point
/// for using continuous evaluation.
public struct Google_Cloud_Datalabeling_V1beta1_EvaluationJob {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. After you create a job, Data Labeling Service assigns a name
  /// to the job with the following format:
  ///
  /// "projects/<var>{project_id}</var>/evaluationJobs/<var>{evaluation_job_id}</var>"
  public var name: String = String()

  /// Required. Description of the job. The description can be up to 25,000
  /// characters long.
  public var description_p: String = String()

  /// Output only. Describes the current state of the job.
  public var state: Google_Cloud_Datalabeling_V1beta1_EvaluationJob.State = .unspecified

  /// Required. Describes the interval at which the job runs. This interval must
  /// be at least 1 day, and it is rounded to the nearest day. For example, if
  /// you specify a 50-hour interval, the job runs every 2 days.
  ///
  /// You can provide the schedule in
  /// [crontab format](/scheduler/docs/configuring/cron-job-schedules) or in an
  /// [English-like
  /// format](/appengine/docs/standard/python/config/cronref#schedule_format).
  ///
  /// Regardless of what you specify, the job will run at 10:00 AM UTC. Only the
  /// interval from this schedule is used, not the specific time of day.
  public var schedule: String = String()

  /// Required. The [AI Platform Prediction model
  /// version](/ml-engine/docs/prediction-overview) to be evaluated. Prediction
  /// input and output is sampled from this model version. When creating an
  /// evaluation job, specify the model version in the following format:
  ///
  /// "projects/<var>{project_id}</var>/models/<var>{model_name}</var>/versions/<var>{version_name}</var>"
  ///
  /// There can only be one evaluation job per model version.
  public var modelVersion: String = String()

  /// Required. Configuration details for the evaluation job.
  public var evaluationJobConfig: Google_Cloud_Datalabeling_V1beta1_EvaluationJobConfig {
    get {return _evaluationJobConfig ?? Google_Cloud_Datalabeling_V1beta1_EvaluationJobConfig()}
    set {_evaluationJobConfig = newValue}
  }
  /// Returns true if `evaluationJobConfig` has been explicitly set.
  public var hasEvaluationJobConfig: Bool {return self._evaluationJobConfig != nil}
  /// Clears the value of `evaluationJobConfig`. Subsequent reads from it will return its default value.
  public mutating func clearEvaluationJobConfig() {self._evaluationJobConfig = nil}

  /// Required. Name of the [AnnotationSpecSet][google.cloud.datalabeling.v1beta1.AnnotationSpecSet] describing all the
  /// labels that your machine learning model outputs. You must create this
  /// resource before you create an evaluation job and provide its name in the
  /// following format:
  ///
  /// "projects/<var>{project_id}</var>/annotationSpecSets/<var>{annotation_spec_set_id}</var>"
  public var annotationSpecSet: String = String()

  /// Required. Whether you want Data Labeling Service to provide ground truth
  /// labels for prediction input. If you want the service to assign human
  /// labelers to annotate your data, set this to `true`. If you want to provide
  /// your own ground truth labels in the evaluation job's BigQuery table, set
  /// this to `false`.
  public var labelMissingGroundTruth: Bool = false

  /// Output only. Every time the evaluation job runs and an error occurs, the
  /// failed attempt is appended to this array.
  public var attempts: [Google_Cloud_Datalabeling_V1beta1_Attempt] = []

  /// Output only. Timestamp of when this evaluation job was created.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return self._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {self._createTime = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// State of the job.
  public enum State: SwiftProtobuf.Enum {
    public typealias RawValue = Int
    case unspecified // = 0

    /// The job is scheduled to run at the [configured interval][google.cloud.datalabeling.v1beta1.EvaluationJob.schedule]. You
    /// can [pause][google.cloud.datalabeling.v1beta1.DataLabelingService.PauseEvaluationJob] or
    /// [delete][google.cloud.datalabeling.v1beta1.DataLabelingService.DeleteEvaluationJob] the job.
    ///
    /// When the job is in this state, it samples prediction input and output
    /// from your model version into your BigQuery table as predictions occur.
    case scheduled // = 1

    /// The job is currently running. When the job runs, Data Labeling Service
    /// does several things:
    ///
    /// 1. If you have configured your job to use Data Labeling Service for
    ///    ground truth labeling, the service creates a
    ///    [Dataset][google.cloud.datalabeling.v1beta1.Dataset] and a labeling task for all data sampled
    ///    since the last time the job ran. Human labelers provide ground truth
    ///    labels for your data. Human labeling may take hours, or even days,
    ///    depending on how much data has been sampled. The job remains in the
    ///    `RUNNING` state during this time, and it can even be running multiple
    ///    times in parallel if it gets triggered again (for example 24 hours
    ///    later) before the earlier run has completed. When human labelers have
    ///    finished labeling the data, the next step occurs.
    ///    <br><br>
    ///    If you have configured your job to provide your own ground truth
    ///    labels, Data Labeling Service still creates a [Dataset][google.cloud.datalabeling.v1beta1.Dataset] for newly
    ///    sampled data, but it expects that you have already added ground truth
    ///    labels to the BigQuery table by this time. The next step occurs
    ///    immediately.
    ///
    /// 2. Data Labeling Service creates an [Evaluation][google.cloud.datalabeling.v1beta1.Evaluation] by comparing your
    ///    model version's predictions with the ground truth labels.
    ///
    /// If the job remains in this state for a long time, it continues to sample
    /// prediction data into your BigQuery table and will run again at the next
    /// interval, even if it causes the job to run multiple times in parallel.
    case running // = 2

    /// The job is not sampling prediction input and output into your BigQuery
    /// table and it will not run according to its schedule. You can
    /// [resume][google.cloud.datalabeling.v1beta1.DataLabelingService.ResumeEvaluationJob] the job.
    case paused // = 3

    /// The job has this state right before it is deleted.
    case stopped // = 4
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .scheduled
      case 2: self = .running
      case 3: self = .paused
      case 4: self = .stopped
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .scheduled: return 1
      case .running: return 2
      case .paused: return 3
      case .stopped: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _evaluationJobConfig: Google_Cloud_Datalabeling_V1beta1_EvaluationJobConfig? = nil
  fileprivate var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

#if swift(>=4.2)

extension Google_Cloud_Datalabeling_V1beta1_EvaluationJob.State: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Datalabeling_V1beta1_EvaluationJob.State] = [
    .unspecified,
    .scheduled,
    .running,
    .paused,
    .stopped,
  ]
}

#endif  // swift(>=4.2)

/// Configures specific details of how a continuous evaluation job works. Provide
/// this configuration when you create an EvaluationJob.
public struct Google_Cloud_Datalabeling_V1beta1_EvaluationJobConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Details for how you want human reviewers to provide ground truth
  /// labels.
  public var humanAnnotationRequestConfig: OneOf_HumanAnnotationRequestConfig? {
    get {return _storage._humanAnnotationRequestConfig}
    set {_uniqueStorage()._humanAnnotationRequestConfig = newValue}
  }

  /// Specify this field if your model version performs image classification or
  /// general classification.
  ///
  /// `annotationSpecSet` in this configuration must match
  /// [EvaluationJob.annotationSpecSet][google.cloud.datalabeling.v1beta1.EvaluationJob.annotation_spec_set].
  /// `allowMultiLabel` in this configuration must match
  /// `classificationMetadata.isMultiLabel` in [input_config][google.cloud.datalabeling.v1beta1.EvaluationJobConfig.input_config].
  public var imageClassificationConfig: Google_Cloud_Datalabeling_V1beta1_ImageClassificationConfig {
    get {
      if case .imageClassificationConfig(let v)? = _storage._humanAnnotationRequestConfig {return v}
      return Google_Cloud_Datalabeling_V1beta1_ImageClassificationConfig()
    }
    set {_uniqueStorage()._humanAnnotationRequestConfig = .imageClassificationConfig(newValue)}
  }

  /// Specify this field if your model version performs image object detection
  /// (bounding box detection).
  ///
  /// `annotationSpecSet` in this configuration must match
  /// [EvaluationJob.annotationSpecSet][google.cloud.datalabeling.v1beta1.EvaluationJob.annotation_spec_set].
  public var boundingPolyConfig: Google_Cloud_Datalabeling_V1beta1_BoundingPolyConfig {
    get {
      if case .boundingPolyConfig(let v)? = _storage._humanAnnotationRequestConfig {return v}
      return Google_Cloud_Datalabeling_V1beta1_BoundingPolyConfig()
    }
    set {_uniqueStorage()._humanAnnotationRequestConfig = .boundingPolyConfig(newValue)}
  }

  /// Specify this field if your model version performs text classification.
  ///
  /// `annotationSpecSet` in this configuration must match
  /// [EvaluationJob.annotationSpecSet][google.cloud.datalabeling.v1beta1.EvaluationJob.annotation_spec_set].
  /// `allowMultiLabel` in this configuration must match
  /// `classificationMetadata.isMultiLabel` in [input_config][google.cloud.datalabeling.v1beta1.EvaluationJobConfig.input_config].
  public var textClassificationConfig: Google_Cloud_Datalabeling_V1beta1_TextClassificationConfig {
    get {
      if case .textClassificationConfig(let v)? = _storage._humanAnnotationRequestConfig {return v}
      return Google_Cloud_Datalabeling_V1beta1_TextClassificationConfig()
    }
    set {_uniqueStorage()._humanAnnotationRequestConfig = .textClassificationConfig(newValue)}
  }

  /// Rquired. Details for the sampled prediction input. Within this
  /// configuration, there are requirements for several fields:
  ///
  /// * `dataType` must be one of `IMAGE`, `TEXT`, or `GENERAL_DATA`.
  /// * `annotationType` must be one of `IMAGE_CLASSIFICATION_ANNOTATION`,
  ///   `TEXT_CLASSIFICATION_ANNOTATION`, `GENERAL_CLASSIFICATION_ANNOTATION`,
  ///   or `IMAGE_BOUNDING_BOX_ANNOTATION` (image object detection).
  /// * If your machine learning model performs classification, you must specify
  ///   `classificationMetadata.isMultiLabel`.
  /// * You must specify `bigquerySource` (not `gcsSource`).
  public var inputConfig: Google_Cloud_Datalabeling_V1beta1_InputConfig {
    get {return _storage._inputConfig ?? Google_Cloud_Datalabeling_V1beta1_InputConfig()}
    set {_uniqueStorage()._inputConfig = newValue}
  }
  /// Returns true if `inputConfig` has been explicitly set.
  public var hasInputConfig: Bool {return _storage._inputConfig != nil}
  /// Clears the value of `inputConfig`. Subsequent reads from it will return its default value.
  public mutating func clearInputConfig() {_uniqueStorage()._inputConfig = nil}

  /// Required. Details for calculating evaluation metrics and creating
  /// [Evaulations][google.cloud.datalabeling.v1beta1.Evaluation]. If your model version performs image object
  /// detection, you must specify the `boundingBoxEvaluationOptions` field within
  /// this configuration. Otherwise, provide an empty object for this
  /// configuration.
  public var evaluationConfig: Google_Cloud_Datalabeling_V1beta1_EvaluationConfig {
    get {return _storage._evaluationConfig ?? Google_Cloud_Datalabeling_V1beta1_EvaluationConfig()}
    set {_uniqueStorage()._evaluationConfig = newValue}
  }
  /// Returns true if `evaluationConfig` has been explicitly set.
  public var hasEvaluationConfig: Bool {return _storage._evaluationConfig != nil}
  /// Clears the value of `evaluationConfig`. Subsequent reads from it will return its default value.
  public mutating func clearEvaluationConfig() {_uniqueStorage()._evaluationConfig = nil}

  /// Optional. Details for human annotation of your data. If you set
  /// [labelMissingGroundTruth][google.cloud.datalabeling.v1beta1.EvaluationJob.label_missing_ground_truth] to
  /// `true` for this evaluation job, then you must specify this field. If you
  /// plan to provide your own ground truth labels, then omit this field.
  ///
  /// Note that you must create an [Instruction][google.cloud.datalabeling.v1beta1.Instruction] resource before you can
  /// specify this field. Provide the name of the instruction resource in the
  /// `instruction` field within this configuration.
  public var humanAnnotationConfig: Google_Cloud_Datalabeling_V1beta1_HumanAnnotationConfig {
    get {return _storage._humanAnnotationConfig ?? Google_Cloud_Datalabeling_V1beta1_HumanAnnotationConfig()}
    set {_uniqueStorage()._humanAnnotationConfig = newValue}
  }
  /// Returns true if `humanAnnotationConfig` has been explicitly set.
  public var hasHumanAnnotationConfig: Bool {return _storage._humanAnnotationConfig != nil}
  /// Clears the value of `humanAnnotationConfig`. Subsequent reads from it will return its default value.
  public mutating func clearHumanAnnotationConfig() {_uniqueStorage()._humanAnnotationConfig = nil}

  /// Required. Prediction keys that tell Data Labeling Service where to find the
  /// data for evaluation in your BigQuery table. When the service samples
  /// prediction input and output from your model version and saves it to
  /// BigQuery, the data gets stored as JSON strings in the BigQuery table. These
  /// keys tell Data Labeling Service how to parse the JSON.
  ///
  /// You can provide the following entries in this field:
  ///
  /// * `data_json_key`: the data key for prediction input. You must provide
  ///   either this key or `reference_json_key`.
  /// * `reference_json_key`: the data reference key for prediction input. You
  ///   must provide either this key or `data_json_key`.
  /// * `label_json_key`: the label key for prediction output. Required.
  /// * `label_score_json_key`: the score key for prediction output. Required.
  /// * `bounding_box_json_key`: the bounding box key for prediction output.
  ///   Required if your model version perform image object detection.
  ///
  /// Learn [how to configure prediction
  /// keys](/ml-engine/docs/continuous-evaluation/create-job#prediction-keys).
  public var bigqueryImportKeys: Dictionary<String,String> {
    get {return _storage._bigqueryImportKeys}
    set {_uniqueStorage()._bigqueryImportKeys = newValue}
  }

  /// Required. The maximum number of predictions to sample and save to BigQuery
  /// during each [evaluation interval][google.cloud.datalabeling.v1beta1.EvaluationJob.schedule]. This limit
  /// overrides `example_sample_percentage`: even if the service has not sampled
  /// enough predictions to fulfill `example_sample_perecentage` during an
  /// interval, it stops sampling predictions when it meets this limit.
  public var exampleCount: Int32 {
    get {return _storage._exampleCount}
    set {_uniqueStorage()._exampleCount = newValue}
  }

  /// Required. Fraction of predictions to sample and save to BigQuery during
  /// each [evaluation interval][google.cloud.datalabeling.v1beta1.EvaluationJob.schedule]. For example, 0.1 means
  /// 10% of predictions served by your model version get saved to BigQuery.
  public var exampleSamplePercentage: Double {
    get {return _storage._exampleSamplePercentage}
    set {_uniqueStorage()._exampleSamplePercentage = newValue}
  }

  /// Optional. Configuration details for evaluation job alerts. Specify this
  /// field if you want to receive email alerts if the evaluation job finds that
  /// your predictions have low mean average precision during a run.
  public var evaluationJobAlertConfig: Google_Cloud_Datalabeling_V1beta1_EvaluationJobAlertConfig {
    get {return _storage._evaluationJobAlertConfig ?? Google_Cloud_Datalabeling_V1beta1_EvaluationJobAlertConfig()}
    set {_uniqueStorage()._evaluationJobAlertConfig = newValue}
  }
  /// Returns true if `evaluationJobAlertConfig` has been explicitly set.
  public var hasEvaluationJobAlertConfig: Bool {return _storage._evaluationJobAlertConfig != nil}
  /// Clears the value of `evaluationJobAlertConfig`. Subsequent reads from it will return its default value.
  public mutating func clearEvaluationJobAlertConfig() {_uniqueStorage()._evaluationJobAlertConfig = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Required. Details for how you want human reviewers to provide ground truth
  /// labels.
  public enum OneOf_HumanAnnotationRequestConfig: Equatable {
    /// Specify this field if your model version performs image classification or
    /// general classification.
    ///
    /// `annotationSpecSet` in this configuration must match
    /// [EvaluationJob.annotationSpecSet][google.cloud.datalabeling.v1beta1.EvaluationJob.annotation_spec_set].
    /// `allowMultiLabel` in this configuration must match
    /// `classificationMetadata.isMultiLabel` in [input_config][google.cloud.datalabeling.v1beta1.EvaluationJobConfig.input_config].
    case imageClassificationConfig(Google_Cloud_Datalabeling_V1beta1_ImageClassificationConfig)
    /// Specify this field if your model version performs image object detection
    /// (bounding box detection).
    ///
    /// `annotationSpecSet` in this configuration must match
    /// [EvaluationJob.annotationSpecSet][google.cloud.datalabeling.v1beta1.EvaluationJob.annotation_spec_set].
    case boundingPolyConfig(Google_Cloud_Datalabeling_V1beta1_BoundingPolyConfig)
    /// Specify this field if your model version performs text classification.
    ///
    /// `annotationSpecSet` in this configuration must match
    /// [EvaluationJob.annotationSpecSet][google.cloud.datalabeling.v1beta1.EvaluationJob.annotation_spec_set].
    /// `allowMultiLabel` in this configuration must match
    /// `classificationMetadata.isMultiLabel` in [input_config][google.cloud.datalabeling.v1beta1.EvaluationJobConfig.input_config].
    case textClassificationConfig(Google_Cloud_Datalabeling_V1beta1_TextClassificationConfig)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Datalabeling_V1beta1_EvaluationJobConfig.OneOf_HumanAnnotationRequestConfig, rhs: Google_Cloud_Datalabeling_V1beta1_EvaluationJobConfig.OneOf_HumanAnnotationRequestConfig) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.imageClassificationConfig, .imageClassificationConfig): return {
        guard case .imageClassificationConfig(let l) = lhs, case .imageClassificationConfig(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.boundingPolyConfig, .boundingPolyConfig): return {
        guard case .boundingPolyConfig(let l) = lhs, case .boundingPolyConfig(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.textClassificationConfig, .textClassificationConfig): return {
        guard case .textClassificationConfig(let l) = lhs, case .textClassificationConfig(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Provides details for how an evaluation job sends email alerts based on the
/// results of a run.
public struct Google_Cloud_Datalabeling_V1beta1_EvaluationJobAlertConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. An email address to send alerts to.
  public var email: String = String()

  /// Required. A number between 0 and 1 that describes a minimum mean average
  /// precision threshold. When the evaluation job runs, if it calculates that
  /// your model version's predictions from the recent interval have
  /// [meanAveragePrecision][google.cloud.datalabeling.v1beta1.PrCurve.mean_average_precision] below this
  /// threshold, then it sends an alert to your specified email.
  public var minAcceptableMeanAveragePrecision: Double = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Records a failed evaluation job run.
public struct Google_Cloud_Datalabeling_V1beta1_Attempt {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var attemptTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _attemptTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_attemptTime = newValue}
  }
  /// Returns true if `attemptTime` has been explicitly set.
  public var hasAttemptTime: Bool {return self._attemptTime != nil}
  /// Clears the value of `attemptTime`. Subsequent reads from it will return its default value.
  public mutating func clearAttemptTime() {self._attemptTime = nil}

  /// Details of errors that occurred.
  public var partialFailures: [Google_Rpc_Status] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _attemptTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.datalabeling.v1beta1"

extension Google_Cloud_Datalabeling_V1beta1_EvaluationJob: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".EvaluationJob"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "description"),
    3: .same(proto: "state"),
    4: .same(proto: "schedule"),
    5: .standard(proto: "model_version"),
    6: .standard(proto: "evaluation_job_config"),
    7: .standard(proto: "annotation_spec_set"),
    8: .standard(proto: "label_missing_ground_truth"),
    9: .same(proto: "attempts"),
    10: .standard(proto: "create_time"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.description_p) }()
      case 3: try { try decoder.decodeSingularEnumField(value: &self.state) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.schedule) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.modelVersion) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._evaluationJobConfig) }()
      case 7: try { try decoder.decodeSingularStringField(value: &self.annotationSpecSet) }()
      case 8: try { try decoder.decodeSingularBoolField(value: &self.labelMissingGroundTruth) }()
      case 9: try { try decoder.decodeRepeatedMessageField(value: &self.attempts) }()
      case 10: try { try decoder.decodeSingularMessageField(value: &self._createTime) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if !self.description_p.isEmpty {
      try visitor.visitSingularStringField(value: self.description_p, fieldNumber: 2)
    }
    if self.state != .unspecified {
      try visitor.visitSingularEnumField(value: self.state, fieldNumber: 3)
    }
    if !self.schedule.isEmpty {
      try visitor.visitSingularStringField(value: self.schedule, fieldNumber: 4)
    }
    if !self.modelVersion.isEmpty {
      try visitor.visitSingularStringField(value: self.modelVersion, fieldNumber: 5)
    }
    if let v = self._evaluationJobConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }
    if !self.annotationSpecSet.isEmpty {
      try visitor.visitSingularStringField(value: self.annotationSpecSet, fieldNumber: 7)
    }
    if self.labelMissingGroundTruth != false {
      try visitor.visitSingularBoolField(value: self.labelMissingGroundTruth, fieldNumber: 8)
    }
    if !self.attempts.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.attempts, fieldNumber: 9)
    }
    if let v = self._createTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Datalabeling_V1beta1_EvaluationJob, rhs: Google_Cloud_Datalabeling_V1beta1_EvaluationJob) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.description_p != rhs.description_p {return false}
    if lhs.state != rhs.state {return false}
    if lhs.schedule != rhs.schedule {return false}
    if lhs.modelVersion != rhs.modelVersion {return false}
    if lhs._evaluationJobConfig != rhs._evaluationJobConfig {return false}
    if lhs.annotationSpecSet != rhs.annotationSpecSet {return false}
    if lhs.labelMissingGroundTruth != rhs.labelMissingGroundTruth {return false}
    if lhs.attempts != rhs.attempts {return false}
    if lhs._createTime != rhs._createTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Datalabeling_V1beta1_EvaluationJob.State: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "STATE_UNSPECIFIED"),
    1: .same(proto: "SCHEDULED"),
    2: .same(proto: "RUNNING"),
    3: .same(proto: "PAUSED"),
    4: .same(proto: "STOPPED"),
  ]
}

extension Google_Cloud_Datalabeling_V1beta1_EvaluationJobConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".EvaluationJobConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    4: .standard(proto: "image_classification_config"),
    5: .standard(proto: "bounding_poly_config"),
    8: .standard(proto: "text_classification_config"),
    1: .standard(proto: "input_config"),
    2: .standard(proto: "evaluation_config"),
    3: .standard(proto: "human_annotation_config"),
    9: .standard(proto: "bigquery_import_keys"),
    10: .standard(proto: "example_count"),
    11: .standard(proto: "example_sample_percentage"),
    13: .standard(proto: "evaluation_job_alert_config"),
  ]

  fileprivate class _StorageClass {
    var _humanAnnotationRequestConfig: Google_Cloud_Datalabeling_V1beta1_EvaluationJobConfig.OneOf_HumanAnnotationRequestConfig?
    var _inputConfig: Google_Cloud_Datalabeling_V1beta1_InputConfig? = nil
    var _evaluationConfig: Google_Cloud_Datalabeling_V1beta1_EvaluationConfig? = nil
    var _humanAnnotationConfig: Google_Cloud_Datalabeling_V1beta1_HumanAnnotationConfig? = nil
    var _bigqueryImportKeys: Dictionary<String,String> = [:]
    var _exampleCount: Int32 = 0
    var _exampleSamplePercentage: Double = 0
    var _evaluationJobAlertConfig: Google_Cloud_Datalabeling_V1beta1_EvaluationJobAlertConfig? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _humanAnnotationRequestConfig = source._humanAnnotationRequestConfig
      _inputConfig = source._inputConfig
      _evaluationConfig = source._evaluationConfig
      _humanAnnotationConfig = source._humanAnnotationConfig
      _bigqueryImportKeys = source._bigqueryImportKeys
      _exampleCount = source._exampleCount
      _exampleSamplePercentage = source._exampleSamplePercentage
      _evaluationJobAlertConfig = source._evaluationJobAlertConfig
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._inputConfig) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._evaluationConfig) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._humanAnnotationConfig) }()
        case 4: try {
          var v: Google_Cloud_Datalabeling_V1beta1_ImageClassificationConfig?
          if let current = _storage._humanAnnotationRequestConfig {
            try decoder.handleConflictingOneOf()
            if case .imageClassificationConfig(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._humanAnnotationRequestConfig = .imageClassificationConfig(v)}
        }()
        case 5: try {
          var v: Google_Cloud_Datalabeling_V1beta1_BoundingPolyConfig?
          if let current = _storage._humanAnnotationRequestConfig {
            try decoder.handleConflictingOneOf()
            if case .boundingPolyConfig(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._humanAnnotationRequestConfig = .boundingPolyConfig(v)}
        }()
        case 8: try {
          var v: Google_Cloud_Datalabeling_V1beta1_TextClassificationConfig?
          if let current = _storage._humanAnnotationRequestConfig {
            try decoder.handleConflictingOneOf()
            if case .textClassificationConfig(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._humanAnnotationRequestConfig = .textClassificationConfig(v)}
        }()
        case 9: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._bigqueryImportKeys) }()
        case 10: try { try decoder.decodeSingularInt32Field(value: &_storage._exampleCount) }()
        case 11: try { try decoder.decodeSingularDoubleField(value: &_storage._exampleSamplePercentage) }()
        case 13: try { try decoder.decodeSingularMessageField(value: &_storage._evaluationJobAlertConfig) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if let v = _storage._inputConfig {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }
      if let v = _storage._evaluationConfig {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if let v = _storage._humanAnnotationConfig {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch _storage._humanAnnotationRequestConfig {
      case .imageClassificationConfig?: try {
        guard case .imageClassificationConfig(let v)? = _storage._humanAnnotationRequestConfig else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }()
      case .boundingPolyConfig?: try {
        guard case .boundingPolyConfig(let v)? = _storage._humanAnnotationRequestConfig else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      }()
      case .textClassificationConfig?: try {
        guard case .textClassificationConfig(let v)? = _storage._humanAnnotationRequestConfig else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      }()
      case nil: break
      }
      if !_storage._bigqueryImportKeys.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._bigqueryImportKeys, fieldNumber: 9)
      }
      if _storage._exampleCount != 0 {
        try visitor.visitSingularInt32Field(value: _storage._exampleCount, fieldNumber: 10)
      }
      if _storage._exampleSamplePercentage != 0 {
        try visitor.visitSingularDoubleField(value: _storage._exampleSamplePercentage, fieldNumber: 11)
      }
      if let v = _storage._evaluationJobAlertConfig {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Datalabeling_V1beta1_EvaluationJobConfig, rhs: Google_Cloud_Datalabeling_V1beta1_EvaluationJobConfig) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._humanAnnotationRequestConfig != rhs_storage._humanAnnotationRequestConfig {return false}
        if _storage._inputConfig != rhs_storage._inputConfig {return false}
        if _storage._evaluationConfig != rhs_storage._evaluationConfig {return false}
        if _storage._humanAnnotationConfig != rhs_storage._humanAnnotationConfig {return false}
        if _storage._bigqueryImportKeys != rhs_storage._bigqueryImportKeys {return false}
        if _storage._exampleCount != rhs_storage._exampleCount {return false}
        if _storage._exampleSamplePercentage != rhs_storage._exampleSamplePercentage {return false}
        if _storage._evaluationJobAlertConfig != rhs_storage._evaluationJobAlertConfig {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Datalabeling_V1beta1_EvaluationJobAlertConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".EvaluationJobAlertConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "email"),
    2: .standard(proto: "min_acceptable_mean_average_precision"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.email) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.minAcceptableMeanAveragePrecision) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.email.isEmpty {
      try visitor.visitSingularStringField(value: self.email, fieldNumber: 1)
    }
    if self.minAcceptableMeanAveragePrecision != 0 {
      try visitor.visitSingularDoubleField(value: self.minAcceptableMeanAveragePrecision, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Datalabeling_V1beta1_EvaluationJobAlertConfig, rhs: Google_Cloud_Datalabeling_V1beta1_EvaluationJobAlertConfig) -> Bool {
    if lhs.email != rhs.email {return false}
    if lhs.minAcceptableMeanAveragePrecision != rhs.minAcceptableMeanAveragePrecision {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Datalabeling_V1beta1_Attempt: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Attempt"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "attempt_time"),
    2: .standard(proto: "partial_failures"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._attemptTime) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.partialFailures) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._attemptTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.partialFailures.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.partialFailures, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Datalabeling_V1beta1_Attempt, rhs: Google_Cloud_Datalabeling_V1beta1_Attempt) -> Bool {
    if lhs._attemptTime != rhs._attemptTime {return false}
    if lhs.partialFailures != rhs.partialFailures {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
