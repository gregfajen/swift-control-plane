// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/logging/v1/audit_data.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// BigQuery request and response messages for audit log.
/// Note: `Table.schema` has been deprecated in favor of `Table.schemaJson`.
/// `Table.schema` may continue to be present in your logs during this
/// transition.
public struct Google_Cloud_Bigquery_Logging_V1_AuditData {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Request data for each BigQuery method.
  public var request: OneOf_Request? {
    get {return _storage._request}
    set {_uniqueStorage()._request = newValue}
  }

  /// Table insert request.
  public var tableInsertRequest: Google_Cloud_Bigquery_Logging_V1_TableInsertRequest {
    get {
      if case .tableInsertRequest(let v)? = _storage._request {return v}
      return Google_Cloud_Bigquery_Logging_V1_TableInsertRequest()
    }
    set {_uniqueStorage()._request = .tableInsertRequest(newValue)}
  }

  /// Table update request.
  public var tableUpdateRequest: Google_Cloud_Bigquery_Logging_V1_TableUpdateRequest {
    get {
      if case .tableUpdateRequest(let v)? = _storage._request {return v}
      return Google_Cloud_Bigquery_Logging_V1_TableUpdateRequest()
    }
    set {_uniqueStorage()._request = .tableUpdateRequest(newValue)}
  }

  /// Dataset list request.
  public var datasetListRequest: Google_Cloud_Bigquery_Logging_V1_DatasetListRequest {
    get {
      if case .datasetListRequest(let v)? = _storage._request {return v}
      return Google_Cloud_Bigquery_Logging_V1_DatasetListRequest()
    }
    set {_uniqueStorage()._request = .datasetListRequest(newValue)}
  }

  /// Dataset insert request.
  public var datasetInsertRequest: Google_Cloud_Bigquery_Logging_V1_DatasetInsertRequest {
    get {
      if case .datasetInsertRequest(let v)? = _storage._request {return v}
      return Google_Cloud_Bigquery_Logging_V1_DatasetInsertRequest()
    }
    set {_uniqueStorage()._request = .datasetInsertRequest(newValue)}
  }

  /// Dataset update request.
  public var datasetUpdateRequest: Google_Cloud_Bigquery_Logging_V1_DatasetUpdateRequest {
    get {
      if case .datasetUpdateRequest(let v)? = _storage._request {return v}
      return Google_Cloud_Bigquery_Logging_V1_DatasetUpdateRequest()
    }
    set {_uniqueStorage()._request = .datasetUpdateRequest(newValue)}
  }

  /// Job insert request.
  public var jobInsertRequest: Google_Cloud_Bigquery_Logging_V1_JobInsertRequest {
    get {
      if case .jobInsertRequest(let v)? = _storage._request {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobInsertRequest()
    }
    set {_uniqueStorage()._request = .jobInsertRequest(newValue)}
  }

  /// Job query request.
  public var jobQueryRequest: Google_Cloud_Bigquery_Logging_V1_JobQueryRequest {
    get {
      if case .jobQueryRequest(let v)? = _storage._request {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobQueryRequest()
    }
    set {_uniqueStorage()._request = .jobQueryRequest(newValue)}
  }

  /// Job get query results request.
  public var jobGetQueryResultsRequest: Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsRequest {
    get {
      if case .jobGetQueryResultsRequest(let v)? = _storage._request {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsRequest()
    }
    set {_uniqueStorage()._request = .jobGetQueryResultsRequest(newValue)}
  }

  /// Table data-list request.
  public var tableDataListRequest: Google_Cloud_Bigquery_Logging_V1_TableDataListRequest {
    get {
      if case .tableDataListRequest(let v)? = _storage._request {return v}
      return Google_Cloud_Bigquery_Logging_V1_TableDataListRequest()
    }
    set {_uniqueStorage()._request = .tableDataListRequest(newValue)}
  }

  /// Iam policy request.
  public var setIamPolicyRequest: Google_Iam_V1_SetIamPolicyRequest {
    get {
      if case .setIamPolicyRequest(let v)? = _storage._request {return v}
      return Google_Iam_V1_SetIamPolicyRequest()
    }
    set {_uniqueStorage()._request = .setIamPolicyRequest(newValue)}
  }

  /// Response data for each BigQuery method.
  public var response: OneOf_Response? {
    get {return _storage._response}
    set {_uniqueStorage()._response = newValue}
  }

  /// Table insert response.
  public var tableInsertResponse: Google_Cloud_Bigquery_Logging_V1_TableInsertResponse {
    get {
      if case .tableInsertResponse(let v)? = _storage._response {return v}
      return Google_Cloud_Bigquery_Logging_V1_TableInsertResponse()
    }
    set {_uniqueStorage()._response = .tableInsertResponse(newValue)}
  }

  /// Table update response.
  public var tableUpdateResponse: Google_Cloud_Bigquery_Logging_V1_TableUpdateResponse {
    get {
      if case .tableUpdateResponse(let v)? = _storage._response {return v}
      return Google_Cloud_Bigquery_Logging_V1_TableUpdateResponse()
    }
    set {_uniqueStorage()._response = .tableUpdateResponse(newValue)}
  }

  /// Dataset insert response.
  public var datasetInsertResponse: Google_Cloud_Bigquery_Logging_V1_DatasetInsertResponse {
    get {
      if case .datasetInsertResponse(let v)? = _storage._response {return v}
      return Google_Cloud_Bigquery_Logging_V1_DatasetInsertResponse()
    }
    set {_uniqueStorage()._response = .datasetInsertResponse(newValue)}
  }

  /// Dataset update response.
  public var datasetUpdateResponse: Google_Cloud_Bigquery_Logging_V1_DatasetUpdateResponse {
    get {
      if case .datasetUpdateResponse(let v)? = _storage._response {return v}
      return Google_Cloud_Bigquery_Logging_V1_DatasetUpdateResponse()
    }
    set {_uniqueStorage()._response = .datasetUpdateResponse(newValue)}
  }

  /// Job insert response.
  public var jobInsertResponse: Google_Cloud_Bigquery_Logging_V1_JobInsertResponse {
    get {
      if case .jobInsertResponse(let v)? = _storage._response {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobInsertResponse()
    }
    set {_uniqueStorage()._response = .jobInsertResponse(newValue)}
  }

  /// Job query response.
  public var jobQueryResponse: Google_Cloud_Bigquery_Logging_V1_JobQueryResponse {
    get {
      if case .jobQueryResponse(let v)? = _storage._response {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobQueryResponse()
    }
    set {_uniqueStorage()._response = .jobQueryResponse(newValue)}
  }

  /// Job get query results response.
  public var jobGetQueryResultsResponse: Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsResponse {
    get {
      if case .jobGetQueryResultsResponse(let v)? = _storage._response {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsResponse()
    }
    set {_uniqueStorage()._response = .jobGetQueryResultsResponse(newValue)}
  }

  /// Deprecated: Job query-done response. Use this information for usage
  /// analysis.
  public var jobQueryDoneResponse: Google_Cloud_Bigquery_Logging_V1_JobQueryDoneResponse {
    get {
      if case .jobQueryDoneResponse(let v)? = _storage._response {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobQueryDoneResponse()
    }
    set {_uniqueStorage()._response = .jobQueryDoneResponse(newValue)}
  }

  /// Iam Policy.
  public var policyResponse: Google_Iam_V1_Policy {
    get {
      if case .policyResponse(let v)? = _storage._response {return v}
      return Google_Iam_V1_Policy()
    }
    set {_uniqueStorage()._response = .policyResponse(newValue)}
  }

  /// A job completion event.
  public var jobCompletedEvent: Google_Cloud_Bigquery_Logging_V1_JobCompletedEvent {
    get {return _storage._jobCompletedEvent ?? Google_Cloud_Bigquery_Logging_V1_JobCompletedEvent()}
    set {_uniqueStorage()._jobCompletedEvent = newValue}
  }
  /// Returns true if `jobCompletedEvent` has been explicitly set.
  public var hasJobCompletedEvent: Bool {return _storage._jobCompletedEvent != nil}
  /// Clears the value of `jobCompletedEvent`. Subsequent reads from it will return its default value.
  public mutating func clearJobCompletedEvent() {_uniqueStorage()._jobCompletedEvent = nil}

  /// Information about the table access events.
  public var tableDataReadEvents: [Google_Cloud_Bigquery_Logging_V1_TableDataReadEvent] {
    get {return _storage._tableDataReadEvents}
    set {_uniqueStorage()._tableDataReadEvents = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Request data for each BigQuery method.
  public enum OneOf_Request: Equatable {
    /// Table insert request.
    case tableInsertRequest(Google_Cloud_Bigquery_Logging_V1_TableInsertRequest)
    /// Table update request.
    case tableUpdateRequest(Google_Cloud_Bigquery_Logging_V1_TableUpdateRequest)
    /// Dataset list request.
    case datasetListRequest(Google_Cloud_Bigquery_Logging_V1_DatasetListRequest)
    /// Dataset insert request.
    case datasetInsertRequest(Google_Cloud_Bigquery_Logging_V1_DatasetInsertRequest)
    /// Dataset update request.
    case datasetUpdateRequest(Google_Cloud_Bigquery_Logging_V1_DatasetUpdateRequest)
    /// Job insert request.
    case jobInsertRequest(Google_Cloud_Bigquery_Logging_V1_JobInsertRequest)
    /// Job query request.
    case jobQueryRequest(Google_Cloud_Bigquery_Logging_V1_JobQueryRequest)
    /// Job get query results request.
    case jobGetQueryResultsRequest(Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsRequest)
    /// Table data-list request.
    case tableDataListRequest(Google_Cloud_Bigquery_Logging_V1_TableDataListRequest)
    /// Iam policy request.
    case setIamPolicyRequest(Google_Iam_V1_SetIamPolicyRequest)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_AuditData.OneOf_Request, rhs: Google_Cloud_Bigquery_Logging_V1_AuditData.OneOf_Request) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.tableInsertRequest, .tableInsertRequest): return {
        guard case .tableInsertRequest(let l) = lhs, case .tableInsertRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.tableUpdateRequest, .tableUpdateRequest): return {
        guard case .tableUpdateRequest(let l) = lhs, case .tableUpdateRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.datasetListRequest, .datasetListRequest): return {
        guard case .datasetListRequest(let l) = lhs, case .datasetListRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.datasetInsertRequest, .datasetInsertRequest): return {
        guard case .datasetInsertRequest(let l) = lhs, case .datasetInsertRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.datasetUpdateRequest, .datasetUpdateRequest): return {
        guard case .datasetUpdateRequest(let l) = lhs, case .datasetUpdateRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.jobInsertRequest, .jobInsertRequest): return {
        guard case .jobInsertRequest(let l) = lhs, case .jobInsertRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.jobQueryRequest, .jobQueryRequest): return {
        guard case .jobQueryRequest(let l) = lhs, case .jobQueryRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.jobGetQueryResultsRequest, .jobGetQueryResultsRequest): return {
        guard case .jobGetQueryResultsRequest(let l) = lhs, case .jobGetQueryResultsRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.tableDataListRequest, .tableDataListRequest): return {
        guard case .tableDataListRequest(let l) = lhs, case .tableDataListRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.setIamPolicyRequest, .setIamPolicyRequest): return {
        guard case .setIamPolicyRequest(let l) = lhs, case .setIamPolicyRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  /// Response data for each BigQuery method.
  public enum OneOf_Response: Equatable {
    /// Table insert response.
    case tableInsertResponse(Google_Cloud_Bigquery_Logging_V1_TableInsertResponse)
    /// Table update response.
    case tableUpdateResponse(Google_Cloud_Bigquery_Logging_V1_TableUpdateResponse)
    /// Dataset insert response.
    case datasetInsertResponse(Google_Cloud_Bigquery_Logging_V1_DatasetInsertResponse)
    /// Dataset update response.
    case datasetUpdateResponse(Google_Cloud_Bigquery_Logging_V1_DatasetUpdateResponse)
    /// Job insert response.
    case jobInsertResponse(Google_Cloud_Bigquery_Logging_V1_JobInsertResponse)
    /// Job query response.
    case jobQueryResponse(Google_Cloud_Bigquery_Logging_V1_JobQueryResponse)
    /// Job get query results response.
    case jobGetQueryResultsResponse(Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsResponse)
    /// Deprecated: Job query-done response. Use this information for usage
    /// analysis.
    case jobQueryDoneResponse(Google_Cloud_Bigquery_Logging_V1_JobQueryDoneResponse)
    /// Iam Policy.
    case policyResponse(Google_Iam_V1_Policy)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_AuditData.OneOf_Response, rhs: Google_Cloud_Bigquery_Logging_V1_AuditData.OneOf_Response) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.tableInsertResponse, .tableInsertResponse): return {
        guard case .tableInsertResponse(let l) = lhs, case .tableInsertResponse(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.tableUpdateResponse, .tableUpdateResponse): return {
        guard case .tableUpdateResponse(let l) = lhs, case .tableUpdateResponse(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.datasetInsertResponse, .datasetInsertResponse): return {
        guard case .datasetInsertResponse(let l) = lhs, case .datasetInsertResponse(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.datasetUpdateResponse, .datasetUpdateResponse): return {
        guard case .datasetUpdateResponse(let l) = lhs, case .datasetUpdateResponse(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.jobInsertResponse, .jobInsertResponse): return {
        guard case .jobInsertResponse(let l) = lhs, case .jobInsertResponse(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.jobQueryResponse, .jobQueryResponse): return {
        guard case .jobQueryResponse(let l) = lhs, case .jobQueryResponse(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.jobGetQueryResultsResponse, .jobGetQueryResultsResponse): return {
        guard case .jobGetQueryResultsResponse(let l) = lhs, case .jobGetQueryResultsResponse(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.jobQueryDoneResponse, .jobQueryDoneResponse): return {
        guard case .jobQueryDoneResponse(let l) = lhs, case .jobQueryDoneResponse(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.policyResponse, .policyResponse): return {
        guard case .policyResponse(let l) = lhs, case .policyResponse(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Table insert request.
public struct Google_Cloud_Bigquery_Logging_V1_TableInsertRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The new table.
  public var resource: Google_Cloud_Bigquery_Logging_V1_Table {
    get {return _resource ?? Google_Cloud_Bigquery_Logging_V1_Table()}
    set {_resource = newValue}
  }
  /// Returns true if `resource` has been explicitly set.
  public var hasResource: Bool {return self._resource != nil}
  /// Clears the value of `resource`. Subsequent reads from it will return its default value.
  public mutating func clearResource() {self._resource = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resource: Google_Cloud_Bigquery_Logging_V1_Table? = nil
}

/// Table update request.
public struct Google_Cloud_Bigquery_Logging_V1_TableUpdateRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The table to be updated.
  public var resource: Google_Cloud_Bigquery_Logging_V1_Table {
    get {return _resource ?? Google_Cloud_Bigquery_Logging_V1_Table()}
    set {_resource = newValue}
  }
  /// Returns true if `resource` has been explicitly set.
  public var hasResource: Bool {return self._resource != nil}
  /// Clears the value of `resource`. Subsequent reads from it will return its default value.
  public mutating func clearResource() {self._resource = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resource: Google_Cloud_Bigquery_Logging_V1_Table? = nil
}

/// Table insert response.
public struct Google_Cloud_Bigquery_Logging_V1_TableInsertResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Final state of the inserted table.
  public var resource: Google_Cloud_Bigquery_Logging_V1_Table {
    get {return _resource ?? Google_Cloud_Bigquery_Logging_V1_Table()}
    set {_resource = newValue}
  }
  /// Returns true if `resource` has been explicitly set.
  public var hasResource: Bool {return self._resource != nil}
  /// Clears the value of `resource`. Subsequent reads from it will return its default value.
  public mutating func clearResource() {self._resource = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resource: Google_Cloud_Bigquery_Logging_V1_Table? = nil
}

/// Table update response.
public struct Google_Cloud_Bigquery_Logging_V1_TableUpdateResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Final state of the updated table.
  public var resource: Google_Cloud_Bigquery_Logging_V1_Table {
    get {return _resource ?? Google_Cloud_Bigquery_Logging_V1_Table()}
    set {_resource = newValue}
  }
  /// Returns true if `resource` has been explicitly set.
  public var hasResource: Bool {return self._resource != nil}
  /// Clears the value of `resource`. Subsequent reads from it will return its default value.
  public mutating func clearResource() {self._resource = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resource: Google_Cloud_Bigquery_Logging_V1_Table? = nil
}

/// Dataset list request.
public struct Google_Cloud_Bigquery_Logging_V1_DatasetListRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Whether to list all datasets, including hidden ones.
  public var listAll: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Dataset insert request.
public struct Google_Cloud_Bigquery_Logging_V1_DatasetInsertRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The dataset to be inserted.
  public var resource: Google_Cloud_Bigquery_Logging_V1_Dataset {
    get {return _resource ?? Google_Cloud_Bigquery_Logging_V1_Dataset()}
    set {_resource = newValue}
  }
  /// Returns true if `resource` has been explicitly set.
  public var hasResource: Bool {return self._resource != nil}
  /// Clears the value of `resource`. Subsequent reads from it will return its default value.
  public mutating func clearResource() {self._resource = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resource: Google_Cloud_Bigquery_Logging_V1_Dataset? = nil
}

/// Dataset insert response.
public struct Google_Cloud_Bigquery_Logging_V1_DatasetInsertResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Final state of the inserted dataset.
  public var resource: Google_Cloud_Bigquery_Logging_V1_Dataset {
    get {return _resource ?? Google_Cloud_Bigquery_Logging_V1_Dataset()}
    set {_resource = newValue}
  }
  /// Returns true if `resource` has been explicitly set.
  public var hasResource: Bool {return self._resource != nil}
  /// Clears the value of `resource`. Subsequent reads from it will return its default value.
  public mutating func clearResource() {self._resource = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resource: Google_Cloud_Bigquery_Logging_V1_Dataset? = nil
}

/// Dataset update request.
public struct Google_Cloud_Bigquery_Logging_V1_DatasetUpdateRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The dataset to be updated.
  public var resource: Google_Cloud_Bigquery_Logging_V1_Dataset {
    get {return _resource ?? Google_Cloud_Bigquery_Logging_V1_Dataset()}
    set {_resource = newValue}
  }
  /// Returns true if `resource` has been explicitly set.
  public var hasResource: Bool {return self._resource != nil}
  /// Clears the value of `resource`. Subsequent reads from it will return its default value.
  public mutating func clearResource() {self._resource = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resource: Google_Cloud_Bigquery_Logging_V1_Dataset? = nil
}

/// Dataset update response.
public struct Google_Cloud_Bigquery_Logging_V1_DatasetUpdateResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Final state of the updated dataset.
  public var resource: Google_Cloud_Bigquery_Logging_V1_Dataset {
    get {return _resource ?? Google_Cloud_Bigquery_Logging_V1_Dataset()}
    set {_resource = newValue}
  }
  /// Returns true if `resource` has been explicitly set.
  public var hasResource: Bool {return self._resource != nil}
  /// Clears the value of `resource`. Subsequent reads from it will return its default value.
  public mutating func clearResource() {self._resource = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resource: Google_Cloud_Bigquery_Logging_V1_Dataset? = nil
}

/// Job insert request.
public struct Google_Cloud_Bigquery_Logging_V1_JobInsertRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Job insert request.
  public var resource: Google_Cloud_Bigquery_Logging_V1_Job {
    get {return _resource ?? Google_Cloud_Bigquery_Logging_V1_Job()}
    set {_resource = newValue}
  }
  /// Returns true if `resource` has been explicitly set.
  public var hasResource: Bool {return self._resource != nil}
  /// Clears the value of `resource`. Subsequent reads from it will return its default value.
  public mutating func clearResource() {self._resource = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resource: Google_Cloud_Bigquery_Logging_V1_Job? = nil
}

/// Job insert response.
public struct Google_Cloud_Bigquery_Logging_V1_JobInsertResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Job insert response.
  public var resource: Google_Cloud_Bigquery_Logging_V1_Job {
    get {return _resource ?? Google_Cloud_Bigquery_Logging_V1_Job()}
    set {_resource = newValue}
  }
  /// Returns true if `resource` has been explicitly set.
  public var hasResource: Bool {return self._resource != nil}
  /// Clears the value of `resource`. Subsequent reads from it will return its default value.
  public mutating func clearResource() {self._resource = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resource: Google_Cloud_Bigquery_Logging_V1_Job? = nil
}

/// Job query request.
public struct Google_Cloud_Bigquery_Logging_V1_JobQueryRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The query.
  public var query: String = String()

  /// The maximum number of results.
  public var maxResults: UInt32 = 0

  /// The default dataset for tables that do not have a dataset specified.
  public var defaultDataset: Google_Cloud_Bigquery_Logging_V1_DatasetName {
    get {return _defaultDataset ?? Google_Cloud_Bigquery_Logging_V1_DatasetName()}
    set {_defaultDataset = newValue}
  }
  /// Returns true if `defaultDataset` has been explicitly set.
  public var hasDefaultDataset: Bool {return self._defaultDataset != nil}
  /// Clears the value of `defaultDataset`. Subsequent reads from it will return its default value.
  public mutating func clearDefaultDataset() {self._defaultDataset = nil}

  /// Project that the query should be charged to.
  public var projectID: String = String()

  /// If true, don't actually run the job. Just check that it would run.
  public var dryRun: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _defaultDataset: Google_Cloud_Bigquery_Logging_V1_DatasetName? = nil
}

/// Job query response.
public struct Google_Cloud_Bigquery_Logging_V1_JobQueryResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The total number of rows in the full query result set.
  public var totalResults: UInt64 = 0

  /// Information about the queried job.
  public var job: Google_Cloud_Bigquery_Logging_V1_Job {
    get {return _job ?? Google_Cloud_Bigquery_Logging_V1_Job()}
    set {_job = newValue}
  }
  /// Returns true if `job` has been explicitly set.
  public var hasJob: Bool {return self._job != nil}
  /// Clears the value of `job`. Subsequent reads from it will return its default value.
  public mutating func clearJob() {self._job = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _job: Google_Cloud_Bigquery_Logging_V1_Job? = nil
}

/// Job getQueryResults request.
public struct Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Maximum number of results to return.
  public var maxResults: UInt32 = 0

  /// Zero-based row number at which to start.
  public var startRow: UInt64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Job getQueryResults response.
public struct Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Total number of results in query results.
  public var totalResults: UInt64 = 0

  /// The job that was created to run the query.
  /// It completed if `job.status.state` is `DONE`.
  /// It failed if `job.status.errorResult` is also present.
  public var job: Google_Cloud_Bigquery_Logging_V1_Job {
    get {return _job ?? Google_Cloud_Bigquery_Logging_V1_Job()}
    set {_job = newValue}
  }
  /// Returns true if `job` has been explicitly set.
  public var hasJob: Bool {return self._job != nil}
  /// Clears the value of `job`. Subsequent reads from it will return its default value.
  public mutating func clearJob() {self._job = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _job: Google_Cloud_Bigquery_Logging_V1_Job? = nil
}

/// Job getQueryDone response.
public struct Google_Cloud_Bigquery_Logging_V1_JobQueryDoneResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The job and status information.
  /// The job completed if `job.status.state` is `DONE`.
  public var job: Google_Cloud_Bigquery_Logging_V1_Job {
    get {return _job ?? Google_Cloud_Bigquery_Logging_V1_Job()}
    set {_job = newValue}
  }
  /// Returns true if `job` has been explicitly set.
  public var hasJob: Bool {return self._job != nil}
  /// Clears the value of `job`. Subsequent reads from it will return its default value.
  public mutating func clearJob() {self._job = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _job: Google_Cloud_Bigquery_Logging_V1_Job? = nil
}

/// Query job completed event.
public struct Google_Cloud_Bigquery_Logging_V1_JobCompletedEvent {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Name of the event.
  public var eventName: String = String()

  /// Job information.
  public var job: Google_Cloud_Bigquery_Logging_V1_Job {
    get {return _job ?? Google_Cloud_Bigquery_Logging_V1_Job()}
    set {_job = newValue}
  }
  /// Returns true if `job` has been explicitly set.
  public var hasJob: Bool {return self._job != nil}
  /// Clears the value of `job`. Subsequent reads from it will return its default value.
  public mutating func clearJob() {self._job = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _job: Google_Cloud_Bigquery_Logging_V1_Job? = nil
}

/// Table data read event. Only present for tables, not views, and is only
/// included in the log record for the project that owns the table.
public struct Google_Cloud_Bigquery_Logging_V1_TableDataReadEvent {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Name of the accessed table.
  public var tableName: Google_Cloud_Bigquery_Logging_V1_TableName {
    get {return _tableName ?? Google_Cloud_Bigquery_Logging_V1_TableName()}
    set {_tableName = newValue}
  }
  /// Returns true if `tableName` has been explicitly set.
  public var hasTableName: Bool {return self._tableName != nil}
  /// Clears the value of `tableName`. Subsequent reads from it will return its default value.
  public mutating func clearTableName() {self._tableName = nil}

  /// A list of referenced fields. This information is not included by default.
  /// To enable this in the logs, please contact BigQuery support or open a bug
  /// in the BigQuery issue tracker.
  public var referencedFields: [String] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _tableName: Google_Cloud_Bigquery_Logging_V1_TableName? = nil
}

/// Table data-list request.
public struct Google_Cloud_Bigquery_Logging_V1_TableDataListRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Starting row offset.
  public var startRow: UInt64 = 0

  /// Maximum number of results to return.
  public var maxResults: UInt32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Describes a BigQuery table.
/// See the [Table](/bigquery/docs/reference/v2/tables) API resource
/// for more details on individual fields.
/// Note: `Table.schema` has been deprecated in favor of `Table.schemaJson`.
/// `Table.schema` may continue to be present in your logs during this
/// transition.
public struct Google_Cloud_Bigquery_Logging_V1_Table {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The name of the table.
  public var tableName: Google_Cloud_Bigquery_Logging_V1_TableName {
    get {return _storage._tableName ?? Google_Cloud_Bigquery_Logging_V1_TableName()}
    set {_uniqueStorage()._tableName = newValue}
  }
  /// Returns true if `tableName` has been explicitly set.
  public var hasTableName: Bool {return _storage._tableName != nil}
  /// Clears the value of `tableName`. Subsequent reads from it will return its default value.
  public mutating func clearTableName() {_uniqueStorage()._tableName = nil}

  /// User-provided metadata for the table.
  public var info: Google_Cloud_Bigquery_Logging_V1_TableInfo {
    get {return _storage._info ?? Google_Cloud_Bigquery_Logging_V1_TableInfo()}
    set {_uniqueStorage()._info = newValue}
  }
  /// Returns true if `info` has been explicitly set.
  public var hasInfo: Bool {return _storage._info != nil}
  /// Clears the value of `info`. Subsequent reads from it will return its default value.
  public mutating func clearInfo() {_uniqueStorage()._info = nil}

  /// A JSON representation of the table's schema.
  public var schemaJson: String {
    get {return _storage._schemaJson}
    set {_uniqueStorage()._schemaJson = newValue}
  }

  /// If present, this is a virtual table defined by a SQL query.
  public var view: Google_Cloud_Bigquery_Logging_V1_TableViewDefinition {
    get {return _storage._view ?? Google_Cloud_Bigquery_Logging_V1_TableViewDefinition()}
    set {_uniqueStorage()._view = newValue}
  }
  /// Returns true if `view` has been explicitly set.
  public var hasView: Bool {return _storage._view != nil}
  /// Clears the value of `view`. Subsequent reads from it will return its default value.
  public mutating func clearView() {_uniqueStorage()._view = nil}

  /// The expiration date for the table, after which the table
  /// is deleted and the storage reclaimed.
  /// If not present, the table persists indefinitely.
  public var expireTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._expireTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._expireTime = newValue}
  }
  /// Returns true if `expireTime` has been explicitly set.
  public var hasExpireTime: Bool {return _storage._expireTime != nil}
  /// Clears the value of `expireTime`. Subsequent reads from it will return its default value.
  public mutating func clearExpireTime() {_uniqueStorage()._expireTime = nil}

  /// The time the table was created.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return _storage._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {_uniqueStorage()._createTime = nil}

  /// The time the table was last truncated
  /// by an operation with a `writeDisposition` of `WRITE_TRUNCATE`.
  public var truncateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._truncateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._truncateTime = newValue}
  }
  /// Returns true if `truncateTime` has been explicitly set.
  public var hasTruncateTime: Bool {return _storage._truncateTime != nil}
  /// Clears the value of `truncateTime`. Subsequent reads from it will return its default value.
  public mutating func clearTruncateTime() {_uniqueStorage()._truncateTime = nil}

  /// The time the table was last modified.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return _storage._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {_uniqueStorage()._updateTime = nil}

  /// The table encryption information. Set when non-default encryption is used.
  public var encryption: Google_Cloud_Bigquery_Logging_V1_EncryptionInfo {
    get {return _storage._encryption ?? Google_Cloud_Bigquery_Logging_V1_EncryptionInfo()}
    set {_uniqueStorage()._encryption = newValue}
  }
  /// Returns true if `encryption` has been explicitly set.
  public var hasEncryption: Bool {return _storage._encryption != nil}
  /// Clears the value of `encryption`. Subsequent reads from it will return its default value.
  public mutating func clearEncryption() {_uniqueStorage()._encryption = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// User-provided metadata for a table.
public struct Google_Cloud_Bigquery_Logging_V1_TableInfo {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// A short name for the table, such as`"Analytics Data - Jan 2011"`.
  public var friendlyName: String = String()

  /// A long description, perhaps several paragraphs,
  /// describing the table contents in detail.
  public var description_p: String = String()

  /// Labels provided for the table.
  public var labels: Dictionary<String,String> = [:]

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Describes a virtual table defined by a SQL query.
public struct Google_Cloud_Bigquery_Logging_V1_TableViewDefinition {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// SQL query defining the view.
  public var query: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// BigQuery dataset information.
/// See the [Dataset](/bigquery/docs/reference/v2/datasets) API resource
/// for more details on individual fields.
public struct Google_Cloud_Bigquery_Logging_V1_Dataset {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The name of the dataset.
  public var datasetName: Google_Cloud_Bigquery_Logging_V1_DatasetName {
    get {return _datasetName ?? Google_Cloud_Bigquery_Logging_V1_DatasetName()}
    set {_datasetName = newValue}
  }
  /// Returns true if `datasetName` has been explicitly set.
  public var hasDatasetName: Bool {return self._datasetName != nil}
  /// Clears the value of `datasetName`. Subsequent reads from it will return its default value.
  public mutating func clearDatasetName() {self._datasetName = nil}

  /// User-provided metadata for the dataset.
  public var info: Google_Cloud_Bigquery_Logging_V1_DatasetInfo {
    get {return _info ?? Google_Cloud_Bigquery_Logging_V1_DatasetInfo()}
    set {_info = newValue}
  }
  /// Returns true if `info` has been explicitly set.
  public var hasInfo: Bool {return self._info != nil}
  /// Clears the value of `info`. Subsequent reads from it will return its default value.
  public mutating func clearInfo() {self._info = nil}

  /// The time the dataset was created.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return self._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {self._createTime = nil}

  /// The time the dataset was last modified.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return self._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {self._updateTime = nil}

  /// The access control list for the dataset.
  public var acl: Google_Cloud_Bigquery_Logging_V1_BigQueryAcl {
    get {return _acl ?? Google_Cloud_Bigquery_Logging_V1_BigQueryAcl()}
    set {_acl = newValue}
  }
  /// Returns true if `acl` has been explicitly set.
  public var hasAcl: Bool {return self._acl != nil}
  /// Clears the value of `acl`. Subsequent reads from it will return its default value.
  public mutating func clearAcl() {self._acl = nil}

  /// If this field is present, each table that does not specify an
  /// expiration time is assigned an expiration time by adding this
  /// duration to the table's `createTime`.  If this field is empty,
  /// there is no default table expiration time.
  public var defaultTableExpireDuration: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _defaultTableExpireDuration ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_defaultTableExpireDuration = newValue}
  }
  /// Returns true if `defaultTableExpireDuration` has been explicitly set.
  public var hasDefaultTableExpireDuration: Bool {return self._defaultTableExpireDuration != nil}
  /// Clears the value of `defaultTableExpireDuration`. Subsequent reads from it will return its default value.
  public mutating func clearDefaultTableExpireDuration() {self._defaultTableExpireDuration = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _datasetName: Google_Cloud_Bigquery_Logging_V1_DatasetName? = nil
  fileprivate var _info: Google_Cloud_Bigquery_Logging_V1_DatasetInfo? = nil
  fileprivate var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
  fileprivate var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
  fileprivate var _acl: Google_Cloud_Bigquery_Logging_V1_BigQueryAcl? = nil
  fileprivate var _defaultTableExpireDuration: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

/// User-provided metadata for a dataset.
public struct Google_Cloud_Bigquery_Logging_V1_DatasetInfo {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// A short name for the dataset, such as`"Analytics Data 2011"`.
  public var friendlyName: String = String()

  /// A long description, perhaps several paragraphs,
  /// describing the dataset contents in detail.
  public var description_p: String = String()

  /// Labels provided for the dataset.
  public var labels: Dictionary<String,String> = [:]

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// An access control list.
public struct Google_Cloud_Bigquery_Logging_V1_BigQueryAcl {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Access control entry list.
  public var entries: [Google_Cloud_Bigquery_Logging_V1_BigQueryAcl.Entry] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Access control entry.
  public struct Entry {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// The granted role, which can be `READER`, `WRITER`, or `OWNER`.
    public var role: String = String()

    /// Grants access to a group identified by an email address.
    public var groupEmail: String = String()

    /// Grants access to a user identified by an email address.
    public var userEmail: String = String()

    /// Grants access to all members of a domain.
    public var domain: String = String()

    /// Grants access to special groups. Valid groups are `PROJECT_OWNERS`,
    /// `PROJECT_READERS`, `PROJECT_WRITERS` and `ALL_AUTHENTICATED_USERS`.
    public var specialGroup: String = String()

    /// Grants access to a BigQuery View.
    public var viewName: Google_Cloud_Bigquery_Logging_V1_TableName {
      get {return _viewName ?? Google_Cloud_Bigquery_Logging_V1_TableName()}
      set {_viewName = newValue}
    }
    /// Returns true if `viewName` has been explicitly set.
    public var hasViewName: Bool {return self._viewName != nil}
    /// Clears the value of `viewName`. Subsequent reads from it will return its default value.
    public mutating func clearViewName() {self._viewName = nil}

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}

    fileprivate var _viewName: Google_Cloud_Bigquery_Logging_V1_TableName? = nil
  }

  public init() {}
}

/// Describes a job.
public struct Google_Cloud_Bigquery_Logging_V1_Job {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Job name.
  public var jobName: Google_Cloud_Bigquery_Logging_V1_JobName {
    get {return _storage._jobName ?? Google_Cloud_Bigquery_Logging_V1_JobName()}
    set {_uniqueStorage()._jobName = newValue}
  }
  /// Returns true if `jobName` has been explicitly set.
  public var hasJobName: Bool {return _storage._jobName != nil}
  /// Clears the value of `jobName`. Subsequent reads from it will return its default value.
  public mutating func clearJobName() {_uniqueStorage()._jobName = nil}

  /// Job configuration.
  public var jobConfiguration: Google_Cloud_Bigquery_Logging_V1_JobConfiguration {
    get {return _storage._jobConfiguration ?? Google_Cloud_Bigquery_Logging_V1_JobConfiguration()}
    set {_uniqueStorage()._jobConfiguration = newValue}
  }
  /// Returns true if `jobConfiguration` has been explicitly set.
  public var hasJobConfiguration: Bool {return _storage._jobConfiguration != nil}
  /// Clears the value of `jobConfiguration`. Subsequent reads from it will return its default value.
  public mutating func clearJobConfiguration() {_uniqueStorage()._jobConfiguration = nil}

  /// Job status.
  public var jobStatus: Google_Cloud_Bigquery_Logging_V1_JobStatus {
    get {return _storage._jobStatus ?? Google_Cloud_Bigquery_Logging_V1_JobStatus()}
    set {_uniqueStorage()._jobStatus = newValue}
  }
  /// Returns true if `jobStatus` has been explicitly set.
  public var hasJobStatus: Bool {return _storage._jobStatus != nil}
  /// Clears the value of `jobStatus`. Subsequent reads from it will return its default value.
  public mutating func clearJobStatus() {_uniqueStorage()._jobStatus = nil}

  /// Job statistics.
  public var jobStatistics: Google_Cloud_Bigquery_Logging_V1_JobStatistics {
    get {return _storage._jobStatistics ?? Google_Cloud_Bigquery_Logging_V1_JobStatistics()}
    set {_uniqueStorage()._jobStatistics = newValue}
  }
  /// Returns true if `jobStatistics` has been explicitly set.
  public var hasJobStatistics: Bool {return _storage._jobStatistics != nil}
  /// Clears the value of `jobStatistics`. Subsequent reads from it will return its default value.
  public mutating func clearJobStatistics() {_uniqueStorage()._jobStatistics = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Job configuration information.
/// See the [Jobs](/bigquery/docs/reference/v2/jobs) API resource
/// for more details on individual fields.
public struct Google_Cloud_Bigquery_Logging_V1_JobConfiguration {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Job configuration information.
  public var configuration: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.OneOf_Configuration? = nil

  /// Query job information.
  public var query: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Query {
    get {
      if case .query(let v)? = configuration {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Query()
    }
    set {configuration = .query(newValue)}
  }

  /// Load job information.
  public var load: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Load {
    get {
      if case .load(let v)? = configuration {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Load()
    }
    set {configuration = .load(newValue)}
  }

  /// Extract job information.
  public var extract: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Extract {
    get {
      if case .extract(let v)? = configuration {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Extract()
    }
    set {configuration = .extract(newValue)}
  }

  /// TableCopy job information.
  public var tableCopy: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.TableCopy {
    get {
      if case .tableCopy(let v)? = configuration {return v}
      return Google_Cloud_Bigquery_Logging_V1_JobConfiguration.TableCopy()
    }
    set {configuration = .tableCopy(newValue)}
  }

  /// If true, don't actually run the job. Just check that it would run.
  public var dryRun: Bool = false

  /// Labels provided for the job.
  public var labels: Dictionary<String,String> = [:]

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Job configuration information.
  public enum OneOf_Configuration: Equatable {
    /// Query job information.
    case query(Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Query)
    /// Load job information.
    case load(Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Load)
    /// Extract job information.
    case extract(Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Extract)
    /// TableCopy job information.
    case tableCopy(Google_Cloud_Bigquery_Logging_V1_JobConfiguration.TableCopy)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.OneOf_Configuration, rhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.OneOf_Configuration) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.query, .query): return {
        guard case .query(let l) = lhs, case .query(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.load, .load): return {
        guard case .load(let l) = lhs, case .load(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.extract, .extract): return {
        guard case .extract(let l) = lhs, case .extract(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.tableCopy, .tableCopy): return {
        guard case .tableCopy(let l) = lhs, case .tableCopy(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  /// Describes a query job, which executes a SQL-like query.
  public struct Query {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// The SQL query to run.
    public var query: String = String()

    /// The table where results are written.
    public var destinationTable: Google_Cloud_Bigquery_Logging_V1_TableName {
      get {return _destinationTable ?? Google_Cloud_Bigquery_Logging_V1_TableName()}
      set {_destinationTable = newValue}
    }
    /// Returns true if `destinationTable` has been explicitly set.
    public var hasDestinationTable: Bool {return self._destinationTable != nil}
    /// Clears the value of `destinationTable`. Subsequent reads from it will return its default value.
    public mutating func clearDestinationTable() {self._destinationTable = nil}

    /// Describes when a job is allowed to create a table:
    /// `CREATE_IF_NEEDED`, `CREATE_NEVER`.
    public var createDisposition: String = String()

    /// Describes how writes affect existing tables:
    /// `WRITE_TRUNCATE`, `WRITE_APPEND`, `WRITE_EMPTY`.
    public var writeDisposition: String = String()

    /// If a table name is specified without a dataset in a query,
    /// this dataset will be added to table name.
    public var defaultDataset: Google_Cloud_Bigquery_Logging_V1_DatasetName {
      get {return _defaultDataset ?? Google_Cloud_Bigquery_Logging_V1_DatasetName()}
      set {_defaultDataset = newValue}
    }
    /// Returns true if `defaultDataset` has been explicitly set.
    public var hasDefaultDataset: Bool {return self._defaultDataset != nil}
    /// Clears the value of `defaultDataset`. Subsequent reads from it will return its default value.
    public mutating func clearDefaultDataset() {self._defaultDataset = nil}

    /// Describes data sources outside BigQuery, if needed.
    public var tableDefinitions: [Google_Cloud_Bigquery_Logging_V1_TableDefinition] = []

    /// Describes the priority given to the query:
    /// `QUERY_INTERACTIVE` or `QUERY_BATCH`.
    public var queryPriority: String = String()

    /// Result table encryption information. Set when non-default encryption is
    /// used.
    public var destinationTableEncryption: Google_Cloud_Bigquery_Logging_V1_EncryptionInfo {
      get {return _destinationTableEncryption ?? Google_Cloud_Bigquery_Logging_V1_EncryptionInfo()}
      set {_destinationTableEncryption = newValue}
    }
    /// Returns true if `destinationTableEncryption` has been explicitly set.
    public var hasDestinationTableEncryption: Bool {return self._destinationTableEncryption != nil}
    /// Clears the value of `destinationTableEncryption`. Subsequent reads from it will return its default value.
    public mutating func clearDestinationTableEncryption() {self._destinationTableEncryption = nil}

    /// Type of the statement (e.g. SELECT, INSERT, CREATE_TABLE, CREATE_MODEL..)
    public var statementType: String = String()

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}

    fileprivate var _destinationTable: Google_Cloud_Bigquery_Logging_V1_TableName? = nil
    fileprivate var _defaultDataset: Google_Cloud_Bigquery_Logging_V1_DatasetName? = nil
    fileprivate var _destinationTableEncryption: Google_Cloud_Bigquery_Logging_V1_EncryptionInfo? = nil
  }

  /// Describes a load job, which loads data from an external source via
  /// the  import pipeline.
  public struct Load {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// URIs for the data to be imported. Only Google Cloud Storage URIs are
    /// supported.
    public var sourceUris: [String] = []

    /// The table schema in JSON format representation of a TableSchema.
    public var schemaJson: String = String()

    /// The table where the imported data is written.
    public var destinationTable: Google_Cloud_Bigquery_Logging_V1_TableName {
      get {return _destinationTable ?? Google_Cloud_Bigquery_Logging_V1_TableName()}
      set {_destinationTable = newValue}
    }
    /// Returns true if `destinationTable` has been explicitly set.
    public var hasDestinationTable: Bool {return self._destinationTable != nil}
    /// Clears the value of `destinationTable`. Subsequent reads from it will return its default value.
    public mutating func clearDestinationTable() {self._destinationTable = nil}

    /// Describes when a job is allowed to create a table:
    /// `CREATE_IF_NEEDED`, `CREATE_NEVER`.
    public var createDisposition: String = String()

    /// Describes how writes affect existing tables:
    /// `WRITE_TRUNCATE`, `WRITE_APPEND`, `WRITE_EMPTY`.
    public var writeDisposition: String = String()

    /// Result table encryption information. Set when non-default encryption is
    /// used.
    public var destinationTableEncryption: Google_Cloud_Bigquery_Logging_V1_EncryptionInfo {
      get {return _destinationTableEncryption ?? Google_Cloud_Bigquery_Logging_V1_EncryptionInfo()}
      set {_destinationTableEncryption = newValue}
    }
    /// Returns true if `destinationTableEncryption` has been explicitly set.
    public var hasDestinationTableEncryption: Bool {return self._destinationTableEncryption != nil}
    /// Clears the value of `destinationTableEncryption`. Subsequent reads from it will return its default value.
    public mutating func clearDestinationTableEncryption() {self._destinationTableEncryption = nil}

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}

    fileprivate var _destinationTable: Google_Cloud_Bigquery_Logging_V1_TableName? = nil
    fileprivate var _destinationTableEncryption: Google_Cloud_Bigquery_Logging_V1_EncryptionInfo? = nil
  }

  /// Describes an extract job, which exports data to an external source
  /// via the  export pipeline.
  public struct Extract {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Google Cloud Storage URIs where extracted data should be written.
    public var destinationUris: [String] = []

    /// The source table.
    public var sourceTable: Google_Cloud_Bigquery_Logging_V1_TableName {
      get {return _sourceTable ?? Google_Cloud_Bigquery_Logging_V1_TableName()}
      set {_sourceTable = newValue}
    }
    /// Returns true if `sourceTable` has been explicitly set.
    public var hasSourceTable: Bool {return self._sourceTable != nil}
    /// Clears the value of `sourceTable`. Subsequent reads from it will return its default value.
    public mutating func clearSourceTable() {self._sourceTable = nil}

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}

    fileprivate var _sourceTable: Google_Cloud_Bigquery_Logging_V1_TableName? = nil
  }

  /// Describes a copy job, which copies an existing table to another table.
  public struct TableCopy {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Source tables.
    public var sourceTables: [Google_Cloud_Bigquery_Logging_V1_TableName] = []

    /// Destination table.
    public var destinationTable: Google_Cloud_Bigquery_Logging_V1_TableName {
      get {return _destinationTable ?? Google_Cloud_Bigquery_Logging_V1_TableName()}
      set {_destinationTable = newValue}
    }
    /// Returns true if `destinationTable` has been explicitly set.
    public var hasDestinationTable: Bool {return self._destinationTable != nil}
    /// Clears the value of `destinationTable`. Subsequent reads from it will return its default value.
    public mutating func clearDestinationTable() {self._destinationTable = nil}

    /// Describes when a job is allowed to create a table:
    /// `CREATE_IF_NEEDED`, `CREATE_NEVER`.
    public var createDisposition: String = String()

    /// Describes how writes affect existing tables:
    /// `WRITE_TRUNCATE`, `WRITE_APPEND`, `WRITE_EMPTY`.
    public var writeDisposition: String = String()

    /// Result table encryption information. Set when non-default encryption is
    /// used.
    public var destinationTableEncryption: Google_Cloud_Bigquery_Logging_V1_EncryptionInfo {
      get {return _destinationTableEncryption ?? Google_Cloud_Bigquery_Logging_V1_EncryptionInfo()}
      set {_destinationTableEncryption = newValue}
    }
    /// Returns true if `destinationTableEncryption` has been explicitly set.
    public var hasDestinationTableEncryption: Bool {return self._destinationTableEncryption != nil}
    /// Clears the value of `destinationTableEncryption`. Subsequent reads from it will return its default value.
    public mutating func clearDestinationTableEncryption() {self._destinationTableEncryption = nil}

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}

    fileprivate var _destinationTable: Google_Cloud_Bigquery_Logging_V1_TableName? = nil
    fileprivate var _destinationTableEncryption: Google_Cloud_Bigquery_Logging_V1_EncryptionInfo? = nil
  }

  public init() {}
}

/// Describes an external data source used in a query.
public struct Google_Cloud_Bigquery_Logging_V1_TableDefinition {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Name of the table, used in queries.
  public var name: String = String()

  /// Google Cloud Storage URIs for the data to be imported.
  public var sourceUris: [String] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Running state of a job.
public struct Google_Cloud_Bigquery_Logging_V1_JobStatus {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// State of a job: `PENDING`, `RUNNING`, or `DONE`.
  public var state: String = String()

  /// If the job did not complete successfully, this field describes why.
  public var error: Google_Rpc_Status {
    get {return _error ?? Google_Rpc_Status()}
    set {_error = newValue}
  }
  /// Returns true if `error` has been explicitly set.
  public var hasError: Bool {return self._error != nil}
  /// Clears the value of `error`. Subsequent reads from it will return its default value.
  public mutating func clearError() {self._error = nil}

  /// Errors encountered during the running of the job. Do not necessarily mean
  /// that the job has completed or was unsuccessful.
  public var additionalErrors: [Google_Rpc_Status] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _error: Google_Rpc_Status? = nil
}

/// Job statistics that may change after a job starts.
public struct Google_Cloud_Bigquery_Logging_V1_JobStatistics {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Time when the job was created.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return _storage._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {_uniqueStorage()._createTime = nil}

  /// Time when the job started.
  public var startTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._startTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._startTime = newValue}
  }
  /// Returns true if `startTime` has been explicitly set.
  public var hasStartTime: Bool {return _storage._startTime != nil}
  /// Clears the value of `startTime`. Subsequent reads from it will return its default value.
  public mutating func clearStartTime() {_uniqueStorage()._startTime = nil}

  /// Time when the job ended.
  public var endTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._endTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._endTime = newValue}
  }
  /// Returns true if `endTime` has been explicitly set.
  public var hasEndTime: Bool {return _storage._endTime != nil}
  /// Clears the value of `endTime`. Subsequent reads from it will return its default value.
  public mutating func clearEndTime() {_uniqueStorage()._endTime = nil}

  /// Total bytes processed for a job.
  public var totalProcessedBytes: Int64 {
    get {return _storage._totalProcessedBytes}
    set {_uniqueStorage()._totalProcessedBytes = newValue}
  }

  /// Processed bytes, adjusted by the job's CPU usage.
  public var totalBilledBytes: Int64 {
    get {return _storage._totalBilledBytes}
    set {_uniqueStorage()._totalBilledBytes = newValue}
  }

  /// The tier assigned by CPU-based billing.
  public var billingTier: Int32 {
    get {return _storage._billingTier}
    set {_uniqueStorage()._billingTier = newValue}
  }

  /// The total number of slot-ms consumed by the query job.
  public var totalSlotMs: Int64 {
    get {return _storage._totalSlotMs}
    set {_uniqueStorage()._totalSlotMs = newValue}
  }

  /// Reservation usage.
  public var reservationUsage: [Google_Cloud_Bigquery_Logging_V1_JobStatistics.ReservationResourceUsage] {
    get {return _storage._reservationUsage}
    set {_uniqueStorage()._reservationUsage = newValue}
  }

  /// The first N tables accessed by the query job. Older queries that
  /// reference a large number of tables may not have all of their
  /// tables in this list. You can use the total_tables_processed count to
  /// know how many total tables were read in the query. For new queries,
  /// there is currently no limit.
  public var referencedTables: [Google_Cloud_Bigquery_Logging_V1_TableName] {
    get {return _storage._referencedTables}
    set {_uniqueStorage()._referencedTables = newValue}
  }

  /// Total number of unique tables referenced in the query.
  public var totalTablesProcessed: Int32 {
    get {return _storage._totalTablesProcessed}
    set {_uniqueStorage()._totalTablesProcessed = newValue}
  }

  /// The first N views accessed by the query job. Older queries that
  /// reference a large number of views may not have all of their
  /// views in this list. You can use the total_tables_processed count to
  /// know how many total tables were read in the query. For new queries,
  /// there is currently no limit.
  public var referencedViews: [Google_Cloud_Bigquery_Logging_V1_TableName] {
    get {return _storage._referencedViews}
    set {_uniqueStorage()._referencedViews = newValue}
  }

  /// Total number of unique views referenced in the query.
  public var totalViewsProcessed: Int32 {
    get {return _storage._totalViewsProcessed}
    set {_uniqueStorage()._totalViewsProcessed = newValue}
  }

  /// Number of output rows produced by the query job.
  public var queryOutputRowCount: Int64 {
    get {return _storage._queryOutputRowCount}
    set {_uniqueStorage()._queryOutputRowCount = newValue}
  }

  /// Total bytes loaded for an import job.
  public var totalLoadOutputBytes: Int64 {
    get {return _storage._totalLoadOutputBytes}
    set {_uniqueStorage()._totalLoadOutputBytes = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Job resource usage breakdown by reservation.
  public struct ReservationResourceUsage {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Reservation name or "unreserved" for on-demand resources usage.
    public var name: String = String()

    /// Total slot milliseconds used by the reservation for a particular job.
    public var slotMs: Int64 = 0

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// The fully-qualified name for a dataset.
public struct Google_Cloud_Bigquery_Logging_V1_DatasetName {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The project ID.
  public var projectID: String = String()

  /// The dataset ID within the project.
  public var datasetID: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// The fully-qualified name for a table.
public struct Google_Cloud_Bigquery_Logging_V1_TableName {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The project ID.
  public var projectID: String = String()

  /// The dataset ID within the project.
  public var datasetID: String = String()

  /// The table ID of the table within the dataset.
  public var tableID: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// The fully-qualified name for a job.
public struct Google_Cloud_Bigquery_Logging_V1_JobName {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The project ID.
  public var projectID: String = String()

  /// The job ID within the project.
  public var jobID: String = String()

  /// The job location.
  public var location: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Describes encryption properties for a table or a job
public struct Google_Cloud_Bigquery_Logging_V1_EncryptionInfo {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// unique identifier for cloud kms key
  public var kmsKeyName: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.logging.v1"

extension Google_Cloud_Bigquery_Logging_V1_AuditData: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AuditData"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "table_insert_request"),
    16: .standard(proto: "table_update_request"),
    2: .standard(proto: "dataset_list_request"),
    3: .standard(proto: "dataset_insert_request"),
    4: .standard(proto: "dataset_update_request"),
    5: .standard(proto: "job_insert_request"),
    6: .standard(proto: "job_query_request"),
    7: .standard(proto: "job_get_query_results_request"),
    8: .standard(proto: "table_data_list_request"),
    20: .standard(proto: "set_iam_policy_request"),
    9: .standard(proto: "table_insert_response"),
    10: .standard(proto: "table_update_response"),
    11: .standard(proto: "dataset_insert_response"),
    12: .standard(proto: "dataset_update_response"),
    18: .standard(proto: "job_insert_response"),
    13: .standard(proto: "job_query_response"),
    14: .standard(proto: "job_get_query_results_response"),
    15: .standard(proto: "job_query_done_response"),
    21: .standard(proto: "policy_response"),
    17: .standard(proto: "job_completed_event"),
    19: .standard(proto: "table_data_read_events"),
  ]

  fileprivate class _StorageClass {
    var _request: Google_Cloud_Bigquery_Logging_V1_AuditData.OneOf_Request?
    var _response: Google_Cloud_Bigquery_Logging_V1_AuditData.OneOf_Response?
    var _jobCompletedEvent: Google_Cloud_Bigquery_Logging_V1_JobCompletedEvent? = nil
    var _tableDataReadEvents: [Google_Cloud_Bigquery_Logging_V1_TableDataReadEvent] = []

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _request = source._request
      _response = source._response
      _jobCompletedEvent = source._jobCompletedEvent
      _tableDataReadEvents = source._tableDataReadEvents
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try {
          var v: Google_Cloud_Bigquery_Logging_V1_TableInsertRequest?
          if let current = _storage._request {
            try decoder.handleConflictingOneOf()
            if case .tableInsertRequest(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._request = .tableInsertRequest(v)}
        }()
        case 2: try {
          var v: Google_Cloud_Bigquery_Logging_V1_DatasetListRequest?
          if let current = _storage._request {
            try decoder.handleConflictingOneOf()
            if case .datasetListRequest(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._request = .datasetListRequest(v)}
        }()
        case 3: try {
          var v: Google_Cloud_Bigquery_Logging_V1_DatasetInsertRequest?
          if let current = _storage._request {
            try decoder.handleConflictingOneOf()
            if case .datasetInsertRequest(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._request = .datasetInsertRequest(v)}
        }()
        case 4: try {
          var v: Google_Cloud_Bigquery_Logging_V1_DatasetUpdateRequest?
          if let current = _storage._request {
            try decoder.handleConflictingOneOf()
            if case .datasetUpdateRequest(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._request = .datasetUpdateRequest(v)}
        }()
        case 5: try {
          var v: Google_Cloud_Bigquery_Logging_V1_JobInsertRequest?
          if let current = _storage._request {
            try decoder.handleConflictingOneOf()
            if case .jobInsertRequest(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._request = .jobInsertRequest(v)}
        }()
        case 6: try {
          var v: Google_Cloud_Bigquery_Logging_V1_JobQueryRequest?
          if let current = _storage._request {
            try decoder.handleConflictingOneOf()
            if case .jobQueryRequest(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._request = .jobQueryRequest(v)}
        }()
        case 7: try {
          var v: Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsRequest?
          if let current = _storage._request {
            try decoder.handleConflictingOneOf()
            if case .jobGetQueryResultsRequest(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._request = .jobGetQueryResultsRequest(v)}
        }()
        case 8: try {
          var v: Google_Cloud_Bigquery_Logging_V1_TableDataListRequest?
          if let current = _storage._request {
            try decoder.handleConflictingOneOf()
            if case .tableDataListRequest(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._request = .tableDataListRequest(v)}
        }()
        case 9: try {
          var v: Google_Cloud_Bigquery_Logging_V1_TableInsertResponse?
          if let current = _storage._response {
            try decoder.handleConflictingOneOf()
            if case .tableInsertResponse(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._response = .tableInsertResponse(v)}
        }()
        case 10: try {
          var v: Google_Cloud_Bigquery_Logging_V1_TableUpdateResponse?
          if let current = _storage._response {
            try decoder.handleConflictingOneOf()
            if case .tableUpdateResponse(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._response = .tableUpdateResponse(v)}
        }()
        case 11: try {
          var v: Google_Cloud_Bigquery_Logging_V1_DatasetInsertResponse?
          if let current = _storage._response {
            try decoder.handleConflictingOneOf()
            if case .datasetInsertResponse(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._response = .datasetInsertResponse(v)}
        }()
        case 12: try {
          var v: Google_Cloud_Bigquery_Logging_V1_DatasetUpdateResponse?
          if let current = _storage._response {
            try decoder.handleConflictingOneOf()
            if case .datasetUpdateResponse(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._response = .datasetUpdateResponse(v)}
        }()
        case 13: try {
          var v: Google_Cloud_Bigquery_Logging_V1_JobQueryResponse?
          if let current = _storage._response {
            try decoder.handleConflictingOneOf()
            if case .jobQueryResponse(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._response = .jobQueryResponse(v)}
        }()
        case 14: try {
          var v: Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsResponse?
          if let current = _storage._response {
            try decoder.handleConflictingOneOf()
            if case .jobGetQueryResultsResponse(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._response = .jobGetQueryResultsResponse(v)}
        }()
        case 15: try {
          var v: Google_Cloud_Bigquery_Logging_V1_JobQueryDoneResponse?
          if let current = _storage._response {
            try decoder.handleConflictingOneOf()
            if case .jobQueryDoneResponse(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._response = .jobQueryDoneResponse(v)}
        }()
        case 16: try {
          var v: Google_Cloud_Bigquery_Logging_V1_TableUpdateRequest?
          if let current = _storage._request {
            try decoder.handleConflictingOneOf()
            if case .tableUpdateRequest(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._request = .tableUpdateRequest(v)}
        }()
        case 17: try { try decoder.decodeSingularMessageField(value: &_storage._jobCompletedEvent) }()
        case 18: try {
          var v: Google_Cloud_Bigquery_Logging_V1_JobInsertResponse?
          if let current = _storage._response {
            try decoder.handleConflictingOneOf()
            if case .jobInsertResponse(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._response = .jobInsertResponse(v)}
        }()
        case 19: try { try decoder.decodeRepeatedMessageField(value: &_storage._tableDataReadEvents) }()
        case 20: try {
          var v: Google_Iam_V1_SetIamPolicyRequest?
          if let current = _storage._request {
            try decoder.handleConflictingOneOf()
            if case .setIamPolicyRequest(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._request = .setIamPolicyRequest(v)}
        }()
        case 21: try {
          var v: Google_Iam_V1_Policy?
          if let current = _storage._response {
            try decoder.handleConflictingOneOf()
            if case .policyResponse(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._response = .policyResponse(v)}
        }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch _storage._request {
      case .tableInsertRequest?: try {
        guard case .tableInsertRequest(let v)? = _storage._request else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }()
      case .datasetListRequest?: try {
        guard case .datasetListRequest(let v)? = _storage._request else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }()
      case .datasetInsertRequest?: try {
        guard case .datasetInsertRequest(let v)? = _storage._request else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }()
      case .datasetUpdateRequest?: try {
        guard case .datasetUpdateRequest(let v)? = _storage._request else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }()
      case .jobInsertRequest?: try {
        guard case .jobInsertRequest(let v)? = _storage._request else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      }()
      case .jobQueryRequest?: try {
        guard case .jobQueryRequest(let v)? = _storage._request else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      }()
      case .jobGetQueryResultsRequest?: try {
        guard case .jobGetQueryResultsRequest(let v)? = _storage._request else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      }()
      case .tableDataListRequest?: try {
        guard case .tableDataListRequest(let v)? = _storage._request else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      }()
      default: break
      }
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch _storage._response {
      case .tableInsertResponse?: try {
        guard case .tableInsertResponse(let v)? = _storage._response else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      }()
      case .tableUpdateResponse?: try {
        guard case .tableUpdateResponse(let v)? = _storage._response else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      }()
      case .datasetInsertResponse?: try {
        guard case .datasetInsertResponse(let v)? = _storage._response else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      }()
      case .datasetUpdateResponse?: try {
        guard case .datasetUpdateResponse(let v)? = _storage._response else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      }()
      case .jobQueryResponse?: try {
        guard case .jobQueryResponse(let v)? = _storage._response else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
      }()
      case .jobGetQueryResultsResponse?: try {
        guard case .jobGetQueryResultsResponse(let v)? = _storage._response else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      }()
      case .jobQueryDoneResponse?: try {
        guard case .jobQueryDoneResponse(let v)? = _storage._response else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 15)
      }()
      default: break
      }
      if case .tableUpdateRequest(let v)? = _storage._request {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
      }
      if let v = _storage._jobCompletedEvent {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
      }
      if case .jobInsertResponse(let v)? = _storage._response {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
      }
      if !_storage._tableDataReadEvents.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._tableDataReadEvents, fieldNumber: 19)
      }
      if case .setIamPolicyRequest(let v)? = _storage._request {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
      }
      if case .policyResponse(let v)? = _storage._response {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_AuditData, rhs: Google_Cloud_Bigquery_Logging_V1_AuditData) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._request != rhs_storage._request {return false}
        if _storage._response != rhs_storage._response {return false}
        if _storage._jobCompletedEvent != rhs_storage._jobCompletedEvent {return false}
        if _storage._tableDataReadEvents != rhs_storage._tableDataReadEvents {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_TableInsertRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TableInsertRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "resource"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._resource) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._resource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_TableInsertRequest, rhs: Google_Cloud_Bigquery_Logging_V1_TableInsertRequest) -> Bool {
    if lhs._resource != rhs._resource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_TableUpdateRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TableUpdateRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "resource"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._resource) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._resource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_TableUpdateRequest, rhs: Google_Cloud_Bigquery_Logging_V1_TableUpdateRequest) -> Bool {
    if lhs._resource != rhs._resource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_TableInsertResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TableInsertResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "resource"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._resource) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._resource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_TableInsertResponse, rhs: Google_Cloud_Bigquery_Logging_V1_TableInsertResponse) -> Bool {
    if lhs._resource != rhs._resource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_TableUpdateResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TableUpdateResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "resource"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._resource) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._resource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_TableUpdateResponse, rhs: Google_Cloud_Bigquery_Logging_V1_TableUpdateResponse) -> Bool {
    if lhs._resource != rhs._resource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_DatasetListRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DatasetListRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "list_all"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.listAll) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.listAll != false {
      try visitor.visitSingularBoolField(value: self.listAll, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_DatasetListRequest, rhs: Google_Cloud_Bigquery_Logging_V1_DatasetListRequest) -> Bool {
    if lhs.listAll != rhs.listAll {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_DatasetInsertRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DatasetInsertRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "resource"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._resource) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._resource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_DatasetInsertRequest, rhs: Google_Cloud_Bigquery_Logging_V1_DatasetInsertRequest) -> Bool {
    if lhs._resource != rhs._resource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_DatasetInsertResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DatasetInsertResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "resource"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._resource) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._resource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_DatasetInsertResponse, rhs: Google_Cloud_Bigquery_Logging_V1_DatasetInsertResponse) -> Bool {
    if lhs._resource != rhs._resource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_DatasetUpdateRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DatasetUpdateRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "resource"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._resource) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._resource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_DatasetUpdateRequest, rhs: Google_Cloud_Bigquery_Logging_V1_DatasetUpdateRequest) -> Bool {
    if lhs._resource != rhs._resource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_DatasetUpdateResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DatasetUpdateResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "resource"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._resource) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._resource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_DatasetUpdateResponse, rhs: Google_Cloud_Bigquery_Logging_V1_DatasetUpdateResponse) -> Bool {
    if lhs._resource != rhs._resource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobInsertRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobInsertRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "resource"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._resource) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._resource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobInsertRequest, rhs: Google_Cloud_Bigquery_Logging_V1_JobInsertRequest) -> Bool {
    if lhs._resource != rhs._resource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobInsertResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobInsertResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "resource"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._resource) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._resource {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobInsertResponse, rhs: Google_Cloud_Bigquery_Logging_V1_JobInsertResponse) -> Bool {
    if lhs._resource != rhs._resource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobQueryRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobQueryRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "query"),
    2: .standard(proto: "max_results"),
    3: .standard(proto: "default_dataset"),
    4: .standard(proto: "project_id"),
    5: .standard(proto: "dry_run"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.query) }()
      case 2: try { try decoder.decodeSingularUInt32Field(value: &self.maxResults) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._defaultDataset) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 5: try { try decoder.decodeSingularBoolField(value: &self.dryRun) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.query.isEmpty {
      try visitor.visitSingularStringField(value: self.query, fieldNumber: 1)
    }
    if self.maxResults != 0 {
      try visitor.visitSingularUInt32Field(value: self.maxResults, fieldNumber: 2)
    }
    if let v = self._defaultDataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 4)
    }
    if self.dryRun != false {
      try visitor.visitSingularBoolField(value: self.dryRun, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobQueryRequest, rhs: Google_Cloud_Bigquery_Logging_V1_JobQueryRequest) -> Bool {
    if lhs.query != rhs.query {return false}
    if lhs.maxResults != rhs.maxResults {return false}
    if lhs._defaultDataset != rhs._defaultDataset {return false}
    if lhs.projectID != rhs.projectID {return false}
    if lhs.dryRun != rhs.dryRun {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobQueryResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobQueryResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "total_results"),
    2: .same(proto: "job"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.totalResults) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._job) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.totalResults != 0 {
      try visitor.visitSingularUInt64Field(value: self.totalResults, fieldNumber: 1)
    }
    if let v = self._job {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobQueryResponse, rhs: Google_Cloud_Bigquery_Logging_V1_JobQueryResponse) -> Bool {
    if lhs.totalResults != rhs.totalResults {return false}
    if lhs._job != rhs._job {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobGetQueryResultsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "max_results"),
    2: .standard(proto: "start_row"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.maxResults) }()
      case 2: try { try decoder.decodeSingularUInt64Field(value: &self.startRow) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.maxResults != 0 {
      try visitor.visitSingularUInt32Field(value: self.maxResults, fieldNumber: 1)
    }
    if self.startRow != 0 {
      try visitor.visitSingularUInt64Field(value: self.startRow, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsRequest, rhs: Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsRequest) -> Bool {
    if lhs.maxResults != rhs.maxResults {return false}
    if lhs.startRow != rhs.startRow {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobGetQueryResultsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "total_results"),
    2: .same(proto: "job"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.totalResults) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._job) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.totalResults != 0 {
      try visitor.visitSingularUInt64Field(value: self.totalResults, fieldNumber: 1)
    }
    if let v = self._job {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsResponse, rhs: Google_Cloud_Bigquery_Logging_V1_JobGetQueryResultsResponse) -> Bool {
    if lhs.totalResults != rhs.totalResults {return false}
    if lhs._job != rhs._job {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobQueryDoneResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobQueryDoneResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "job"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._job) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._job {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobQueryDoneResponse, rhs: Google_Cloud_Bigquery_Logging_V1_JobQueryDoneResponse) -> Bool {
    if lhs._job != rhs._job {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobCompletedEvent: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobCompletedEvent"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "event_name"),
    2: .same(proto: "job"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.eventName) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._job) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.eventName.isEmpty {
      try visitor.visitSingularStringField(value: self.eventName, fieldNumber: 1)
    }
    if let v = self._job {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobCompletedEvent, rhs: Google_Cloud_Bigquery_Logging_V1_JobCompletedEvent) -> Bool {
    if lhs.eventName != rhs.eventName {return false}
    if lhs._job != rhs._job {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_TableDataReadEvent: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TableDataReadEvent"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "table_name"),
    2: .standard(proto: "referenced_fields"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._tableName) }()
      case 2: try { try decoder.decodeRepeatedStringField(value: &self.referencedFields) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._tableName {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if !self.referencedFields.isEmpty {
      try visitor.visitRepeatedStringField(value: self.referencedFields, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_TableDataReadEvent, rhs: Google_Cloud_Bigquery_Logging_V1_TableDataReadEvent) -> Bool {
    if lhs._tableName != rhs._tableName {return false}
    if lhs.referencedFields != rhs.referencedFields {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_TableDataListRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TableDataListRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "start_row"),
    2: .standard(proto: "max_results"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt64Field(value: &self.startRow) }()
      case 2: try { try decoder.decodeSingularUInt32Field(value: &self.maxResults) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.startRow != 0 {
      try visitor.visitSingularUInt64Field(value: self.startRow, fieldNumber: 1)
    }
    if self.maxResults != 0 {
      try visitor.visitSingularUInt32Field(value: self.maxResults, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_TableDataListRequest, rhs: Google_Cloud_Bigquery_Logging_V1_TableDataListRequest) -> Bool {
    if lhs.startRow != rhs.startRow {return false}
    if lhs.maxResults != rhs.maxResults {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_Table: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Table"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "table_name"),
    2: .same(proto: "info"),
    8: .standard(proto: "schema_json"),
    4: .same(proto: "view"),
    5: .standard(proto: "expire_time"),
    6: .standard(proto: "create_time"),
    7: .standard(proto: "truncate_time"),
    9: .standard(proto: "update_time"),
    10: .same(proto: "encryption"),
  ]

  fileprivate class _StorageClass {
    var _tableName: Google_Cloud_Bigquery_Logging_V1_TableName? = nil
    var _info: Google_Cloud_Bigquery_Logging_V1_TableInfo? = nil
    var _schemaJson: String = String()
    var _view: Google_Cloud_Bigquery_Logging_V1_TableViewDefinition? = nil
    var _expireTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _truncateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _encryption: Google_Cloud_Bigquery_Logging_V1_EncryptionInfo? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _tableName = source._tableName
      _info = source._info
      _schemaJson = source._schemaJson
      _view = source._view
      _expireTime = source._expireTime
      _createTime = source._createTime
      _truncateTime = source._truncateTime
      _updateTime = source._updateTime
      _encryption = source._encryption
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._tableName) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._info) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._view) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._expireTime) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._createTime) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._truncateTime) }()
        case 8: try { try decoder.decodeSingularStringField(value: &_storage._schemaJson) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._updateTime) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._encryption) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if let v = _storage._tableName {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }
      if let v = _storage._info {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if let v = _storage._view {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }
      if let v = _storage._expireTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      }
      if let v = _storage._createTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      }
      if let v = _storage._truncateTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      }
      if !_storage._schemaJson.isEmpty {
        try visitor.visitSingularStringField(value: _storage._schemaJson, fieldNumber: 8)
      }
      if let v = _storage._updateTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      }
      if let v = _storage._encryption {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_Table, rhs: Google_Cloud_Bigquery_Logging_V1_Table) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._tableName != rhs_storage._tableName {return false}
        if _storage._info != rhs_storage._info {return false}
        if _storage._schemaJson != rhs_storage._schemaJson {return false}
        if _storage._view != rhs_storage._view {return false}
        if _storage._expireTime != rhs_storage._expireTime {return false}
        if _storage._createTime != rhs_storage._createTime {return false}
        if _storage._truncateTime != rhs_storage._truncateTime {return false}
        if _storage._updateTime != rhs_storage._updateTime {return false}
        if _storage._encryption != rhs_storage._encryption {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_TableInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TableInfo"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "friendly_name"),
    2: .same(proto: "description"),
    3: .same(proto: "labels"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.friendlyName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.description_p) }()
      case 3: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.labels) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.friendlyName.isEmpty {
      try visitor.visitSingularStringField(value: self.friendlyName, fieldNumber: 1)
    }
    if !self.description_p.isEmpty {
      try visitor.visitSingularStringField(value: self.description_p, fieldNumber: 2)
    }
    if !self.labels.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.labels, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_TableInfo, rhs: Google_Cloud_Bigquery_Logging_V1_TableInfo) -> Bool {
    if lhs.friendlyName != rhs.friendlyName {return false}
    if lhs.description_p != rhs.description_p {return false}
    if lhs.labels != rhs.labels {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_TableViewDefinition: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TableViewDefinition"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "query"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.query) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.query.isEmpty {
      try visitor.visitSingularStringField(value: self.query, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_TableViewDefinition, rhs: Google_Cloud_Bigquery_Logging_V1_TableViewDefinition) -> Bool {
    if lhs.query != rhs.query {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_Dataset: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Dataset"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "dataset_name"),
    2: .same(proto: "info"),
    4: .standard(proto: "create_time"),
    5: .standard(proto: "update_time"),
    6: .same(proto: "acl"),
    8: .standard(proto: "default_table_expire_duration"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._datasetName) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._info) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._createTime) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._updateTime) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._acl) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._defaultTableExpireDuration) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._datasetName {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._info {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if let v = self._createTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    if let v = self._updateTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }
    if let v = self._acl {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }
    if let v = self._defaultTableExpireDuration {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_Dataset, rhs: Google_Cloud_Bigquery_Logging_V1_Dataset) -> Bool {
    if lhs._datasetName != rhs._datasetName {return false}
    if lhs._info != rhs._info {return false}
    if lhs._createTime != rhs._createTime {return false}
    if lhs._updateTime != rhs._updateTime {return false}
    if lhs._acl != rhs._acl {return false}
    if lhs._defaultTableExpireDuration != rhs._defaultTableExpireDuration {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_DatasetInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DatasetInfo"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "friendly_name"),
    2: .same(proto: "description"),
    3: .same(proto: "labels"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.friendlyName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.description_p) }()
      case 3: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.labels) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.friendlyName.isEmpty {
      try visitor.visitSingularStringField(value: self.friendlyName, fieldNumber: 1)
    }
    if !self.description_p.isEmpty {
      try visitor.visitSingularStringField(value: self.description_p, fieldNumber: 2)
    }
    if !self.labels.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.labels, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_DatasetInfo, rhs: Google_Cloud_Bigquery_Logging_V1_DatasetInfo) -> Bool {
    if lhs.friendlyName != rhs.friendlyName {return false}
    if lhs.description_p != rhs.description_p {return false}
    if lhs.labels != rhs.labels {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_BigQueryAcl: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BigQueryAcl"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "entries"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.entries) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.entries.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.entries, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_BigQueryAcl, rhs: Google_Cloud_Bigquery_Logging_V1_BigQueryAcl) -> Bool {
    if lhs.entries != rhs.entries {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_BigQueryAcl.Entry: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Bigquery_Logging_V1_BigQueryAcl.protoMessageName + ".Entry"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "role"),
    2: .standard(proto: "group_email"),
    3: .standard(proto: "user_email"),
    4: .same(proto: "domain"),
    5: .standard(proto: "special_group"),
    6: .standard(proto: "view_name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.role) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.groupEmail) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.userEmail) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.domain) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.specialGroup) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._viewName) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.role.isEmpty {
      try visitor.visitSingularStringField(value: self.role, fieldNumber: 1)
    }
    if !self.groupEmail.isEmpty {
      try visitor.visitSingularStringField(value: self.groupEmail, fieldNumber: 2)
    }
    if !self.userEmail.isEmpty {
      try visitor.visitSingularStringField(value: self.userEmail, fieldNumber: 3)
    }
    if !self.domain.isEmpty {
      try visitor.visitSingularStringField(value: self.domain, fieldNumber: 4)
    }
    if !self.specialGroup.isEmpty {
      try visitor.visitSingularStringField(value: self.specialGroup, fieldNumber: 5)
    }
    if let v = self._viewName {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_BigQueryAcl.Entry, rhs: Google_Cloud_Bigquery_Logging_V1_BigQueryAcl.Entry) -> Bool {
    if lhs.role != rhs.role {return false}
    if lhs.groupEmail != rhs.groupEmail {return false}
    if lhs.userEmail != rhs.userEmail {return false}
    if lhs.domain != rhs.domain {return false}
    if lhs.specialGroup != rhs.specialGroup {return false}
    if lhs._viewName != rhs._viewName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_Job: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Job"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "job_name"),
    2: .standard(proto: "job_configuration"),
    3: .standard(proto: "job_status"),
    4: .standard(proto: "job_statistics"),
  ]

  fileprivate class _StorageClass {
    var _jobName: Google_Cloud_Bigquery_Logging_V1_JobName? = nil
    var _jobConfiguration: Google_Cloud_Bigquery_Logging_V1_JobConfiguration? = nil
    var _jobStatus: Google_Cloud_Bigquery_Logging_V1_JobStatus? = nil
    var _jobStatistics: Google_Cloud_Bigquery_Logging_V1_JobStatistics? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _jobName = source._jobName
      _jobConfiguration = source._jobConfiguration
      _jobStatus = source._jobStatus
      _jobStatistics = source._jobStatistics
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._jobName) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._jobConfiguration) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._jobStatus) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._jobStatistics) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if let v = _storage._jobName {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }
      if let v = _storage._jobConfiguration {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if let v = _storage._jobStatus {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }
      if let v = _storage._jobStatistics {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_Job, rhs: Google_Cloud_Bigquery_Logging_V1_Job) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._jobName != rhs_storage._jobName {return false}
        if _storage._jobConfiguration != rhs_storage._jobConfiguration {return false}
        if _storage._jobStatus != rhs_storage._jobStatus {return false}
        if _storage._jobStatistics != rhs_storage._jobStatistics {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobConfiguration: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobConfiguration"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    5: .same(proto: "query"),
    6: .same(proto: "load"),
    7: .same(proto: "extract"),
    8: .standard(proto: "table_copy"),
    9: .standard(proto: "dry_run"),
    3: .same(proto: "labels"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 3: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.labels) }()
      case 5: try {
        var v: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Query?
        if let current = self.configuration {
          try decoder.handleConflictingOneOf()
          if case .query(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.configuration = .query(v)}
      }()
      case 6: try {
        var v: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Load?
        if let current = self.configuration {
          try decoder.handleConflictingOneOf()
          if case .load(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.configuration = .load(v)}
      }()
      case 7: try {
        var v: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Extract?
        if let current = self.configuration {
          try decoder.handleConflictingOneOf()
          if case .extract(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.configuration = .extract(v)}
      }()
      case 8: try {
        var v: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.TableCopy?
        if let current = self.configuration {
          try decoder.handleConflictingOneOf()
          if case .tableCopy(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.configuration = .tableCopy(v)}
      }()
      case 9: try { try decoder.decodeSingularBoolField(value: &self.dryRun) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.labels.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.labels, fieldNumber: 3)
    }
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.configuration {
    case .query?: try {
      guard case .query(let v)? = self.configuration else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case .load?: try {
      guard case .load(let v)? = self.configuration else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case .extract?: try {
      guard case .extract(let v)? = self.configuration else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }()
    case .tableCopy?: try {
      guard case .tableCopy(let v)? = self.configuration else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    }()
    case nil: break
    }
    if self.dryRun != false {
      try visitor.visitSingularBoolField(value: self.dryRun, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration, rhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration) -> Bool {
    if lhs.configuration != rhs.configuration {return false}
    if lhs.dryRun != rhs.dryRun {return false}
    if lhs.labels != rhs.labels {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Query: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Bigquery_Logging_V1_JobConfiguration.protoMessageName + ".Query"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "query"),
    2: .standard(proto: "destination_table"),
    3: .standard(proto: "create_disposition"),
    4: .standard(proto: "write_disposition"),
    5: .standard(proto: "default_dataset"),
    6: .standard(proto: "table_definitions"),
    7: .standard(proto: "query_priority"),
    8: .standard(proto: "destination_table_encryption"),
    9: .standard(proto: "statement_type"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.query) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._destinationTable) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.createDisposition) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.writeDisposition) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._defaultDataset) }()
      case 6: try { try decoder.decodeRepeatedMessageField(value: &self.tableDefinitions) }()
      case 7: try { try decoder.decodeSingularStringField(value: &self.queryPriority) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._destinationTableEncryption) }()
      case 9: try { try decoder.decodeSingularStringField(value: &self.statementType) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.query.isEmpty {
      try visitor.visitSingularStringField(value: self.query, fieldNumber: 1)
    }
    if let v = self._destinationTable {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if !self.createDisposition.isEmpty {
      try visitor.visitSingularStringField(value: self.createDisposition, fieldNumber: 3)
    }
    if !self.writeDisposition.isEmpty {
      try visitor.visitSingularStringField(value: self.writeDisposition, fieldNumber: 4)
    }
    if let v = self._defaultDataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }
    if !self.tableDefinitions.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.tableDefinitions, fieldNumber: 6)
    }
    if !self.queryPriority.isEmpty {
      try visitor.visitSingularStringField(value: self.queryPriority, fieldNumber: 7)
    }
    if let v = self._destinationTableEncryption {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    }
    if !self.statementType.isEmpty {
      try visitor.visitSingularStringField(value: self.statementType, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Query, rhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Query) -> Bool {
    if lhs.query != rhs.query {return false}
    if lhs._destinationTable != rhs._destinationTable {return false}
    if lhs.createDisposition != rhs.createDisposition {return false}
    if lhs.writeDisposition != rhs.writeDisposition {return false}
    if lhs._defaultDataset != rhs._defaultDataset {return false}
    if lhs.tableDefinitions != rhs.tableDefinitions {return false}
    if lhs.queryPriority != rhs.queryPriority {return false}
    if lhs._destinationTableEncryption != rhs._destinationTableEncryption {return false}
    if lhs.statementType != rhs.statementType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Load: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Bigquery_Logging_V1_JobConfiguration.protoMessageName + ".Load"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "source_uris"),
    6: .standard(proto: "schema_json"),
    3: .standard(proto: "destination_table"),
    4: .standard(proto: "create_disposition"),
    5: .standard(proto: "write_disposition"),
    7: .standard(proto: "destination_table_encryption"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedStringField(value: &self.sourceUris) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._destinationTable) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.createDisposition) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.writeDisposition) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.schemaJson) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._destinationTableEncryption) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.sourceUris.isEmpty {
      try visitor.visitRepeatedStringField(value: self.sourceUris, fieldNumber: 1)
    }
    if let v = self._destinationTable {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }
    if !self.createDisposition.isEmpty {
      try visitor.visitSingularStringField(value: self.createDisposition, fieldNumber: 4)
    }
    if !self.writeDisposition.isEmpty {
      try visitor.visitSingularStringField(value: self.writeDisposition, fieldNumber: 5)
    }
    if !self.schemaJson.isEmpty {
      try visitor.visitSingularStringField(value: self.schemaJson, fieldNumber: 6)
    }
    if let v = self._destinationTableEncryption {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Load, rhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Load) -> Bool {
    if lhs.sourceUris != rhs.sourceUris {return false}
    if lhs.schemaJson != rhs.schemaJson {return false}
    if lhs._destinationTable != rhs._destinationTable {return false}
    if lhs.createDisposition != rhs.createDisposition {return false}
    if lhs.writeDisposition != rhs.writeDisposition {return false}
    if lhs._destinationTableEncryption != rhs._destinationTableEncryption {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Extract: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Bigquery_Logging_V1_JobConfiguration.protoMessageName + ".Extract"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "destination_uris"),
    2: .standard(proto: "source_table"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedStringField(value: &self.destinationUris) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._sourceTable) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.destinationUris.isEmpty {
      try visitor.visitRepeatedStringField(value: self.destinationUris, fieldNumber: 1)
    }
    if let v = self._sourceTable {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Extract, rhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.Extract) -> Bool {
    if lhs.destinationUris != rhs.destinationUris {return false}
    if lhs._sourceTable != rhs._sourceTable {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobConfiguration.TableCopy: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Bigquery_Logging_V1_JobConfiguration.protoMessageName + ".TableCopy"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "source_tables"),
    2: .standard(proto: "destination_table"),
    3: .standard(proto: "create_disposition"),
    4: .standard(proto: "write_disposition"),
    5: .standard(proto: "destination_table_encryption"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.sourceTables) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._destinationTable) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.createDisposition) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.writeDisposition) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._destinationTableEncryption) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.sourceTables.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.sourceTables, fieldNumber: 1)
    }
    if let v = self._destinationTable {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if !self.createDisposition.isEmpty {
      try visitor.visitSingularStringField(value: self.createDisposition, fieldNumber: 3)
    }
    if !self.writeDisposition.isEmpty {
      try visitor.visitSingularStringField(value: self.writeDisposition, fieldNumber: 4)
    }
    if let v = self._destinationTableEncryption {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.TableCopy, rhs: Google_Cloud_Bigquery_Logging_V1_JobConfiguration.TableCopy) -> Bool {
    if lhs.sourceTables != rhs.sourceTables {return false}
    if lhs._destinationTable != rhs._destinationTable {return false}
    if lhs.createDisposition != rhs.createDisposition {return false}
    if lhs.writeDisposition != rhs.writeDisposition {return false}
    if lhs._destinationTableEncryption != rhs._destinationTableEncryption {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_TableDefinition: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TableDefinition"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .standard(proto: "source_uris"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeRepeatedStringField(value: &self.sourceUris) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if !self.sourceUris.isEmpty {
      try visitor.visitRepeatedStringField(value: self.sourceUris, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_TableDefinition, rhs: Google_Cloud_Bigquery_Logging_V1_TableDefinition) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.sourceUris != rhs.sourceUris {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobStatus: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobStatus"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "state"),
    2: .same(proto: "error"),
    3: .standard(proto: "additional_errors"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.state) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._error) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.additionalErrors) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.state.isEmpty {
      try visitor.visitSingularStringField(value: self.state, fieldNumber: 1)
    }
    if let v = self._error {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if !self.additionalErrors.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.additionalErrors, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobStatus, rhs: Google_Cloud_Bigquery_Logging_V1_JobStatus) -> Bool {
    if lhs.state != rhs.state {return false}
    if lhs._error != rhs._error {return false}
    if lhs.additionalErrors != rhs.additionalErrors {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobStatistics: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobStatistics"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "create_time"),
    2: .standard(proto: "start_time"),
    3: .standard(proto: "end_time"),
    4: .standard(proto: "total_processed_bytes"),
    5: .standard(proto: "total_billed_bytes"),
    7: .standard(proto: "billing_tier"),
    8: .standard(proto: "total_slot_ms"),
    14: .standard(proto: "reservation_usage"),
    9: .standard(proto: "referenced_tables"),
    10: .standard(proto: "total_tables_processed"),
    11: .standard(proto: "referenced_views"),
    12: .standard(proto: "total_views_processed"),
    15: .standard(proto: "query_output_row_count"),
    13: .standard(proto: "total_load_output_bytes"),
  ]

  fileprivate class _StorageClass {
    var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _startTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _endTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _totalProcessedBytes: Int64 = 0
    var _totalBilledBytes: Int64 = 0
    var _billingTier: Int32 = 0
    var _totalSlotMs: Int64 = 0
    var _reservationUsage: [Google_Cloud_Bigquery_Logging_V1_JobStatistics.ReservationResourceUsage] = []
    var _referencedTables: [Google_Cloud_Bigquery_Logging_V1_TableName] = []
    var _totalTablesProcessed: Int32 = 0
    var _referencedViews: [Google_Cloud_Bigquery_Logging_V1_TableName] = []
    var _totalViewsProcessed: Int32 = 0
    var _queryOutputRowCount: Int64 = 0
    var _totalLoadOutputBytes: Int64 = 0

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _createTime = source._createTime
      _startTime = source._startTime
      _endTime = source._endTime
      _totalProcessedBytes = source._totalProcessedBytes
      _totalBilledBytes = source._totalBilledBytes
      _billingTier = source._billingTier
      _totalSlotMs = source._totalSlotMs
      _reservationUsage = source._reservationUsage
      _referencedTables = source._referencedTables
      _totalTablesProcessed = source._totalTablesProcessed
      _referencedViews = source._referencedViews
      _totalViewsProcessed = source._totalViewsProcessed
      _queryOutputRowCount = source._queryOutputRowCount
      _totalLoadOutputBytes = source._totalLoadOutputBytes
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._createTime) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._startTime) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._endTime) }()
        case 4: try { try decoder.decodeSingularInt64Field(value: &_storage._totalProcessedBytes) }()
        case 5: try { try decoder.decodeSingularInt64Field(value: &_storage._totalBilledBytes) }()
        case 7: try { try decoder.decodeSingularInt32Field(value: &_storage._billingTier) }()
        case 8: try { try decoder.decodeSingularInt64Field(value: &_storage._totalSlotMs) }()
        case 9: try { try decoder.decodeRepeatedMessageField(value: &_storage._referencedTables) }()
        case 10: try { try decoder.decodeSingularInt32Field(value: &_storage._totalTablesProcessed) }()
        case 11: try { try decoder.decodeRepeatedMessageField(value: &_storage._referencedViews) }()
        case 12: try { try decoder.decodeSingularInt32Field(value: &_storage._totalViewsProcessed) }()
        case 13: try { try decoder.decodeSingularInt64Field(value: &_storage._totalLoadOutputBytes) }()
        case 14: try { try decoder.decodeRepeatedMessageField(value: &_storage._reservationUsage) }()
        case 15: try { try decoder.decodeSingularInt64Field(value: &_storage._queryOutputRowCount) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if let v = _storage._createTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }
      if let v = _storage._startTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if let v = _storage._endTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }
      if _storage._totalProcessedBytes != 0 {
        try visitor.visitSingularInt64Field(value: _storage._totalProcessedBytes, fieldNumber: 4)
      }
      if _storage._totalBilledBytes != 0 {
        try visitor.visitSingularInt64Field(value: _storage._totalBilledBytes, fieldNumber: 5)
      }
      if _storage._billingTier != 0 {
        try visitor.visitSingularInt32Field(value: _storage._billingTier, fieldNumber: 7)
      }
      if _storage._totalSlotMs != 0 {
        try visitor.visitSingularInt64Field(value: _storage._totalSlotMs, fieldNumber: 8)
      }
      if !_storage._referencedTables.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._referencedTables, fieldNumber: 9)
      }
      if _storage._totalTablesProcessed != 0 {
        try visitor.visitSingularInt32Field(value: _storage._totalTablesProcessed, fieldNumber: 10)
      }
      if !_storage._referencedViews.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._referencedViews, fieldNumber: 11)
      }
      if _storage._totalViewsProcessed != 0 {
        try visitor.visitSingularInt32Field(value: _storage._totalViewsProcessed, fieldNumber: 12)
      }
      if _storage._totalLoadOutputBytes != 0 {
        try visitor.visitSingularInt64Field(value: _storage._totalLoadOutputBytes, fieldNumber: 13)
      }
      if !_storage._reservationUsage.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._reservationUsage, fieldNumber: 14)
      }
      if _storage._queryOutputRowCount != 0 {
        try visitor.visitSingularInt64Field(value: _storage._queryOutputRowCount, fieldNumber: 15)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobStatistics, rhs: Google_Cloud_Bigquery_Logging_V1_JobStatistics) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._createTime != rhs_storage._createTime {return false}
        if _storage._startTime != rhs_storage._startTime {return false}
        if _storage._endTime != rhs_storage._endTime {return false}
        if _storage._totalProcessedBytes != rhs_storage._totalProcessedBytes {return false}
        if _storage._totalBilledBytes != rhs_storage._totalBilledBytes {return false}
        if _storage._billingTier != rhs_storage._billingTier {return false}
        if _storage._totalSlotMs != rhs_storage._totalSlotMs {return false}
        if _storage._reservationUsage != rhs_storage._reservationUsage {return false}
        if _storage._referencedTables != rhs_storage._referencedTables {return false}
        if _storage._totalTablesProcessed != rhs_storage._totalTablesProcessed {return false}
        if _storage._referencedViews != rhs_storage._referencedViews {return false}
        if _storage._totalViewsProcessed != rhs_storage._totalViewsProcessed {return false}
        if _storage._queryOutputRowCount != rhs_storage._queryOutputRowCount {return false}
        if _storage._totalLoadOutputBytes != rhs_storage._totalLoadOutputBytes {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobStatistics.ReservationResourceUsage: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Bigquery_Logging_V1_JobStatistics.protoMessageName + ".ReservationResourceUsage"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .standard(proto: "slot_ms"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.slotMs) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.slotMs != 0 {
      try visitor.visitSingularInt64Field(value: self.slotMs, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobStatistics.ReservationResourceUsage, rhs: Google_Cloud_Bigquery_Logging_V1_JobStatistics.ReservationResourceUsage) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.slotMs != rhs.slotMs {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_DatasetName: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DatasetName"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_DatasetName, rhs: Google_Cloud_Bigquery_Logging_V1_DatasetName) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_TableName: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TableName"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "dataset_id"),
    3: .standard(proto: "table_id"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.datasetID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.tableID) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.datasetID.isEmpty {
      try visitor.visitSingularStringField(value: self.datasetID, fieldNumber: 2)
    }
    if !self.tableID.isEmpty {
      try visitor.visitSingularStringField(value: self.tableID, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_TableName, rhs: Google_Cloud_Bigquery_Logging_V1_TableName) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.datasetID != rhs.datasetID {return false}
    if lhs.tableID != rhs.tableID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_JobName: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".JobName"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "project_id"),
    2: .standard(proto: "job_id"),
    3: .same(proto: "location"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.projectID) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.jobID) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.location) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.projectID.isEmpty {
      try visitor.visitSingularStringField(value: self.projectID, fieldNumber: 1)
    }
    if !self.jobID.isEmpty {
      try visitor.visitSingularStringField(value: self.jobID, fieldNumber: 2)
    }
    if !self.location.isEmpty {
      try visitor.visitSingularStringField(value: self.location, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_JobName, rhs: Google_Cloud_Bigquery_Logging_V1_JobName) -> Bool {
    if lhs.projectID != rhs.projectID {return false}
    if lhs.jobID != rhs.jobID {return false}
    if lhs.location != rhs.location {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Logging_V1_EncryptionInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".EncryptionInfo"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "kms_key_name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.kmsKeyName) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.kmsKeyName.isEmpty {
      try visitor.visitSingularStringField(value: self.kmsKeyName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Logging_V1_EncryptionInfo, rhs: Google_Cloud_Bigquery_Logging_V1_EncryptionInfo) -> Bool {
    if lhs.kmsKeyName != rhs.kmsKeyName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
