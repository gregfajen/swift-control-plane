// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/datatransfer/v1/transfer.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// DEPRECATED. Represents data transfer type.
public enum Google_Cloud_Bigquery_Datatransfer_V1_TransferType: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// Invalid or Unknown transfer type placeholder.
  case unspecified // = 0

  /// Batch data transfer.
  case batch // = 1

  /// Streaming data transfer. Streaming data source currently doesn't
  /// support multiple transfer configs per project.
  case streaming // = 2
  case UNRECOGNIZED(Int)

  public init() {
    self = .unspecified
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unspecified
    case 1: self = .batch
    case 2: self = .streaming
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .unspecified: return 0
    case .batch: return 1
    case .streaming: return 2
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Google_Cloud_Bigquery_Datatransfer_V1_TransferType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Bigquery_Datatransfer_V1_TransferType] = [
    .unspecified,
    .batch,
    .streaming,
  ]
}

#endif  // swift(>=4.2)

/// Represents data transfer run state.
public enum Google_Cloud_Bigquery_Datatransfer_V1_TransferState: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// State placeholder.
  case unspecified // = 0

  /// Data transfer is scheduled and is waiting to be picked up by
  /// data transfer backend.
  case pending // = 2

  /// Data transfer is in progress.
  case running // = 3

  /// Data transfer completed successfully.
  case succeeded // = 4

  /// Data transfer failed.
  case failed // = 5

  /// Data transfer is cancelled.
  case cancelled // = 6
  case UNRECOGNIZED(Int)

  public init() {
    self = .unspecified
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unspecified
    case 2: self = .pending
    case 3: self = .running
    case 4: self = .succeeded
    case 5: self = .failed
    case 6: self = .cancelled
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .unspecified: return 0
    case .pending: return 2
    case .running: return 3
    case .succeeded: return 4
    case .failed: return 5
    case .cancelled: return 6
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Google_Cloud_Bigquery_Datatransfer_V1_TransferState: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Bigquery_Datatransfer_V1_TransferState] = [
    .unspecified,
    .pending,
    .running,
    .succeeded,
    .failed,
    .cancelled,
  ]
}

#endif  // swift(>=4.2)

/// Represents preferences for sending email notifications for transfer run
/// events.
public struct Google_Cloud_Bigquery_Datatransfer_V1_EmailPreferences {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// If true, email notifications will be sent on transfer run failures.
  public var enableFailureEmail: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Options customizing the data transfer schedule.
public struct Google_Cloud_Bigquery_Datatransfer_V1_ScheduleOptions {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// If true, automatic scheduling of data transfer runs for this configuration
  /// will be disabled. The runs can be started on ad-hoc basis using
  /// StartManualTransferRuns API. When automatic scheduling is disabled, the
  /// TransferConfig.schedule field will be ignored.
  public var disableAutoScheduling: Bool = false

  /// Specifies time to start scheduling transfer runs. The first run will be
  /// scheduled at or after the start time according to a recurrence pattern
  /// defined in the schedule string. The start time can be changed at any
  /// moment. The time when a data transfer can be trigerred manually is not
  /// limited by this option.
  public var startTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _startTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_startTime = newValue}
  }
  /// Returns true if `startTime` has been explicitly set.
  public var hasStartTime: Bool {return self._startTime != nil}
  /// Clears the value of `startTime`. Subsequent reads from it will return its default value.
  public mutating func clearStartTime() {self._startTime = nil}

  /// Defines time to stop scheduling transfer runs. A transfer run cannot be
  /// scheduled at or after the end time. The end time can be changed at any
  /// moment. The time when a data transfer can be trigerred manually is not
  /// limited by this option.
  public var endTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _endTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_endTime = newValue}
  }
  /// Returns true if `endTime` has been explicitly set.
  public var hasEndTime: Bool {return self._endTime != nil}
  /// Clears the value of `endTime`. Subsequent reads from it will return its default value.
  public mutating func clearEndTime() {self._endTime = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _startTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
  fileprivate var _endTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

/// Represents a data transfer configuration. A transfer configuration
/// contains all metadata needed to perform a data transfer. For example,
/// `destination_dataset_id` specifies where data should be stored.
/// When a new transfer configuration is created, the specified
/// `destination_dataset_id` is created when needed and shared with the
/// appropriate data source service account.
public struct Google_Cloud_Bigquery_Datatransfer_V1_TransferConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The resource name of the transfer config.
  /// Transfer config names have the form of
  /// `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`.
  /// The name is automatically generated based on the config_id specified in
  /// CreateTransferConfigRequest along with project_id and region. If config_id
  /// is not provided, usually a uuid, even though it is not guaranteed or
  /// required, will be generated for config_id.
  public var name: String {
    get {return _storage._name}
    set {_uniqueStorage()._name = newValue}
  }

  /// The desination of the transfer config.
  public var destination: OneOf_Destination? {
    get {return _storage._destination}
    set {_uniqueStorage()._destination = newValue}
  }

  /// The BigQuery target dataset id.
  public var destinationDatasetID: String {
    get {
      if case .destinationDatasetID(let v)? = _storage._destination {return v}
      return String()
    }
    set {_uniqueStorage()._destination = .destinationDatasetID(newValue)}
  }

  /// User specified display name for the data transfer.
  public var displayName: String {
    get {return _storage._displayName}
    set {_uniqueStorage()._displayName = newValue}
  }

  /// Data source id. Cannot be changed once data transfer is created.
  public var dataSourceID: String {
    get {return _storage._dataSourceID}
    set {_uniqueStorage()._dataSourceID = newValue}
  }

  /// Data transfer specific parameters.
  public var params: SwiftProtobuf.Google_Protobuf_Struct {
    get {return _storage._params ?? SwiftProtobuf.Google_Protobuf_Struct()}
    set {_uniqueStorage()._params = newValue}
  }
  /// Returns true if `params` has been explicitly set.
  public var hasParams: Bool {return _storage._params != nil}
  /// Clears the value of `params`. Subsequent reads from it will return its default value.
  public mutating func clearParams() {_uniqueStorage()._params = nil}

  /// Data transfer schedule.
  /// If the data source does not support a custom schedule, this should be
  /// empty. If it is empty, the default value for the data source will be
  /// used.
  /// The specified times are in UTC.
  /// Examples of valid format:
  /// `1st,3rd monday of month 15:30`,
  /// `every wed,fri of jan,jun 13:15`, and
  /// `first sunday of quarter 00:00`.
  /// See more explanation about the format here:
  /// https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
  /// NOTE: the granularity should be at least 8 hours, or less frequent.
  public var schedule: String {
    get {return _storage._schedule}
    set {_uniqueStorage()._schedule = newValue}
  }

  /// Options customizing the data transfer schedule.
  public var scheduleOptions: Google_Cloud_Bigquery_Datatransfer_V1_ScheduleOptions {
    get {return _storage._scheduleOptions ?? Google_Cloud_Bigquery_Datatransfer_V1_ScheduleOptions()}
    set {_uniqueStorage()._scheduleOptions = newValue}
  }
  /// Returns true if `scheduleOptions` has been explicitly set.
  public var hasScheduleOptions: Bool {return _storage._scheduleOptions != nil}
  /// Clears the value of `scheduleOptions`. Subsequent reads from it will return its default value.
  public mutating func clearScheduleOptions() {_uniqueStorage()._scheduleOptions = nil}

  /// The number of days to look back to automatically refresh the data.
  /// For example, if `data_refresh_window_days = 10`, then every day
  /// BigQuery reingests data for [today-10, today-1], rather than ingesting data
  /// for just [today-1].
  /// Only valid if the data source supports the feature. Set the value to  0
  /// to use the default value.
  public var dataRefreshWindowDays: Int32 {
    get {return _storage._dataRefreshWindowDays}
    set {_uniqueStorage()._dataRefreshWindowDays = newValue}
  }

  /// Is this config disabled. When set to true, no runs are scheduled
  /// for a given transfer.
  public var disabled: Bool {
    get {return _storage._disabled}
    set {_uniqueStorage()._disabled = newValue}
  }

  /// Output only. Data transfer modification time. Ignored by server on input.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return _storage._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {_uniqueStorage()._updateTime = nil}

  /// Output only. Next time when data transfer will run.
  public var nextRunTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._nextRunTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._nextRunTime = newValue}
  }
  /// Returns true if `nextRunTime` has been explicitly set.
  public var hasNextRunTime: Bool {return _storage._nextRunTime != nil}
  /// Clears the value of `nextRunTime`. Subsequent reads from it will return its default value.
  public mutating func clearNextRunTime() {_uniqueStorage()._nextRunTime = nil}

  /// Output only. State of the most recently updated transfer run.
  public var state: Google_Cloud_Bigquery_Datatransfer_V1_TransferState {
    get {return _storage._state}
    set {_uniqueStorage()._state = newValue}
  }

  /// Deprecated. Unique ID of the user on whose behalf transfer is done.
  public var userID: Int64 {
    get {return _storage._userID}
    set {_uniqueStorage()._userID = newValue}
  }

  /// Output only. Region in which BigQuery dataset is located.
  public var datasetRegion: String {
    get {return _storage._datasetRegion}
    set {_uniqueStorage()._datasetRegion = newValue}
  }

  /// Pub/Sub topic where notifications will be sent after transfer runs
  /// associated with this transfer config finish.
  public var notificationPubsubTopic: String {
    get {return _storage._notificationPubsubTopic}
    set {_uniqueStorage()._notificationPubsubTopic = newValue}
  }

  /// Email notifications will be sent according to these preferences
  /// to the email address of the user who owns this transfer config.
  public var emailPreferences: Google_Cloud_Bigquery_Datatransfer_V1_EmailPreferences {
    get {return _storage._emailPreferences ?? Google_Cloud_Bigquery_Datatransfer_V1_EmailPreferences()}
    set {_uniqueStorage()._emailPreferences = newValue}
  }
  /// Returns true if `emailPreferences` has been explicitly set.
  public var hasEmailPreferences: Bool {return _storage._emailPreferences != nil}
  /// Clears the value of `emailPreferences`. Subsequent reads from it will return its default value.
  public mutating func clearEmailPreferences() {_uniqueStorage()._emailPreferences = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The desination of the transfer config.
  public enum OneOf_Destination: Equatable {
    /// The BigQuery target dataset id.
    case destinationDatasetID(String)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Datatransfer_V1_TransferConfig.OneOf_Destination, rhs: Google_Cloud_Bigquery_Datatransfer_V1_TransferConfig.OneOf_Destination) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.destinationDatasetID, .destinationDatasetID): return {
        guard case .destinationDatasetID(let l) = lhs, case .destinationDatasetID(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Represents a data transfer run.
public struct Google_Cloud_Bigquery_Datatransfer_V1_TransferRun {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The resource name of the transfer run.
  /// Transfer run names have the form
  /// `projects/{project_id}/locations/{location}/transferConfigs/{config_id}/runs/{run_id}`.
  /// The name is ignored when creating a transfer run.
  public var name: String {
    get {return _storage._name}
    set {_uniqueStorage()._name = newValue}
  }

  /// Minimum time after which a transfer run can be started.
  public var scheduleTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._scheduleTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._scheduleTime = newValue}
  }
  /// Returns true if `scheduleTime` has been explicitly set.
  public var hasScheduleTime: Bool {return _storage._scheduleTime != nil}
  /// Clears the value of `scheduleTime`. Subsequent reads from it will return its default value.
  public mutating func clearScheduleTime() {_uniqueStorage()._scheduleTime = nil}

  /// For batch transfer runs, specifies the date and time of the data should be
  /// ingested.
  public var runTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._runTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._runTime = newValue}
  }
  /// Returns true if `runTime` has been explicitly set.
  public var hasRunTime: Bool {return _storage._runTime != nil}
  /// Clears the value of `runTime`. Subsequent reads from it will return its default value.
  public mutating func clearRunTime() {_uniqueStorage()._runTime = nil}

  /// Status of the transfer run.
  public var errorStatus: Google_Rpc_Status {
    get {return _storage._errorStatus ?? Google_Rpc_Status()}
    set {_uniqueStorage()._errorStatus = newValue}
  }
  /// Returns true if `errorStatus` has been explicitly set.
  public var hasErrorStatus: Bool {return _storage._errorStatus != nil}
  /// Clears the value of `errorStatus`. Subsequent reads from it will return its default value.
  public mutating func clearErrorStatus() {_uniqueStorage()._errorStatus = nil}

  /// Output only. Time when transfer run was started.
  /// Parameter ignored by server for input requests.
  public var startTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._startTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._startTime = newValue}
  }
  /// Returns true if `startTime` has been explicitly set.
  public var hasStartTime: Bool {return _storage._startTime != nil}
  /// Clears the value of `startTime`. Subsequent reads from it will return its default value.
  public mutating func clearStartTime() {_uniqueStorage()._startTime = nil}

  /// Output only. Time when transfer run ended.
  /// Parameter ignored by server for input requests.
  public var endTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._endTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._endTime = newValue}
  }
  /// Returns true if `endTime` has been explicitly set.
  public var hasEndTime: Bool {return _storage._endTime != nil}
  /// Clears the value of `endTime`. Subsequent reads from it will return its default value.
  public mutating func clearEndTime() {_uniqueStorage()._endTime = nil}

  /// Output only. Last time the data transfer run state was updated.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return _storage._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {_uniqueStorage()._updateTime = nil}

  /// Output only. Data transfer specific parameters.
  public var params: SwiftProtobuf.Google_Protobuf_Struct {
    get {return _storage._params ?? SwiftProtobuf.Google_Protobuf_Struct()}
    set {_uniqueStorage()._params = newValue}
  }
  /// Returns true if `params` has been explicitly set.
  public var hasParams: Bool {return _storage._params != nil}
  /// Clears the value of `params`. Subsequent reads from it will return its default value.
  public mutating func clearParams() {_uniqueStorage()._params = nil}

  /// Data transfer destination.
  public var destination: OneOf_Destination? {
    get {return _storage._destination}
    set {_uniqueStorage()._destination = newValue}
  }

  /// Output only. The BigQuery target dataset id.
  public var destinationDatasetID: String {
    get {
      if case .destinationDatasetID(let v)? = _storage._destination {return v}
      return String()
    }
    set {_uniqueStorage()._destination = .destinationDatasetID(newValue)}
  }

  /// Output only. Data source id.
  public var dataSourceID: String {
    get {return _storage._dataSourceID}
    set {_uniqueStorage()._dataSourceID = newValue}
  }

  /// Data transfer run state. Ignored for input requests.
  public var state: Google_Cloud_Bigquery_Datatransfer_V1_TransferState {
    get {return _storage._state}
    set {_uniqueStorage()._state = newValue}
  }

  /// Deprecated. Unique ID of the user on whose behalf transfer is done.
  public var userID: Int64 {
    get {return _storage._userID}
    set {_uniqueStorage()._userID = newValue}
  }

  /// Output only. Describes the schedule of this transfer run if it was
  /// created as part of a regular schedule. For batch transfer runs that are
  /// scheduled manually, this is empty.
  /// NOTE: the system might choose to delay the schedule depending on the
  /// current load, so `schedule_time` doesn't always match this.
  public var schedule: String {
    get {return _storage._schedule}
    set {_uniqueStorage()._schedule = newValue}
  }

  /// Output only. Pub/Sub topic where a notification will be sent after this
  /// transfer run finishes
  public var notificationPubsubTopic: String {
    get {return _storage._notificationPubsubTopic}
    set {_uniqueStorage()._notificationPubsubTopic = newValue}
  }

  /// Output only. Email notifications will be sent according to these
  /// preferences to the email address of the user who owns the transfer config
  /// this run was derived from.
  public var emailPreferences: Google_Cloud_Bigquery_Datatransfer_V1_EmailPreferences {
    get {return _storage._emailPreferences ?? Google_Cloud_Bigquery_Datatransfer_V1_EmailPreferences()}
    set {_uniqueStorage()._emailPreferences = newValue}
  }
  /// Returns true if `emailPreferences` has been explicitly set.
  public var hasEmailPreferences: Bool {return _storage._emailPreferences != nil}
  /// Clears the value of `emailPreferences`. Subsequent reads from it will return its default value.
  public mutating func clearEmailPreferences() {_uniqueStorage()._emailPreferences = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Data transfer destination.
  public enum OneOf_Destination: Equatable {
    /// Output only. The BigQuery target dataset id.
    case destinationDatasetID(String)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Datatransfer_V1_TransferRun.OneOf_Destination, rhs: Google_Cloud_Bigquery_Datatransfer_V1_TransferRun.OneOf_Destination) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.destinationDatasetID, .destinationDatasetID): return {
        guard case .destinationDatasetID(let l) = lhs, case .destinationDatasetID(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Represents a user facing message for a particular data transfer run.
public struct Google_Cloud_Bigquery_Datatransfer_V1_TransferMessage {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Time when message was logged.
  public var messageTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _messageTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_messageTime = newValue}
  }
  /// Returns true if `messageTime` has been explicitly set.
  public var hasMessageTime: Bool {return self._messageTime != nil}
  /// Clears the value of `messageTime`. Subsequent reads from it will return its default value.
  public mutating func clearMessageTime() {self._messageTime = nil}

  /// Message severity.
  public var severity: Google_Cloud_Bigquery_Datatransfer_V1_TransferMessage.MessageSeverity = .unspecified

  /// Message text.
  public var messageText: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Represents data transfer user facing message severity.
  public enum MessageSeverity: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// No severity specified.
    case unspecified // = 0

    /// Informational message.
    case info // = 1

    /// Warning message.
    case warning // = 2

    /// Error message.
    case error // = 3
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .info
      case 2: self = .warning
      case 3: self = .error
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .info: return 1
      case .warning: return 2
      case .error: return 3
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _messageTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

#if swift(>=4.2)

extension Google_Cloud_Bigquery_Datatransfer_V1_TransferMessage.MessageSeverity: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Bigquery_Datatransfer_V1_TransferMessage.MessageSeverity] = [
    .unspecified,
    .info,
    .warning,
    .error,
  ]
}

#endif  // swift(>=4.2)

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.datatransfer.v1"

extension Google_Cloud_Bigquery_Datatransfer_V1_TransferType: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TRANSFER_TYPE_UNSPECIFIED"),
    1: .same(proto: "BATCH"),
    2: .same(proto: "STREAMING"),
  ]
}

extension Google_Cloud_Bigquery_Datatransfer_V1_TransferState: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TRANSFER_STATE_UNSPECIFIED"),
    2: .same(proto: "PENDING"),
    3: .same(proto: "RUNNING"),
    4: .same(proto: "SUCCEEDED"),
    5: .same(proto: "FAILED"),
    6: .same(proto: "CANCELLED"),
  ]
}

extension Google_Cloud_Bigquery_Datatransfer_V1_EmailPreferences: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".EmailPreferences"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "enable_failure_email"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.enableFailureEmail) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.enableFailureEmail != false {
      try visitor.visitSingularBoolField(value: self.enableFailureEmail, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Datatransfer_V1_EmailPreferences, rhs: Google_Cloud_Bigquery_Datatransfer_V1_EmailPreferences) -> Bool {
    if lhs.enableFailureEmail != rhs.enableFailureEmail {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Datatransfer_V1_ScheduleOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ScheduleOptions"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    3: .standard(proto: "disable_auto_scheduling"),
    1: .standard(proto: "start_time"),
    2: .standard(proto: "end_time"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._startTime) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._endTime) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.disableAutoScheduling) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._startTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._endTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if self.disableAutoScheduling != false {
      try visitor.visitSingularBoolField(value: self.disableAutoScheduling, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Datatransfer_V1_ScheduleOptions, rhs: Google_Cloud_Bigquery_Datatransfer_V1_ScheduleOptions) -> Bool {
    if lhs.disableAutoScheduling != rhs.disableAutoScheduling {return false}
    if lhs._startTime != rhs._startTime {return false}
    if lhs._endTime != rhs._endTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Datatransfer_V1_TransferConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TransferConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .standard(proto: "destination_dataset_id"),
    3: .standard(proto: "display_name"),
    5: .standard(proto: "data_source_id"),
    9: .same(proto: "params"),
    7: .same(proto: "schedule"),
    24: .standard(proto: "schedule_options"),
    12: .standard(proto: "data_refresh_window_days"),
    13: .same(proto: "disabled"),
    4: .standard(proto: "update_time"),
    8: .standard(proto: "next_run_time"),
    10: .same(proto: "state"),
    11: .standard(proto: "user_id"),
    14: .standard(proto: "dataset_region"),
    15: .standard(proto: "notification_pubsub_topic"),
    18: .standard(proto: "email_preferences"),
  ]

  fileprivate class _StorageClass {
    var _name: String = String()
    var _destination: Google_Cloud_Bigquery_Datatransfer_V1_TransferConfig.OneOf_Destination?
    var _displayName: String = String()
    var _dataSourceID: String = String()
    var _params: SwiftProtobuf.Google_Protobuf_Struct? = nil
    var _schedule: String = String()
    var _scheduleOptions: Google_Cloud_Bigquery_Datatransfer_V1_ScheduleOptions? = nil
    var _dataRefreshWindowDays: Int32 = 0
    var _disabled: Bool = false
    var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _nextRunTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _state: Google_Cloud_Bigquery_Datatransfer_V1_TransferState = .unspecified
    var _userID: Int64 = 0
    var _datasetRegion: String = String()
    var _notificationPubsubTopic: String = String()
    var _emailPreferences: Google_Cloud_Bigquery_Datatransfer_V1_EmailPreferences? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _name = source._name
      _destination = source._destination
      _displayName = source._displayName
      _dataSourceID = source._dataSourceID
      _params = source._params
      _schedule = source._schedule
      _scheduleOptions = source._scheduleOptions
      _dataRefreshWindowDays = source._dataRefreshWindowDays
      _disabled = source._disabled
      _updateTime = source._updateTime
      _nextRunTime = source._nextRunTime
      _state = source._state
      _userID = source._userID
      _datasetRegion = source._datasetRegion
      _notificationPubsubTopic = source._notificationPubsubTopic
      _emailPreferences = source._emailPreferences
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._name) }()
        case 2: try {
          if _storage._destination != nil {try decoder.handleConflictingOneOf()}
          var v: String?
          try decoder.decodeSingularStringField(value: &v)
          if let v = v {_storage._destination = .destinationDatasetID(v)}
        }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._displayName) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._updateTime) }()
        case 5: try { try decoder.decodeSingularStringField(value: &_storage._dataSourceID) }()
        case 7: try { try decoder.decodeSingularStringField(value: &_storage._schedule) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._nextRunTime) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._params) }()
        case 10: try { try decoder.decodeSingularEnumField(value: &_storage._state) }()
        case 11: try { try decoder.decodeSingularInt64Field(value: &_storage._userID) }()
        case 12: try { try decoder.decodeSingularInt32Field(value: &_storage._dataRefreshWindowDays) }()
        case 13: try { try decoder.decodeSingularBoolField(value: &_storage._disabled) }()
        case 14: try { try decoder.decodeSingularStringField(value: &_storage._datasetRegion) }()
        case 15: try { try decoder.decodeSingularStringField(value: &_storage._notificationPubsubTopic) }()
        case 18: try { try decoder.decodeSingularMessageField(value: &_storage._emailPreferences) }()
        case 24: try { try decoder.decodeSingularMessageField(value: &_storage._scheduleOptions) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._name.isEmpty {
        try visitor.visitSingularStringField(value: _storage._name, fieldNumber: 1)
      }
      if case .destinationDatasetID(let v)? = _storage._destination {
        try visitor.visitSingularStringField(value: v, fieldNumber: 2)
      }
      if !_storage._displayName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._displayName, fieldNumber: 3)
      }
      if let v = _storage._updateTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }
      if !_storage._dataSourceID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._dataSourceID, fieldNumber: 5)
      }
      if !_storage._schedule.isEmpty {
        try visitor.visitSingularStringField(value: _storage._schedule, fieldNumber: 7)
      }
      if let v = _storage._nextRunTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      }
      if let v = _storage._params {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      }
      if _storage._state != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._state, fieldNumber: 10)
      }
      if _storage._userID != 0 {
        try visitor.visitSingularInt64Field(value: _storage._userID, fieldNumber: 11)
      }
      if _storage._dataRefreshWindowDays != 0 {
        try visitor.visitSingularInt32Field(value: _storage._dataRefreshWindowDays, fieldNumber: 12)
      }
      if _storage._disabled != false {
        try visitor.visitSingularBoolField(value: _storage._disabled, fieldNumber: 13)
      }
      if !_storage._datasetRegion.isEmpty {
        try visitor.visitSingularStringField(value: _storage._datasetRegion, fieldNumber: 14)
      }
      if !_storage._notificationPubsubTopic.isEmpty {
        try visitor.visitSingularStringField(value: _storage._notificationPubsubTopic, fieldNumber: 15)
      }
      if let v = _storage._emailPreferences {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
      }
      if let v = _storage._scheduleOptions {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 24)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Datatransfer_V1_TransferConfig, rhs: Google_Cloud_Bigquery_Datatransfer_V1_TransferConfig) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._name != rhs_storage._name {return false}
        if _storage._destination != rhs_storage._destination {return false}
        if _storage._displayName != rhs_storage._displayName {return false}
        if _storage._dataSourceID != rhs_storage._dataSourceID {return false}
        if _storage._params != rhs_storage._params {return false}
        if _storage._schedule != rhs_storage._schedule {return false}
        if _storage._scheduleOptions != rhs_storage._scheduleOptions {return false}
        if _storage._dataRefreshWindowDays != rhs_storage._dataRefreshWindowDays {return false}
        if _storage._disabled != rhs_storage._disabled {return false}
        if _storage._updateTime != rhs_storage._updateTime {return false}
        if _storage._nextRunTime != rhs_storage._nextRunTime {return false}
        if _storage._state != rhs_storage._state {return false}
        if _storage._userID != rhs_storage._userID {return false}
        if _storage._datasetRegion != rhs_storage._datasetRegion {return false}
        if _storage._notificationPubsubTopic != rhs_storage._notificationPubsubTopic {return false}
        if _storage._emailPreferences != rhs_storage._emailPreferences {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Datatransfer_V1_TransferRun: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TransferRun"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    3: .standard(proto: "schedule_time"),
    10: .standard(proto: "run_time"),
    21: .standard(proto: "error_status"),
    4: .standard(proto: "start_time"),
    5: .standard(proto: "end_time"),
    6: .standard(proto: "update_time"),
    9: .same(proto: "params"),
    2: .standard(proto: "destination_dataset_id"),
    7: .standard(proto: "data_source_id"),
    8: .same(proto: "state"),
    11: .standard(proto: "user_id"),
    12: .same(proto: "schedule"),
    23: .standard(proto: "notification_pubsub_topic"),
    25: .standard(proto: "email_preferences"),
  ]

  fileprivate class _StorageClass {
    var _name: String = String()
    var _scheduleTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _runTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _errorStatus: Google_Rpc_Status? = nil
    var _startTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _endTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _params: SwiftProtobuf.Google_Protobuf_Struct? = nil
    var _destination: Google_Cloud_Bigquery_Datatransfer_V1_TransferRun.OneOf_Destination?
    var _dataSourceID: String = String()
    var _state: Google_Cloud_Bigquery_Datatransfer_V1_TransferState = .unspecified
    var _userID: Int64 = 0
    var _schedule: String = String()
    var _notificationPubsubTopic: String = String()
    var _emailPreferences: Google_Cloud_Bigquery_Datatransfer_V1_EmailPreferences? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _name = source._name
      _scheduleTime = source._scheduleTime
      _runTime = source._runTime
      _errorStatus = source._errorStatus
      _startTime = source._startTime
      _endTime = source._endTime
      _updateTime = source._updateTime
      _params = source._params
      _destination = source._destination
      _dataSourceID = source._dataSourceID
      _state = source._state
      _userID = source._userID
      _schedule = source._schedule
      _notificationPubsubTopic = source._notificationPubsubTopic
      _emailPreferences = source._emailPreferences
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._name) }()
        case 2: try {
          if _storage._destination != nil {try decoder.handleConflictingOneOf()}
          var v: String?
          try decoder.decodeSingularStringField(value: &v)
          if let v = v {_storage._destination = .destinationDatasetID(v)}
        }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._scheduleTime) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._startTime) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._endTime) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._updateTime) }()
        case 7: try { try decoder.decodeSingularStringField(value: &_storage._dataSourceID) }()
        case 8: try { try decoder.decodeSingularEnumField(value: &_storage._state) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._params) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._runTime) }()
        case 11: try { try decoder.decodeSingularInt64Field(value: &_storage._userID) }()
        case 12: try { try decoder.decodeSingularStringField(value: &_storage._schedule) }()
        case 21: try { try decoder.decodeSingularMessageField(value: &_storage._errorStatus) }()
        case 23: try { try decoder.decodeSingularStringField(value: &_storage._notificationPubsubTopic) }()
        case 25: try { try decoder.decodeSingularMessageField(value: &_storage._emailPreferences) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._name.isEmpty {
        try visitor.visitSingularStringField(value: _storage._name, fieldNumber: 1)
      }
      if case .destinationDatasetID(let v)? = _storage._destination {
        try visitor.visitSingularStringField(value: v, fieldNumber: 2)
      }
      if let v = _storage._scheduleTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }
      if let v = _storage._startTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }
      if let v = _storage._endTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      }
      if let v = _storage._updateTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      }
      if !_storage._dataSourceID.isEmpty {
        try visitor.visitSingularStringField(value: _storage._dataSourceID, fieldNumber: 7)
      }
      if _storage._state != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._state, fieldNumber: 8)
      }
      if let v = _storage._params {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      }
      if let v = _storage._runTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      }
      if _storage._userID != 0 {
        try visitor.visitSingularInt64Field(value: _storage._userID, fieldNumber: 11)
      }
      if !_storage._schedule.isEmpty {
        try visitor.visitSingularStringField(value: _storage._schedule, fieldNumber: 12)
      }
      if let v = _storage._errorStatus {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
      }
      if !_storage._notificationPubsubTopic.isEmpty {
        try visitor.visitSingularStringField(value: _storage._notificationPubsubTopic, fieldNumber: 23)
      }
      if let v = _storage._emailPreferences {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 25)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Datatransfer_V1_TransferRun, rhs: Google_Cloud_Bigquery_Datatransfer_V1_TransferRun) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._name != rhs_storage._name {return false}
        if _storage._scheduleTime != rhs_storage._scheduleTime {return false}
        if _storage._runTime != rhs_storage._runTime {return false}
        if _storage._errorStatus != rhs_storage._errorStatus {return false}
        if _storage._startTime != rhs_storage._startTime {return false}
        if _storage._endTime != rhs_storage._endTime {return false}
        if _storage._updateTime != rhs_storage._updateTime {return false}
        if _storage._params != rhs_storage._params {return false}
        if _storage._destination != rhs_storage._destination {return false}
        if _storage._dataSourceID != rhs_storage._dataSourceID {return false}
        if _storage._state != rhs_storage._state {return false}
        if _storage._userID != rhs_storage._userID {return false}
        if _storage._schedule != rhs_storage._schedule {return false}
        if _storage._notificationPubsubTopic != rhs_storage._notificationPubsubTopic {return false}
        if _storage._emailPreferences != rhs_storage._emailPreferences {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Datatransfer_V1_TransferMessage: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TransferMessage"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "message_time"),
    2: .same(proto: "severity"),
    3: .standard(proto: "message_text"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._messageTime) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.severity) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.messageText) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._messageTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if self.severity != .unspecified {
      try visitor.visitSingularEnumField(value: self.severity, fieldNumber: 2)
    }
    if !self.messageText.isEmpty {
      try visitor.visitSingularStringField(value: self.messageText, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Datatransfer_V1_TransferMessage, rhs: Google_Cloud_Bigquery_Datatransfer_V1_TransferMessage) -> Bool {
    if lhs._messageTime != rhs._messageTime {return false}
    if lhs.severity != rhs.severity {return false}
    if lhs.messageText != rhs.messageText {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Datatransfer_V1_TransferMessage.MessageSeverity: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "MESSAGE_SEVERITY_UNSPECIFIED"),
    1: .same(proto: "INFO"),
    2: .same(proto: "WARNING"),
    3: .same(proto: "ERROR"),
  ]
}
