// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/storage/v1beta1/storage.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Data format for input or output data.
public enum Google_Cloud_Bigquery_Storage_V1beta1_DataFormat: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// Data format is unspecified.
  case unspecified // = 0

  /// Avro is a standard open source row based file format.
  /// See https://avro.apache.org/ for more details.
  case avro // = 1
  case arrow // = 3
  case UNRECOGNIZED(Int)

  public init() {
    self = .unspecified
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unspecified
    case 1: self = .avro
    case 3: self = .arrow
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .unspecified: return 0
    case .avro: return 1
    case .arrow: return 3
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Google_Cloud_Bigquery_Storage_V1beta1_DataFormat: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Bigquery_Storage_V1beta1_DataFormat] = [
    .unspecified,
    .avro,
    .arrow,
  ]
}

#endif  // swift(>=4.2)

/// Strategy for distributing data among multiple streams in a read session.
public enum Google_Cloud_Bigquery_Storage_V1beta1_ShardingStrategy: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// Same as LIQUID.
  case unspecified // = 0

  /// Assigns data to each stream based on the client's read rate. The faster the
  /// client reads from a stream, the more data is assigned to the stream. In
  /// this strategy, it's possible to read all data from a single stream even if
  /// there are other streams present.
  case liquid // = 1

  /// Assigns data to each stream such that roughly the same number of rows can
  /// be read from each stream. Because the server-side unit for assigning data
  /// is collections of rows, the API does not guarantee that each stream will
  /// return the same number or rows. Additionally, the limits are enforced based
  /// on the number of pre-filtering rows, so some filters can lead to lopsided
  /// assignments.
  case balanced // = 2
  case UNRECOGNIZED(Int)

  public init() {
    self = .unspecified
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .unspecified
    case 1: self = .liquid
    case 2: self = .balanced
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .unspecified: return 0
    case .liquid: return 1
    case .balanced: return 2
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension Google_Cloud_Bigquery_Storage_V1beta1_ShardingStrategy: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Bigquery_Storage_V1beta1_ShardingStrategy] = [
    .unspecified,
    .liquid,
    .balanced,
  ]
}

#endif  // swift(>=4.2)

/// Information about a single data stream within a read session.
public struct Google_Cloud_Bigquery_Storage_V1beta1_Stream {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Name of the stream, in the form
  /// `projects/{project_id}/locations/{location}/streams/{stream_id}`.
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Expresses a point within a given stream using an offset position.
public struct Google_Cloud_Bigquery_Storage_V1beta1_StreamPosition {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Identifier for a given Stream.
  public var stream: Google_Cloud_Bigquery_Storage_V1beta1_Stream {
    get {return _stream ?? Google_Cloud_Bigquery_Storage_V1beta1_Stream()}
    set {_stream = newValue}
  }
  /// Returns true if `stream` has been explicitly set.
  public var hasStream: Bool {return self._stream != nil}
  /// Clears the value of `stream`. Subsequent reads from it will return its default value.
  public mutating func clearStream() {self._stream = nil}

  /// Position in the stream.
  public var offset: Int64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _stream: Google_Cloud_Bigquery_Storage_V1beta1_Stream? = nil
}

/// Information returned from a `CreateReadSession` request.
public struct Google_Cloud_Bigquery_Storage_V1beta1_ReadSession {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Unique identifier for the session, in the form
  /// `projects/{project_id}/locations/{location}/sessions/{session_id}`.
  public var name: String = String()

  /// Time at which the session becomes invalid. After this time, subsequent
  /// requests to read this Session will return errors.
  public var expireTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _expireTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_expireTime = newValue}
  }
  /// Returns true if `expireTime` has been explicitly set.
  public var hasExpireTime: Bool {return self._expireTime != nil}
  /// Clears the value of `expireTime`. Subsequent reads from it will return its default value.
  public mutating func clearExpireTime() {self._expireTime = nil}

  /// The schema for the read. If read_options.selected_fields is set, the
  /// schema may be different from the table schema as it will only contain
  /// the selected fields.
  public var schema: Google_Cloud_Bigquery_Storage_V1beta1_ReadSession.OneOf_Schema? = nil

  /// Avro schema.
  public var avroSchema: Google_Cloud_Bigquery_Storage_V1beta1_AvroSchema {
    get {
      if case .avroSchema(let v)? = schema {return v}
      return Google_Cloud_Bigquery_Storage_V1beta1_AvroSchema()
    }
    set {schema = .avroSchema(newValue)}
  }

  /// Arrow schema.
  public var arrowSchema: Google_Cloud_Bigquery_Storage_V1beta1_ArrowSchema {
    get {
      if case .arrowSchema(let v)? = schema {return v}
      return Google_Cloud_Bigquery_Storage_V1beta1_ArrowSchema()
    }
    set {schema = .arrowSchema(newValue)}
  }

  /// Streams associated with this session.
  public var streams: [Google_Cloud_Bigquery_Storage_V1beta1_Stream] = []

  /// Table that this ReadSession is reading from.
  public var tableReference: Google_Cloud_Bigquery_Storage_V1beta1_TableReference {
    get {return _tableReference ?? Google_Cloud_Bigquery_Storage_V1beta1_TableReference()}
    set {_tableReference = newValue}
  }
  /// Returns true if `tableReference` has been explicitly set.
  public var hasTableReference: Bool {return self._tableReference != nil}
  /// Clears the value of `tableReference`. Subsequent reads from it will return its default value.
  public mutating func clearTableReference() {self._tableReference = nil}

  /// Any modifiers which are applied when reading from the specified table.
  public var tableModifiers: Google_Cloud_Bigquery_Storage_V1beta1_TableModifiers {
    get {return _tableModifiers ?? Google_Cloud_Bigquery_Storage_V1beta1_TableModifiers()}
    set {_tableModifiers = newValue}
  }
  /// Returns true if `tableModifiers` has been explicitly set.
  public var hasTableModifiers: Bool {return self._tableModifiers != nil}
  /// Clears the value of `tableModifiers`. Subsequent reads from it will return its default value.
  public mutating func clearTableModifiers() {self._tableModifiers = nil}

  /// The strategy to use for distributing data among the streams.
  public var shardingStrategy: Google_Cloud_Bigquery_Storage_V1beta1_ShardingStrategy = .unspecified

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The schema for the read. If read_options.selected_fields is set, the
  /// schema may be different from the table schema as it will only contain
  /// the selected fields.
  public enum OneOf_Schema: Equatable {
    /// Avro schema.
    case avroSchema(Google_Cloud_Bigquery_Storage_V1beta1_AvroSchema)
    /// Arrow schema.
    case arrowSchema(Google_Cloud_Bigquery_Storage_V1beta1_ArrowSchema)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_ReadSession.OneOf_Schema, rhs: Google_Cloud_Bigquery_Storage_V1beta1_ReadSession.OneOf_Schema) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.avroSchema, .avroSchema): return {
        guard case .avroSchema(let l) = lhs, case .avroSchema(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.arrowSchema, .arrowSchema): return {
        guard case .arrowSchema(let l) = lhs, case .arrowSchema(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _expireTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
  fileprivate var _tableReference: Google_Cloud_Bigquery_Storage_V1beta1_TableReference? = nil
  fileprivate var _tableModifiers: Google_Cloud_Bigquery_Storage_V1beta1_TableModifiers? = nil
}

/// Creates a new read session, which may include additional options such as
/// requested parallelism, projection filters and constraints.
public struct Google_Cloud_Bigquery_Storage_V1beta1_CreateReadSessionRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Reference to the table to read.
  public var tableReference: Google_Cloud_Bigquery_Storage_V1beta1_TableReference {
    get {return _tableReference ?? Google_Cloud_Bigquery_Storage_V1beta1_TableReference()}
    set {_tableReference = newValue}
  }
  /// Returns true if `tableReference` has been explicitly set.
  public var hasTableReference: Bool {return self._tableReference != nil}
  /// Clears the value of `tableReference`. Subsequent reads from it will return its default value.
  public mutating func clearTableReference() {self._tableReference = nil}

  /// Required. String of the form `projects/{project_id}` indicating the
  /// project this ReadSession is associated with. This is the project that will
  /// be billed for usage.
  public var parent: String = String()

  /// Any modifiers to the Table (e.g. snapshot timestamp).
  public var tableModifiers: Google_Cloud_Bigquery_Storage_V1beta1_TableModifiers {
    get {return _tableModifiers ?? Google_Cloud_Bigquery_Storage_V1beta1_TableModifiers()}
    set {_tableModifiers = newValue}
  }
  /// Returns true if `tableModifiers` has been explicitly set.
  public var hasTableModifiers: Bool {return self._tableModifiers != nil}
  /// Clears the value of `tableModifiers`. Subsequent reads from it will return its default value.
  public mutating func clearTableModifiers() {self._tableModifiers = nil}

  /// Initial number of streams. If unset or 0, we will
  /// provide a value of streams so as to produce reasonable throughput. Must be
  /// non-negative. The number of streams may be lower than the requested number,
  /// depending on the amount parallelism that is reasonable for the table and
  /// the maximum amount of parallelism allowed by the system.
  ///
  /// Streams must be read starting from offset 0.
  public var requestedStreams: Int32 = 0

  /// Read options for this session (e.g. column selection, filters).
  public var readOptions: Google_Cloud_Bigquery_Storage_V1beta1_TableReadOptions {
    get {return _readOptions ?? Google_Cloud_Bigquery_Storage_V1beta1_TableReadOptions()}
    set {_readOptions = newValue}
  }
  /// Returns true if `readOptions` has been explicitly set.
  public var hasReadOptions: Bool {return self._readOptions != nil}
  /// Clears the value of `readOptions`. Subsequent reads from it will return its default value.
  public mutating func clearReadOptions() {self._readOptions = nil}

  /// Data output format. Currently default to Avro.
  public var format: Google_Cloud_Bigquery_Storage_V1beta1_DataFormat = .unspecified

  /// The strategy to use for distributing data among multiple streams. Currently
  /// defaults to liquid sharding.
  public var shardingStrategy: Google_Cloud_Bigquery_Storage_V1beta1_ShardingStrategy = .unspecified

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _tableReference: Google_Cloud_Bigquery_Storage_V1beta1_TableReference? = nil
  fileprivate var _tableModifiers: Google_Cloud_Bigquery_Storage_V1beta1_TableModifiers? = nil
  fileprivate var _readOptions: Google_Cloud_Bigquery_Storage_V1beta1_TableReadOptions? = nil
}

/// Requesting row data via `ReadRows` must provide Stream position information.
public struct Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Identifier of the position in the stream to start reading from.
  /// The offset requested must be less than the last row read from ReadRows.
  /// Requesting a larger offset is undefined.
  public var readPosition: Google_Cloud_Bigquery_Storage_V1beta1_StreamPosition {
    get {return _readPosition ?? Google_Cloud_Bigquery_Storage_V1beta1_StreamPosition()}
    set {_readPosition = newValue}
  }
  /// Returns true if `readPosition` has been explicitly set.
  public var hasReadPosition: Bool {return self._readPosition != nil}
  /// Clears the value of `readPosition`. Subsequent reads from it will return its default value.
  public mutating func clearReadPosition() {self._readPosition = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _readPosition: Google_Cloud_Bigquery_Storage_V1beta1_StreamPosition? = nil
}

/// Progress information for a given Stream.
public struct Google_Cloud_Bigquery_Storage_V1beta1_StreamStatus {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Number of estimated rows in the current stream. May change over time as
  /// different readers in the stream progress at rates which are relatively fast
  /// or slow.
  public var estimatedRowCount: Int64 = 0

  /// A value in the range [0.0, 1.0] that represents the fraction of rows
  /// assigned to this stream that have been processed by the server. In the
  /// presence of read filters, the server may process more rows than it returns,
  /// so this value reflects progress through the pre-filtering rows.
  ///
  /// This value is only populated for sessions created through the BALANCED
  /// sharding strategy.
  public var fractionConsumed: Float = 0

  /// Represents the progress of the current stream.
  public var progress: Google_Cloud_Bigquery_Storage_V1beta1_Progress {
    get {return _progress ?? Google_Cloud_Bigquery_Storage_V1beta1_Progress()}
    set {_progress = newValue}
  }
  /// Returns true if `progress` has been explicitly set.
  public var hasProgress: Bool {return self._progress != nil}
  /// Clears the value of `progress`. Subsequent reads from it will return its default value.
  public mutating func clearProgress() {self._progress = nil}

  /// Whether this stream can be split. For sessions that use the LIQUID sharding
  /// strategy, this value is always false. For BALANCED sessions, this value is
  /// false when enough data have been read such that no more splits are possible
  /// at that point or beyond. For small tables or streams that are the result of
  /// a chain of splits, this value may never be true.
  public var isSplittable: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _progress: Google_Cloud_Bigquery_Storage_V1beta1_Progress? = nil
}

public struct Google_Cloud_Bigquery_Storage_V1beta1_Progress {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The fraction of rows assigned to the stream that have been processed by the
  /// server so far, not including the rows in the current response message.
  ///
  /// This value, along with `at_response_end`, can be used to interpolate the
  /// progress made as the rows in the message are being processed using the
  /// following formula: `at_response_start + (at_response_end -
  /// at_response_start) * rows_processed_from_response / rows_in_response`.
  ///
  /// Note that if a filter is provided, the `at_response_end` value of the
  /// previous response may not necessarily be equal to the `at_response_start`
  /// value of the current response.
  public var atResponseStart: Float = 0

  /// Similar to `at_response_start`, except that this value includes the rows in
  /// the current response.
  public var atResponseEnd: Float = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Information on if the current connection is being throttled.
public struct Google_Cloud_Bigquery_Storage_V1beta1_ThrottleStatus {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// How much this connection is being throttled.
  /// 0 is no throttling, 100 is completely throttled.
  public var throttlePercent: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response from calling `ReadRows` may include row data, progress and
/// throttling information.
public struct Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Row data is returned in format specified during session creation.
  public var rows: Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsResponse.OneOf_Rows? = nil

  /// Serialized row data in AVRO format.
  public var avroRows: Google_Cloud_Bigquery_Storage_V1beta1_AvroRows {
    get {
      if case .avroRows(let v)? = rows {return v}
      return Google_Cloud_Bigquery_Storage_V1beta1_AvroRows()
    }
    set {rows = .avroRows(newValue)}
  }

  /// Serialized row data in Arrow RecordBatch format.
  public var arrowRecordBatch: Google_Cloud_Bigquery_Storage_V1beta1_ArrowRecordBatch {
    get {
      if case .arrowRecordBatch(let v)? = rows {return v}
      return Google_Cloud_Bigquery_Storage_V1beta1_ArrowRecordBatch()
    }
    set {rows = .arrowRecordBatch(newValue)}
  }

  /// Number of serialized rows in the rows block. This value is recorded here,
  /// in addition to the row_count values in the output-specific messages in
  /// `rows`, so that code which needs to record progress through the stream can
  /// do so in an output format-independent way.
  public var rowCount: Int64 = 0

  /// Estimated stream statistics.
  public var status: Google_Cloud_Bigquery_Storage_V1beta1_StreamStatus {
    get {return _status ?? Google_Cloud_Bigquery_Storage_V1beta1_StreamStatus()}
    set {_status = newValue}
  }
  /// Returns true if `status` has been explicitly set.
  public var hasStatus: Bool {return self._status != nil}
  /// Clears the value of `status`. Subsequent reads from it will return its default value.
  public mutating func clearStatus() {self._status = nil}

  /// Throttling status. If unset, the latest response still describes
  /// the current throttling status.
  public var throttleStatus: Google_Cloud_Bigquery_Storage_V1beta1_ThrottleStatus {
    get {return _throttleStatus ?? Google_Cloud_Bigquery_Storage_V1beta1_ThrottleStatus()}
    set {_throttleStatus = newValue}
  }
  /// Returns true if `throttleStatus` has been explicitly set.
  public var hasThrottleStatus: Bool {return self._throttleStatus != nil}
  /// Clears the value of `throttleStatus`. Subsequent reads from it will return its default value.
  public mutating func clearThrottleStatus() {self._throttleStatus = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Row data is returned in format specified during session creation.
  public enum OneOf_Rows: Equatable {
    /// Serialized row data in AVRO format.
    case avroRows(Google_Cloud_Bigquery_Storage_V1beta1_AvroRows)
    /// Serialized row data in Arrow RecordBatch format.
    case arrowRecordBatch(Google_Cloud_Bigquery_Storage_V1beta1_ArrowRecordBatch)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsResponse.OneOf_Rows, rhs: Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsResponse.OneOf_Rows) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.avroRows, .avroRows): return {
        guard case .avroRows(let l) = lhs, case .avroRows(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.arrowRecordBatch, .arrowRecordBatch): return {
        guard case .arrowRecordBatch(let l) = lhs, case .arrowRecordBatch(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _status: Google_Cloud_Bigquery_Storage_V1beta1_StreamStatus? = nil
  fileprivate var _throttleStatus: Google_Cloud_Bigquery_Storage_V1beta1_ThrottleStatus? = nil
}

/// Information needed to request additional streams for an established read
/// session.
public struct Google_Cloud_Bigquery_Storage_V1beta1_BatchCreateReadSessionStreamsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Must be a non-expired session obtained from a call to
  /// CreateReadSession. Only the name field needs to be set.
  public var session: Google_Cloud_Bigquery_Storage_V1beta1_ReadSession {
    get {return _session ?? Google_Cloud_Bigquery_Storage_V1beta1_ReadSession()}
    set {_session = newValue}
  }
  /// Returns true if `session` has been explicitly set.
  public var hasSession: Bool {return self._session != nil}
  /// Clears the value of `session`. Subsequent reads from it will return its default value.
  public mutating func clearSession() {self._session = nil}

  /// Required. Number of new streams requested. Must be positive.
  /// Number of added streams may be less than this, see CreateReadSessionRequest
  /// for more information.
  public var requestedStreams: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _session: Google_Cloud_Bigquery_Storage_V1beta1_ReadSession? = nil
}

/// The response from `BatchCreateReadSessionStreams` returns the stream
/// identifiers for the newly created streams.
public struct Google_Cloud_Bigquery_Storage_V1beta1_BatchCreateReadSessionStreamsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Newly added streams.
  public var streams: [Google_Cloud_Bigquery_Storage_V1beta1_Stream] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request information for invoking `FinalizeStream`.
public struct Google_Cloud_Bigquery_Storage_V1beta1_FinalizeStreamRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Stream to finalize.
  public var stream: Google_Cloud_Bigquery_Storage_V1beta1_Stream {
    get {return _stream ?? Google_Cloud_Bigquery_Storage_V1beta1_Stream()}
    set {_stream = newValue}
  }
  /// Returns true if `stream` has been explicitly set.
  public var hasStream: Bool {return self._stream != nil}
  /// Clears the value of `stream`. Subsequent reads from it will return its default value.
  public mutating func clearStream() {self._stream = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _stream: Google_Cloud_Bigquery_Storage_V1beta1_Stream? = nil
}

/// Request information for `SplitReadStream`.
public struct Google_Cloud_Bigquery_Storage_V1beta1_SplitReadStreamRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Stream to split.
  public var originalStream: Google_Cloud_Bigquery_Storage_V1beta1_Stream {
    get {return _originalStream ?? Google_Cloud_Bigquery_Storage_V1beta1_Stream()}
    set {_originalStream = newValue}
  }
  /// Returns true if `originalStream` has been explicitly set.
  public var hasOriginalStream: Bool {return self._originalStream != nil}
  /// Clears the value of `originalStream`. Subsequent reads from it will return its default value.
  public mutating func clearOriginalStream() {self._originalStream = nil}

  /// A value in the range (0.0, 1.0) that specifies the fractional point at
  /// which the original stream should be split. The actual split point is
  /// evaluated on pre-filtered rows, so if a filter is provided, then there is
  /// no guarantee that the division of the rows between the new child streams
  /// will be proportional to this fractional value. Additionally, because the
  /// server-side unit for assigning data is collections of rows, this fraction
  /// will always map to to a data storage boundary on the server side.
  public var fraction: Float = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _originalStream: Google_Cloud_Bigquery_Storage_V1beta1_Stream? = nil
}

/// Response from `SplitReadStream`.
public struct Google_Cloud_Bigquery_Storage_V1beta1_SplitReadStreamResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Primary stream, which contains the beginning portion of
  /// |original_stream|. An empty value indicates that the original stream can no
  /// longer be split.
  public var primaryStream: Google_Cloud_Bigquery_Storage_V1beta1_Stream {
    get {return _primaryStream ?? Google_Cloud_Bigquery_Storage_V1beta1_Stream()}
    set {_primaryStream = newValue}
  }
  /// Returns true if `primaryStream` has been explicitly set.
  public var hasPrimaryStream: Bool {return self._primaryStream != nil}
  /// Clears the value of `primaryStream`. Subsequent reads from it will return its default value.
  public mutating func clearPrimaryStream() {self._primaryStream = nil}

  /// Remainder stream, which contains the tail of |original_stream|. An empty
  /// value indicates that the original stream can no longer be split.
  public var remainderStream: Google_Cloud_Bigquery_Storage_V1beta1_Stream {
    get {return _remainderStream ?? Google_Cloud_Bigquery_Storage_V1beta1_Stream()}
    set {_remainderStream = newValue}
  }
  /// Returns true if `remainderStream` has been explicitly set.
  public var hasRemainderStream: Bool {return self._remainderStream != nil}
  /// Clears the value of `remainderStream`. Subsequent reads from it will return its default value.
  public mutating func clearRemainderStream() {self._remainderStream = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _primaryStream: Google_Cloud_Bigquery_Storage_V1beta1_Stream? = nil
  fileprivate var _remainderStream: Google_Cloud_Bigquery_Storage_V1beta1_Stream? = nil
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.storage.v1beta1"

extension Google_Cloud_Bigquery_Storage_V1beta1_DataFormat: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DATA_FORMAT_UNSPECIFIED"),
    1: .same(proto: "AVRO"),
    3: .same(proto: "ARROW"),
  ]
}

extension Google_Cloud_Bigquery_Storage_V1beta1_ShardingStrategy: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "SHARDING_STRATEGY_UNSPECIFIED"),
    1: .same(proto: "LIQUID"),
    2: .same(proto: "BALANCED"),
  ]
}

extension Google_Cloud_Bigquery_Storage_V1beta1_Stream: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Stream"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_Stream, rhs: Google_Cloud_Bigquery_Storage_V1beta1_Stream) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_StreamPosition: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamPosition"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "stream"),
    2: .same(proto: "offset"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._stream) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.offset) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._stream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if self.offset != 0 {
      try visitor.visitSingularInt64Field(value: self.offset, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_StreamPosition, rhs: Google_Cloud_Bigquery_Storage_V1beta1_StreamPosition) -> Bool {
    if lhs._stream != rhs._stream {return false}
    if lhs.offset != rhs.offset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_ReadSession: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ReadSession"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .standard(proto: "expire_time"),
    5: .standard(proto: "avro_schema"),
    6: .standard(proto: "arrow_schema"),
    4: .same(proto: "streams"),
    7: .standard(proto: "table_reference"),
    8: .standard(proto: "table_modifiers"),
    9: .standard(proto: "sharding_strategy"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._expireTime) }()
      case 4: try { try decoder.decodeRepeatedMessageField(value: &self.streams) }()
      case 5: try {
        var v: Google_Cloud_Bigquery_Storage_V1beta1_AvroSchema?
        if let current = self.schema {
          try decoder.handleConflictingOneOf()
          if case .avroSchema(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.schema = .avroSchema(v)}
      }()
      case 6: try {
        var v: Google_Cloud_Bigquery_Storage_V1beta1_ArrowSchema?
        if let current = self.schema {
          try decoder.handleConflictingOneOf()
          if case .arrowSchema(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.schema = .arrowSchema(v)}
      }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._tableReference) }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._tableModifiers) }()
      case 9: try { try decoder.decodeSingularEnumField(value: &self.shardingStrategy) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if let v = self._expireTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if !self.streams.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.streams, fieldNumber: 4)
    }
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.schema {
    case .avroSchema?: try {
      guard case .avroSchema(let v)? = self.schema else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case .arrowSchema?: try {
      guard case .arrowSchema(let v)? = self.schema else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case nil: break
    }
    if let v = self._tableReference {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }
    if let v = self._tableModifiers {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    }
    if self.shardingStrategy != .unspecified {
      try visitor.visitSingularEnumField(value: self.shardingStrategy, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_ReadSession, rhs: Google_Cloud_Bigquery_Storage_V1beta1_ReadSession) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs._expireTime != rhs._expireTime {return false}
    if lhs.schema != rhs.schema {return false}
    if lhs.streams != rhs.streams {return false}
    if lhs._tableReference != rhs._tableReference {return false}
    if lhs._tableModifiers != rhs._tableModifiers {return false}
    if lhs.shardingStrategy != rhs.shardingStrategy {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_CreateReadSessionRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateReadSessionRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "table_reference"),
    6: .same(proto: "parent"),
    2: .standard(proto: "table_modifiers"),
    3: .standard(proto: "requested_streams"),
    4: .standard(proto: "read_options"),
    5: .same(proto: "format"),
    7: .standard(proto: "sharding_strategy"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._tableReference) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._tableModifiers) }()
      case 3: try { try decoder.decodeSingularInt32Field(value: &self.requestedStreams) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._readOptions) }()
      case 5: try { try decoder.decodeSingularEnumField(value: &self.format) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 7: try { try decoder.decodeSingularEnumField(value: &self.shardingStrategy) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._tableReference {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._tableModifiers {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if self.requestedStreams != 0 {
      try visitor.visitSingularInt32Field(value: self.requestedStreams, fieldNumber: 3)
    }
    if let v = self._readOptions {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    if self.format != .unspecified {
      try visitor.visitSingularEnumField(value: self.format, fieldNumber: 5)
    }
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 6)
    }
    if self.shardingStrategy != .unspecified {
      try visitor.visitSingularEnumField(value: self.shardingStrategy, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_CreateReadSessionRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta1_CreateReadSessionRequest) -> Bool {
    if lhs._tableReference != rhs._tableReference {return false}
    if lhs.parent != rhs.parent {return false}
    if lhs._tableModifiers != rhs._tableModifiers {return false}
    if lhs.requestedStreams != rhs.requestedStreams {return false}
    if lhs._readOptions != rhs._readOptions {return false}
    if lhs.format != rhs.format {return false}
    if lhs.shardingStrategy != rhs.shardingStrategy {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ReadRowsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "read_position"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._readPosition) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._readPosition {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsRequest) -> Bool {
    if lhs._readPosition != rhs._readPosition {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_StreamStatus: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamStatus"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "estimated_row_count"),
    2: .standard(proto: "fraction_consumed"),
    4: .same(proto: "progress"),
    3: .standard(proto: "is_splittable"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.estimatedRowCount) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.fractionConsumed) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.isSplittable) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._progress) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.estimatedRowCount != 0 {
      try visitor.visitSingularInt64Field(value: self.estimatedRowCount, fieldNumber: 1)
    }
    if self.fractionConsumed != 0 {
      try visitor.visitSingularFloatField(value: self.fractionConsumed, fieldNumber: 2)
    }
    if self.isSplittable != false {
      try visitor.visitSingularBoolField(value: self.isSplittable, fieldNumber: 3)
    }
    if let v = self._progress {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_StreamStatus, rhs: Google_Cloud_Bigquery_Storage_V1beta1_StreamStatus) -> Bool {
    if lhs.estimatedRowCount != rhs.estimatedRowCount {return false}
    if lhs.fractionConsumed != rhs.fractionConsumed {return false}
    if lhs._progress != rhs._progress {return false}
    if lhs.isSplittable != rhs.isSplittable {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_Progress: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Progress"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "at_response_start"),
    2: .standard(proto: "at_response_end"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularFloatField(value: &self.atResponseStart) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.atResponseEnd) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.atResponseStart != 0 {
      try visitor.visitSingularFloatField(value: self.atResponseStart, fieldNumber: 1)
    }
    if self.atResponseEnd != 0 {
      try visitor.visitSingularFloatField(value: self.atResponseEnd, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_Progress, rhs: Google_Cloud_Bigquery_Storage_V1beta1_Progress) -> Bool {
    if lhs.atResponseStart != rhs.atResponseStart {return false}
    if lhs.atResponseEnd != rhs.atResponseEnd {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_ThrottleStatus: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ThrottleStatus"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "throttle_percent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.throttlePercent) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.throttlePercent != 0 {
      try visitor.visitSingularInt32Field(value: self.throttlePercent, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_ThrottleStatus, rhs: Google_Cloud_Bigquery_Storage_V1beta1_ThrottleStatus) -> Bool {
    if lhs.throttlePercent != rhs.throttlePercent {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ReadRowsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    3: .standard(proto: "avro_rows"),
    4: .standard(proto: "arrow_record_batch"),
    6: .standard(proto: "row_count"),
    2: .same(proto: "status"),
    5: .standard(proto: "throttle_status"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularMessageField(value: &self._status) }()
      case 3: try {
        var v: Google_Cloud_Bigquery_Storage_V1beta1_AvroRows?
        if let current = self.rows {
          try decoder.handleConflictingOneOf()
          if case .avroRows(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.rows = .avroRows(v)}
      }()
      case 4: try {
        var v: Google_Cloud_Bigquery_Storage_V1beta1_ArrowRecordBatch?
        if let current = self.rows {
          try decoder.handleConflictingOneOf()
          if case .arrowRecordBatch(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.rows = .arrowRecordBatch(v)}
      }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._throttleStatus) }()
      case 6: try { try decoder.decodeSingularInt64Field(value: &self.rowCount) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._status {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.rows {
    case .avroRows?: try {
      guard case .avroRows(let v)? = self.rows else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .arrowRecordBatch?: try {
      guard case .arrowRecordBatch(let v)? = self.rows else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case nil: break
    }
    if let v = self._throttleStatus {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }
    if self.rowCount != 0 {
      try visitor.visitSingularInt64Field(value: self.rowCount, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsResponse, rhs: Google_Cloud_Bigquery_Storage_V1beta1_ReadRowsResponse) -> Bool {
    if lhs.rows != rhs.rows {return false}
    if lhs.rowCount != rhs.rowCount {return false}
    if lhs._status != rhs._status {return false}
    if lhs._throttleStatus != rhs._throttleStatus {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_BatchCreateReadSessionStreamsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchCreateReadSessionStreamsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "session"),
    2: .standard(proto: "requested_streams"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._session) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.requestedStreams) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._session {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if self.requestedStreams != 0 {
      try visitor.visitSingularInt32Field(value: self.requestedStreams, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_BatchCreateReadSessionStreamsRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta1_BatchCreateReadSessionStreamsRequest) -> Bool {
    if lhs._session != rhs._session {return false}
    if lhs.requestedStreams != rhs.requestedStreams {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_BatchCreateReadSessionStreamsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchCreateReadSessionStreamsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "streams"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.streams) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.streams.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.streams, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_BatchCreateReadSessionStreamsResponse, rhs: Google_Cloud_Bigquery_Storage_V1beta1_BatchCreateReadSessionStreamsResponse) -> Bool {
    if lhs.streams != rhs.streams {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_FinalizeStreamRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FinalizeStreamRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .same(proto: "stream"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularMessageField(value: &self._stream) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._stream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_FinalizeStreamRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta1_FinalizeStreamRequest) -> Bool {
    if lhs._stream != rhs._stream {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_SplitReadStreamRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SplitReadStreamRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "original_stream"),
    2: .same(proto: "fraction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._originalStream) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.fraction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._originalStream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if self.fraction != 0 {
      try visitor.visitSingularFloatField(value: self.fraction, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_SplitReadStreamRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta1_SplitReadStreamRequest) -> Bool {
    if lhs._originalStream != rhs._originalStream {return false}
    if lhs.fraction != rhs.fraction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta1_SplitReadStreamResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SplitReadStreamResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "primary_stream"),
    2: .standard(proto: "remainder_stream"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._primaryStream) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._remainderStream) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._primaryStream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._remainderStream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta1_SplitReadStreamResponse, rhs: Google_Cloud_Bigquery_Storage_V1beta1_SplitReadStreamResponse) -> Bool {
    if lhs._primaryStream != rhs._primaryStream {return false}
    if lhs._remainderStream != rhs._remainderStream {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
