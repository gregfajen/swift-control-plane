// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/storage/v1beta2/storage.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Request message for `CreateReadSession`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_CreateReadSessionRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The request project that owns the session, in the form of
  /// `projects/{project_id}`.
  public var parent: String = String()

  /// Required. Session to be created.
  public var readSession: Google_Cloud_Bigquery_Storage_V1beta2_ReadSession {
    get {return _readSession ?? Google_Cloud_Bigquery_Storage_V1beta2_ReadSession()}
    set {_readSession = newValue}
  }
  /// Returns true if `readSession` has been explicitly set.
  public var hasReadSession: Bool {return self._readSession != nil}
  /// Clears the value of `readSession`. Subsequent reads from it will return its default value.
  public mutating func clearReadSession() {self._readSession = nil}

  /// Max initial number of streams. If unset or zero, the server will
  /// provide a value of streams so as to produce reasonable throughput. Must be
  /// non-negative. The number of streams may be lower than the requested number,
  /// depending on the amount parallelism that is reasonable for the table. Error
  /// will be returned if the max count is greater than the current system
  /// max limit of 1,000.
  ///
  /// Streams must be read starting from offset 0.
  public var maxStreamCount: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _readSession: Google_Cloud_Bigquery_Storage_V1beta2_ReadSession? = nil
}

/// Request message for `ReadRows`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Stream to read rows from.
  public var readStream: String = String()

  /// The offset requested must be less than the last row read from Read.
  /// Requesting a larger offset is undefined. If not specified, start reading
  /// from offset zero.
  public var offset: Int64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Information on if the current connection is being throttled.
public struct Google_Cloud_Bigquery_Storage_V1beta2_ThrottleState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// How much this connection is being throttled. Zero means no throttling,
  /// 100 means fully throttled.
  public var throttlePercent: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Estimated stream statistics for a given Stream.
public struct Google_Cloud_Bigquery_Storage_V1beta2_StreamStats {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Represents the progress of the current stream.
  public var progress: Google_Cloud_Bigquery_Storage_V1beta2_StreamStats.Progress {
    get {return _progress ?? Google_Cloud_Bigquery_Storage_V1beta2_StreamStats.Progress()}
    set {_progress = newValue}
  }
  /// Returns true if `progress` has been explicitly set.
  public var hasProgress: Bool {return self._progress != nil}
  /// Clears the value of `progress`. Subsequent reads from it will return its default value.
  public mutating func clearProgress() {self._progress = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public struct Progress {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// The fraction of rows assigned to the stream that have been processed by
    /// the server so far, not including the rows in the current response
    /// message.
    ///
    /// This value, along with `at_response_end`, can be used to interpolate
    /// the progress made as the rows in the message are being processed using
    /// the following formula: `at_response_start + (at_response_end -
    /// at_response_start) * rows_processed_from_response / rows_in_response`.
    ///
    /// Note that if a filter is provided, the `at_response_end` value of the
    /// previous response may not necessarily be equal to the
    /// `at_response_start` value of the current response.
    public var atResponseStart: Double = 0

    /// Similar to `at_response_start`, except that this value includes the
    /// rows in the current response.
    public var atResponseEnd: Double = 0

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}
  }

  public init() {}

  fileprivate var _progress: Google_Cloud_Bigquery_Storage_V1beta2_StreamStats.Progress? = nil
}

/// Response from calling `ReadRows` may include row data, progress and
/// throttling information.
public struct Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Row data is returned in format specified during session creation.
  public var rows: Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsResponse.OneOf_Rows? = nil

  /// Serialized row data in AVRO format.
  public var avroRows: Google_Cloud_Bigquery_Storage_V1beta2_AvroRows {
    get {
      if case .avroRows(let v)? = rows {return v}
      return Google_Cloud_Bigquery_Storage_V1beta2_AvroRows()
    }
    set {rows = .avroRows(newValue)}
  }

  /// Serialized row data in Arrow RecordBatch format.
  public var arrowRecordBatch: Google_Cloud_Bigquery_Storage_V1beta2_ArrowRecordBatch {
    get {
      if case .arrowRecordBatch(let v)? = rows {return v}
      return Google_Cloud_Bigquery_Storage_V1beta2_ArrowRecordBatch()
    }
    set {rows = .arrowRecordBatch(newValue)}
  }

  /// Number of serialized rows in the rows block.
  public var rowCount: Int64 = 0

  /// Statistics for the stream.
  public var stats: Google_Cloud_Bigquery_Storage_V1beta2_StreamStats {
    get {return _stats ?? Google_Cloud_Bigquery_Storage_V1beta2_StreamStats()}
    set {_stats = newValue}
  }
  /// Returns true if `stats` has been explicitly set.
  public var hasStats: Bool {return self._stats != nil}
  /// Clears the value of `stats`. Subsequent reads from it will return its default value.
  public mutating func clearStats() {self._stats = nil}

  /// Throttling state. If unset, the latest response still describes
  /// the current throttling status.
  public var throttleState: Google_Cloud_Bigquery_Storage_V1beta2_ThrottleState {
    get {return _throttleState ?? Google_Cloud_Bigquery_Storage_V1beta2_ThrottleState()}
    set {_throttleState = newValue}
  }
  /// Returns true if `throttleState` has been explicitly set.
  public var hasThrottleState: Bool {return self._throttleState != nil}
  /// Clears the value of `throttleState`. Subsequent reads from it will return its default value.
  public mutating func clearThrottleState() {self._throttleState = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Row data is returned in format specified during session creation.
  public enum OneOf_Rows: Equatable {
    /// Serialized row data in AVRO format.
    case avroRows(Google_Cloud_Bigquery_Storage_V1beta2_AvroRows)
    /// Serialized row data in Arrow RecordBatch format.
    case arrowRecordBatch(Google_Cloud_Bigquery_Storage_V1beta2_ArrowRecordBatch)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsResponse.OneOf_Rows, rhs: Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsResponse.OneOf_Rows) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.avroRows, .avroRows): return {
        guard case .avroRows(let l) = lhs, case .avroRows(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.arrowRecordBatch, .arrowRecordBatch): return {
        guard case .arrowRecordBatch(let l) = lhs, case .arrowRecordBatch(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _stats: Google_Cloud_Bigquery_Storage_V1beta2_StreamStats? = nil
  fileprivate var _throttleState: Google_Cloud_Bigquery_Storage_V1beta2_ThrottleState? = nil
}

/// Request message for `SplitReadStream`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_SplitReadStreamRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Name of the stream to split.
  public var name: String = String()

  /// A value in the range (0.0, 1.0) that specifies the fractional point at
  /// which the original stream should be split. The actual split point is
  /// evaluated on pre-filtered rows, so if a filter is provided, then there is
  /// no guarantee that the division of the rows between the new child streams
  /// will be proportional to this fractional value. Additionally, because the
  /// server-side unit for assigning data is collections of rows, this fraction
  /// will always map to a data storage boundary on the server side.
  public var fraction: Double = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Google_Cloud_Bigquery_Storage_V1beta2_SplitReadStreamResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Primary stream, which contains the beginning portion of
  /// |original_stream|. An empty value indicates that the original stream can no
  /// longer be split.
  public var primaryStream: Google_Cloud_Bigquery_Storage_V1beta2_ReadStream {
    get {return _primaryStream ?? Google_Cloud_Bigquery_Storage_V1beta2_ReadStream()}
    set {_primaryStream = newValue}
  }
  /// Returns true if `primaryStream` has been explicitly set.
  public var hasPrimaryStream: Bool {return self._primaryStream != nil}
  /// Clears the value of `primaryStream`. Subsequent reads from it will return its default value.
  public mutating func clearPrimaryStream() {self._primaryStream = nil}

  /// Remainder stream, which contains the tail of |original_stream|. An empty
  /// value indicates that the original stream can no longer be split.
  public var remainderStream: Google_Cloud_Bigquery_Storage_V1beta2_ReadStream {
    get {return _remainderStream ?? Google_Cloud_Bigquery_Storage_V1beta2_ReadStream()}
    set {_remainderStream = newValue}
  }
  /// Returns true if `remainderStream` has been explicitly set.
  public var hasRemainderStream: Bool {return self._remainderStream != nil}
  /// Clears the value of `remainderStream`. Subsequent reads from it will return its default value.
  public mutating func clearRemainderStream() {self._remainderStream = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _primaryStream: Google_Cloud_Bigquery_Storage_V1beta2_ReadStream? = nil
  fileprivate var _remainderStream: Google_Cloud_Bigquery_Storage_V1beta2_ReadStream? = nil
}

/// Request message for `CreateWriteStream`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_CreateWriteStreamRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Reference to the table to which the stream belongs, in the format
  /// of `projects/{project}/datasets/{dataset}/tables/{table}`.
  public var parent: String = String()

  /// Required. Stream to be created.
  public var writeStream: Google_Cloud_Bigquery_Storage_V1beta2_WriteStream {
    get {return _writeStream ?? Google_Cloud_Bigquery_Storage_V1beta2_WriteStream()}
    set {_writeStream = newValue}
  }
  /// Returns true if `writeStream` has been explicitly set.
  public var hasWriteStream: Bool {return self._writeStream != nil}
  /// Clears the value of `writeStream`. Subsequent reads from it will return its default value.
  public mutating func clearWriteStream() {self._writeStream = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _writeStream: Google_Cloud_Bigquery_Storage_V1beta2_WriteStream? = nil
}

/// Request message for `AppendRows`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The stream that is the target of the append operation. This value
  /// must be specified for the initial request. If subsequent requests specify
  /// the stream name, it must equal to the value provided in the first request.
  /// To write to the _default stream, populate this field with a string in the
  /// format `projects/{project}/datasets/{dataset}/tables/{table}/_default`.
  public var writeStream: String {
    get {return _storage._writeStream}
    set {_uniqueStorage()._writeStream = newValue}
  }

  /// If present, the write is only performed if the next append offset is same
  /// as the provided value. If not present, the write is performed at the
  /// current end of stream. Specifying a value for this field is not allowed
  /// when calling AppendRows for the '_default' stream.
  public var offset: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._offset ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._offset = newValue}
  }
  /// Returns true if `offset` has been explicitly set.
  public var hasOffset: Bool {return _storage._offset != nil}
  /// Clears the value of `offset`. Subsequent reads from it will return its default value.
  public mutating func clearOffset() {_uniqueStorage()._offset = nil}

  /// Input rows. The `writer_schema` field must be specified at the initial
  /// request and currently, it will be ignored if specified in following
  /// requests. Following requests must have data in the same format as the
  /// initial request.
  public var rows: OneOf_Rows? {
    get {return _storage._rows}
    set {_uniqueStorage()._rows = newValue}
  }

  /// Rows in proto format.
  public var protoRows: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.ProtoData {
    get {
      if case .protoRows(let v)? = _storage._rows {return v}
      return Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.ProtoData()
    }
    set {_uniqueStorage()._rows = .protoRows(newValue)}
  }

  /// Only initial request setting is respected. If true, drop unknown input
  /// fields. Otherwise, the extra fields will cause append to fail. Default
  /// value is false.
  public var ignoreUnknownFields: Bool {
    get {return _storage._ignoreUnknownFields}
    set {_uniqueStorage()._ignoreUnknownFields = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Input rows. The `writer_schema` field must be specified at the initial
  /// request and currently, it will be ignored if specified in following
  /// requests. Following requests must have data in the same format as the
  /// initial request.
  public enum OneOf_Rows: Equatable {
    /// Rows in proto format.
    case protoRows(Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.ProtoData)

    fileprivate var isInitialized: Bool {
      guard case .protoRows(let v) = self else {return true}
      return v.isInitialized
    }

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.OneOf_Rows, rhs: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.OneOf_Rows) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.protoRows, .protoRows): return {
        guard case .protoRows(let l) = lhs, case .protoRows(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      }
    }
  #endif
  }

  /// Proto schema and data.
  public struct ProtoData {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Proto schema used to serialize the data.
    public var writerSchema: Google_Cloud_Bigquery_Storage_V1beta2_ProtoSchema {
      get {return _writerSchema ?? Google_Cloud_Bigquery_Storage_V1beta2_ProtoSchema()}
      set {_writerSchema = newValue}
    }
    /// Returns true if `writerSchema` has been explicitly set.
    public var hasWriterSchema: Bool {return self._writerSchema != nil}
    /// Clears the value of `writerSchema`. Subsequent reads from it will return its default value.
    public mutating func clearWriterSchema() {self._writerSchema = nil}

    /// Serialized row data in protobuf message format.
    public var rows: Google_Cloud_Bigquery_Storage_V1beta2_ProtoRows {
      get {return _rows ?? Google_Cloud_Bigquery_Storage_V1beta2_ProtoRows()}
      set {_rows = newValue}
    }
    /// Returns true if `rows` has been explicitly set.
    public var hasRows: Bool {return self._rows != nil}
    /// Clears the value of `rows`. Subsequent reads from it will return its default value.
    public mutating func clearRows() {self._rows = nil}

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}

    fileprivate var _writerSchema: Google_Cloud_Bigquery_Storage_V1beta2_ProtoSchema? = nil
    fileprivate var _rows: Google_Cloud_Bigquery_Storage_V1beta2_ProtoRows? = nil
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Response message for `AppendRows`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var response: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsResponse.OneOf_Response? = nil

  /// The row offset at which the last append occurred.
  public var offset: Int64 {
    get {
      if case .offset(let v)? = response {return v}
      return 0
    }
    set {response = .offset(newValue)}
  }

  /// Error in case of append failure. If set, it means rows are not accepted
  /// into the system. Users can retry within the same connection.
  public var error: Google_Rpc_Status {
    get {
      if case .error(let v)? = response {return v}
      return Google_Rpc_Status()
    }
    set {response = .error(newValue)}
  }

  /// If backend detects a schema update, pass it to user so that user can
  /// use it to input new type of message. It will be empty when there is no
  /// schema updates.
  public var updatedSchema: Google_Cloud_Bigquery_Storage_V1beta2_TableSchema {
    get {return _updatedSchema ?? Google_Cloud_Bigquery_Storage_V1beta2_TableSchema()}
    set {_updatedSchema = newValue}
  }
  /// Returns true if `updatedSchema` has been explicitly set.
  public var hasUpdatedSchema: Bool {return self._updatedSchema != nil}
  /// Clears the value of `updatedSchema`. Subsequent reads from it will return its default value.
  public mutating func clearUpdatedSchema() {self._updatedSchema = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public enum OneOf_Response: Equatable {
    /// The row offset at which the last append occurred.
    case offset(Int64)
    /// Error in case of append failure. If set, it means rows are not accepted
    /// into the system. Users can retry within the same connection.
    case error(Google_Rpc_Status)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsResponse.OneOf_Response, rhs: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsResponse.OneOf_Response) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.offset, .offset): return {
        guard case .offset(let l) = lhs, case .offset(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.error, .error): return {
        guard case .error(let l) = lhs, case .error(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _updatedSchema: Google_Cloud_Bigquery_Storage_V1beta2_TableSchema? = nil
}

/// Request message for `GetWriteStreamRequest`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_GetWriteStreamRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Name of the stream to get, in the form of
  /// `projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}`.
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for `BatchCommitWriteStreams`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_BatchCommitWriteStreamsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Parent table that all the streams should belong to, in the form
  /// of `projects/{project}/datasets/{dataset}/tables/{table}`.
  public var parent: String = String()

  /// Required. The group of streams that will be committed atomically.
  public var writeStreams: [String] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response message for `BatchCommitWriteStreams`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_BatchCommitWriteStreamsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The time at which streams were committed in microseconds granularity.
  public var commitTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _commitTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_commitTime = newValue}
  }
  /// Returns true if `commitTime` has been explicitly set.
  public var hasCommitTime: Bool {return self._commitTime != nil}
  /// Clears the value of `commitTime`. Subsequent reads from it will return its default value.
  public mutating func clearCommitTime() {self._commitTime = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _commitTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

/// Request message for invoking `FinalizeWriteStream`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_FinalizeWriteStreamRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Name of the stream to finalize, in the form of
  /// `projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}`.
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response message for `FinalizeWriteStream`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_FinalizeWriteStreamResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Number of rows in the finalized stream.
  public var rowCount: Int64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for `FlushRows`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_FlushRowsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The stream that is the target of the flush operation.
  public var writeStream: String = String()

  /// Ending offset of the flush operation. Rows before this offset(including
  /// this offset) will be flushed.
  public var offset: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _offset ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_offset = newValue}
  }
  /// Returns true if `offset` has been explicitly set.
  public var hasOffset: Bool {return self._offset != nil}
  /// Clears the value of `offset`. Subsequent reads from it will return its default value.
  public mutating func clearOffset() {self._offset = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _offset: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
}

/// Respond message for `FlushRows`.
public struct Google_Cloud_Bigquery_Storage_V1beta2_FlushRowsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The rows before this offset (including this offset) are flushed.
  public var offset: Int64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.storage.v1beta2"

extension Google_Cloud_Bigquery_Storage_V1beta2_CreateReadSessionRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateReadSessionRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .standard(proto: "read_session"),
    3: .standard(proto: "max_stream_count"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._readSession) }()
      case 3: try { try decoder.decodeSingularInt32Field(value: &self.maxStreamCount) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 1)
    }
    if let v = self._readSession {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if self.maxStreamCount != 0 {
      try visitor.visitSingularInt32Field(value: self.maxStreamCount, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_CreateReadSessionRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta2_CreateReadSessionRequest) -> Bool {
    if lhs.parent != rhs.parent {return false}
    if lhs._readSession != rhs._readSession {return false}
    if lhs.maxStreamCount != rhs.maxStreamCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ReadRowsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "read_stream"),
    2: .same(proto: "offset"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.readStream) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.offset) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.readStream.isEmpty {
      try visitor.visitSingularStringField(value: self.readStream, fieldNumber: 1)
    }
    if self.offset != 0 {
      try visitor.visitSingularInt64Field(value: self.offset, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsRequest) -> Bool {
    if lhs.readStream != rhs.readStream {return false}
    if lhs.offset != rhs.offset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_ThrottleState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ThrottleState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "throttle_percent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.throttlePercent) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.throttlePercent != 0 {
      try visitor.visitSingularInt32Field(value: self.throttlePercent, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_ThrottleState, rhs: Google_Cloud_Bigquery_Storage_V1beta2_ThrottleState) -> Bool {
    if lhs.throttlePercent != rhs.throttlePercent {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_StreamStats: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamStats"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .same(proto: "progress"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularMessageField(value: &self._progress) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._progress {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_StreamStats, rhs: Google_Cloud_Bigquery_Storage_V1beta2_StreamStats) -> Bool {
    if lhs._progress != rhs._progress {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_StreamStats.Progress: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Bigquery_Storage_V1beta2_StreamStats.protoMessageName + ".Progress"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "at_response_start"),
    2: .standard(proto: "at_response_end"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularDoubleField(value: &self.atResponseStart) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.atResponseEnd) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.atResponseStart != 0 {
      try visitor.visitSingularDoubleField(value: self.atResponseStart, fieldNumber: 1)
    }
    if self.atResponseEnd != 0 {
      try visitor.visitSingularDoubleField(value: self.atResponseEnd, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_StreamStats.Progress, rhs: Google_Cloud_Bigquery_Storage_V1beta2_StreamStats.Progress) -> Bool {
    if lhs.atResponseStart != rhs.atResponseStart {return false}
    if lhs.atResponseEnd != rhs.atResponseEnd {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ReadRowsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    3: .standard(proto: "avro_rows"),
    4: .standard(proto: "arrow_record_batch"),
    6: .standard(proto: "row_count"),
    2: .same(proto: "stats"),
    5: .standard(proto: "throttle_state"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularMessageField(value: &self._stats) }()
      case 3: try {
        var v: Google_Cloud_Bigquery_Storage_V1beta2_AvroRows?
        if let current = self.rows {
          try decoder.handleConflictingOneOf()
          if case .avroRows(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.rows = .avroRows(v)}
      }()
      case 4: try {
        var v: Google_Cloud_Bigquery_Storage_V1beta2_ArrowRecordBatch?
        if let current = self.rows {
          try decoder.handleConflictingOneOf()
          if case .arrowRecordBatch(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.rows = .arrowRecordBatch(v)}
      }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._throttleState) }()
      case 6: try { try decoder.decodeSingularInt64Field(value: &self.rowCount) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._stats {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.rows {
    case .avroRows?: try {
      guard case .avroRows(let v)? = self.rows else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .arrowRecordBatch?: try {
      guard case .arrowRecordBatch(let v)? = self.rows else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case nil: break
    }
    if let v = self._throttleState {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }
    if self.rowCount != 0 {
      try visitor.visitSingularInt64Field(value: self.rowCount, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsResponse, rhs: Google_Cloud_Bigquery_Storage_V1beta2_ReadRowsResponse) -> Bool {
    if lhs.rows != rhs.rows {return false}
    if lhs.rowCount != rhs.rowCount {return false}
    if lhs._stats != rhs._stats {return false}
    if lhs._throttleState != rhs._throttleState {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_SplitReadStreamRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SplitReadStreamRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "fraction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.fraction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.fraction != 0 {
      try visitor.visitSingularDoubleField(value: self.fraction, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_SplitReadStreamRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta2_SplitReadStreamRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.fraction != rhs.fraction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_SplitReadStreamResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SplitReadStreamResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "primary_stream"),
    2: .standard(proto: "remainder_stream"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._primaryStream) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._remainderStream) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._primaryStream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._remainderStream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_SplitReadStreamResponse, rhs: Google_Cloud_Bigquery_Storage_V1beta2_SplitReadStreamResponse) -> Bool {
    if lhs._primaryStream != rhs._primaryStream {return false}
    if lhs._remainderStream != rhs._remainderStream {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_CreateWriteStreamRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateWriteStreamRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .standard(proto: "write_stream"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._writeStream) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 1)
    }
    if let v = self._writeStream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_CreateWriteStreamRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta2_CreateWriteStreamRequest) -> Bool {
    if lhs.parent != rhs.parent {return false}
    if lhs._writeStream != rhs._writeStream {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AppendRowsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "write_stream"),
    2: .same(proto: "offset"),
    4: .standard(proto: "proto_rows"),
    5: .standard(proto: "ignore_unknown_fields"),
  ]

  fileprivate class _StorageClass {
    var _writeStream: String = String()
    var _offset: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _rows: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.OneOf_Rows?
    var _ignoreUnknownFields: Bool = false

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _writeStream = source._writeStream
      _offset = source._offset
      _rows = source._rows
      _ignoreUnknownFields = source._ignoreUnknownFields
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public var isInitialized: Bool {
    return withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if let v = _storage._rows, !v.isInitialized {return false}
      return true
    }
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._writeStream) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._offset) }()
        case 4: try {
          var v: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.ProtoData?
          if let current = _storage._rows {
            try decoder.handleConflictingOneOf()
            if case .protoRows(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._rows = .protoRows(v)}
        }()
        case 5: try { try decoder.decodeSingularBoolField(value: &_storage._ignoreUnknownFields) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._writeStream.isEmpty {
        try visitor.visitSingularStringField(value: _storage._writeStream, fieldNumber: 1)
      }
      if let v = _storage._offset {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if case .protoRows(let v)? = _storage._rows {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }
      if _storage._ignoreUnknownFields != false {
        try visitor.visitSingularBoolField(value: _storage._ignoreUnknownFields, fieldNumber: 5)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._writeStream != rhs_storage._writeStream {return false}
        if _storage._offset != rhs_storage._offset {return false}
        if _storage._rows != rhs_storage._rows {return false}
        if _storage._ignoreUnknownFields != rhs_storage._ignoreUnknownFields {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.ProtoData: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.protoMessageName + ".ProtoData"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "writer_schema"),
    2: .same(proto: "rows"),
  ]

  public var isInitialized: Bool {
    if let v = self._writerSchema, !v.isInitialized {return false}
    return true
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._writerSchema) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._rows) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._writerSchema {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._rows {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.ProtoData, rhs: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsRequest.ProtoData) -> Bool {
    if lhs._writerSchema != rhs._writerSchema {return false}
    if lhs._rows != rhs._rows {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AppendRowsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "offset"),
    2: .same(proto: "error"),
    3: .standard(proto: "updated_schema"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        if self.response != nil {try decoder.handleConflictingOneOf()}
        var v: Int64?
        try decoder.decodeSingularInt64Field(value: &v)
        if let v = v {self.response = .offset(v)}
      }()
      case 2: try {
        var v: Google_Rpc_Status?
        if let current = self.response {
          try decoder.handleConflictingOneOf()
          if case .error(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.response = .error(v)}
      }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._updatedSchema) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.response {
    case .offset?: try {
      guard case .offset(let v)? = self.response else { preconditionFailure() }
      try visitor.visitSingularInt64Field(value: v, fieldNumber: 1)
    }()
    case .error?: try {
      guard case .error(let v)? = self.response else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    if let v = self._updatedSchema {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsResponse, rhs: Google_Cloud_Bigquery_Storage_V1beta2_AppendRowsResponse) -> Bool {
    if lhs.response != rhs.response {return false}
    if lhs._updatedSchema != rhs._updatedSchema {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_GetWriteStreamRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetWriteStreamRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_GetWriteStreamRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta2_GetWriteStreamRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_BatchCommitWriteStreamsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchCommitWriteStreamsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .standard(proto: "write_streams"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 2: try { try decoder.decodeRepeatedStringField(value: &self.writeStreams) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 1)
    }
    if !self.writeStreams.isEmpty {
      try visitor.visitRepeatedStringField(value: self.writeStreams, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_BatchCommitWriteStreamsRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta2_BatchCommitWriteStreamsRequest) -> Bool {
    if lhs.parent != rhs.parent {return false}
    if lhs.writeStreams != rhs.writeStreams {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_BatchCommitWriteStreamsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchCommitWriteStreamsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "commit_time"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._commitTime) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._commitTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_BatchCommitWriteStreamsResponse, rhs: Google_Cloud_Bigquery_Storage_V1beta2_BatchCommitWriteStreamsResponse) -> Bool {
    if lhs._commitTime != rhs._commitTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_FinalizeWriteStreamRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FinalizeWriteStreamRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_FinalizeWriteStreamRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta2_FinalizeWriteStreamRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_FinalizeWriteStreamResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FinalizeWriteStreamResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "row_count"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.rowCount) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.rowCount != 0 {
      try visitor.visitSingularInt64Field(value: self.rowCount, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_FinalizeWriteStreamResponse, rhs: Google_Cloud_Bigquery_Storage_V1beta2_FinalizeWriteStreamResponse) -> Bool {
    if lhs.rowCount != rhs.rowCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_FlushRowsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FlushRowsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "write_stream"),
    2: .same(proto: "offset"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.writeStream) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._offset) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.writeStream.isEmpty {
      try visitor.visitSingularStringField(value: self.writeStream, fieldNumber: 1)
    }
    if let v = self._offset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_FlushRowsRequest, rhs: Google_Cloud_Bigquery_Storage_V1beta2_FlushRowsRequest) -> Bool {
    if lhs.writeStream != rhs.writeStream {return false}
    if lhs._offset != rhs._offset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1beta2_FlushRowsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FlushRowsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "offset"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.offset) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.offset != 0 {
      try visitor.visitSingularInt64Field(value: self.offset, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1beta2_FlushRowsResponse, rhs: Google_Cloud_Bigquery_Storage_V1beta2_FlushRowsResponse) -> Bool {
    if lhs.offset != rhs.offset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
