// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/storage/v1alpha2/storage.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Request message for `CreateWriteStream`.
public struct Google_Cloud_Bigquery_Storage_V1alpha2_CreateWriteStreamRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Reference to the table to which the stream belongs, in the format
  /// of `projects/{project}/datasets/{dataset}/tables/{table}`.
  public var parent: String = String()

  /// Required. Stream to be created.
  public var writeStream: Google_Cloud_Bigquery_Storage_V1alpha2_WriteStream {
    get {return _writeStream ?? Google_Cloud_Bigquery_Storage_V1alpha2_WriteStream()}
    set {_writeStream = newValue}
  }
  /// Returns true if `writeStream` has been explicitly set.
  public var hasWriteStream: Bool {return self._writeStream != nil}
  /// Clears the value of `writeStream`. Subsequent reads from it will return its default value.
  public mutating func clearWriteStream() {self._writeStream = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _writeStream: Google_Cloud_Bigquery_Storage_V1alpha2_WriteStream? = nil
}

/// Request message for `AppendRows`.
public struct Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The stream that is the target of the append operation. This value must be
  /// specified for the initial request. If subsequent requests specify the
  /// stream name, it must equal to the value provided in the first request.
  public var writeStream: String {
    get {return _storage._writeStream}
    set {_uniqueStorage()._writeStream = newValue}
  }

  /// Optional. If present, the write is only performed if the next append offset is same
  /// as the provided value. If not present, the write is performed at the
  /// current end of stream.
  public var offset: SwiftProtobuf.Google_Protobuf_Int64Value {
    get {return _storage._offset ?? SwiftProtobuf.Google_Protobuf_Int64Value()}
    set {_uniqueStorage()._offset = newValue}
  }
  /// Returns true if `offset` has been explicitly set.
  public var hasOffset: Bool {return _storage._offset != nil}
  /// Clears the value of `offset`. Subsequent reads from it will return its default value.
  public mutating func clearOffset() {_uniqueStorage()._offset = nil}

  /// Input rows. The `writer_schema` field must be specified at the initial
  /// request and currently, it will be ignored if specified in following
  /// requests. Following requests must have data in the same format as the
  /// initial request.
  public var rows: OneOf_Rows? {
    get {return _storage._rows}
    set {_uniqueStorage()._rows = newValue}
  }

  public var protoRows: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.ProtoData {
    get {
      if case .protoRows(let v)? = _storage._rows {return v}
      return Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.ProtoData()
    }
    set {_uniqueStorage()._rows = .protoRows(newValue)}
  }

  /// Only initial request setting is respected. If true, drop unknown input
  /// fields. Otherwise, the extra fields will cause append to fail. Default
  /// value is false.
  public var ignoreUnknownFields: Bool {
    get {return _storage._ignoreUnknownFields}
    set {_uniqueStorage()._ignoreUnknownFields = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Input rows. The `writer_schema` field must be specified at the initial
  /// request and currently, it will be ignored if specified in following
  /// requests. Following requests must have data in the same format as the
  /// initial request.
  public enum OneOf_Rows: Equatable {
    case protoRows(Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.ProtoData)

    fileprivate var isInitialized: Bool {
      guard case .protoRows(let v) = self else {return true}
      return v.isInitialized
    }

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.OneOf_Rows, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.OneOf_Rows) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.protoRows, .protoRows): return {
        guard case .protoRows(let l) = lhs, case .protoRows(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      }
    }
  #endif
  }

  public struct ProtoData {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Proto schema used to serialize the data.
    public var writerSchema: Google_Cloud_Bigquery_Storage_V1alpha2_ProtoSchema {
      get {return _writerSchema ?? Google_Cloud_Bigquery_Storage_V1alpha2_ProtoSchema()}
      set {_writerSchema = newValue}
    }
    /// Returns true if `writerSchema` has been explicitly set.
    public var hasWriterSchema: Bool {return self._writerSchema != nil}
    /// Clears the value of `writerSchema`. Subsequent reads from it will return its default value.
    public mutating func clearWriterSchema() {self._writerSchema = nil}

    /// Serialized row data in protobuf message format.
    public var rows: Google_Cloud_Bigquery_Storage_V1alpha2_ProtoRows {
      get {return _rows ?? Google_Cloud_Bigquery_Storage_V1alpha2_ProtoRows()}
      set {_rows = newValue}
    }
    /// Returns true if `rows` has been explicitly set.
    public var hasRows: Bool {return self._rows != nil}
    /// Clears the value of `rows`. Subsequent reads from it will return its default value.
    public mutating func clearRows() {self._rows = nil}

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}

    fileprivate var _writerSchema: Google_Cloud_Bigquery_Storage_V1alpha2_ProtoSchema? = nil
    fileprivate var _rows: Google_Cloud_Bigquery_Storage_V1alpha2_ProtoRows? = nil
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Response message for `AppendRows`.
public struct Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var response: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsResponse.OneOf_Response? = nil

  /// The row offset at which the last append occurred.
  public var offset: Int64 {
    get {
      if case .offset(let v)? = response {return v}
      return 0
    }
    set {response = .offset(newValue)}
  }

  /// Error in case of append failure. If set, it means rows are not accepted
  /// into the system. Users can retry within the same connection.
  public var error: Google_Rpc_Status {
    get {
      if case .error(let v)? = response {return v}
      return Google_Rpc_Status()
    }
    set {response = .error(newValue)}
  }

  /// If backend detects a schema update, pass it to user so that user can
  /// use it to input new type of message. It will be empty when there is no
  /// schema updates.
  public var updatedSchema: Google_Cloud_Bigquery_Storage_V1alpha2_TableSchema {
    get {return _updatedSchema ?? Google_Cloud_Bigquery_Storage_V1alpha2_TableSchema()}
    set {_updatedSchema = newValue}
  }
  /// Returns true if `updatedSchema` has been explicitly set.
  public var hasUpdatedSchema: Bool {return self._updatedSchema != nil}
  /// Clears the value of `updatedSchema`. Subsequent reads from it will return its default value.
  public mutating func clearUpdatedSchema() {self._updatedSchema = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public enum OneOf_Response: Equatable {
    /// The row offset at which the last append occurred.
    case offset(Int64)
    /// Error in case of append failure. If set, it means rows are not accepted
    /// into the system. Users can retry within the same connection.
    case error(Google_Rpc_Status)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsResponse.OneOf_Response, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsResponse.OneOf_Response) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.offset, .offset): return {
        guard case .offset(let l) = lhs, case .offset(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.error, .error): return {
        guard case .error(let l) = lhs, case .error(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _updatedSchema: Google_Cloud_Bigquery_Storage_V1alpha2_TableSchema? = nil
}

/// Request message for `GetWriteStreamRequest`.
public struct Google_Cloud_Bigquery_Storage_V1alpha2_GetWriteStreamRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Name of the stream to get, in the form of
  /// `projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}`.
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for `BatchCommitWriteStreams`.
public struct Google_Cloud_Bigquery_Storage_V1alpha2_BatchCommitWriteStreamsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Parent table that all the streams should belong to, in the form of
  /// `projects/{project}/datasets/{dataset}/tables/{table}`.
  public var parent: String = String()

  /// Required. The group of streams that will be committed atomically.
  public var writeStreams: [String] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response message for `BatchCommitWriteStreams`.
public struct Google_Cloud_Bigquery_Storage_V1alpha2_BatchCommitWriteStreamsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The time at which streams were committed in microseconds granularity.
  public var commitTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _commitTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_commitTime = newValue}
  }
  /// Returns true if `commitTime` has been explicitly set.
  public var hasCommitTime: Bool {return self._commitTime != nil}
  /// Clears the value of `commitTime`. Subsequent reads from it will return its default value.
  public mutating func clearCommitTime() {self._commitTime = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _commitTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

/// Request message for invoking `FinalizeWriteStream`.
public struct Google_Cloud_Bigquery_Storage_V1alpha2_FinalizeWriteStreamRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Name of the stream to finalize, in the form of
  /// `projects/{project}/datasets/{dataset}/tables/{table}/streams/{stream}`.
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response message for `FinalizeWriteStream`.
public struct Google_Cloud_Bigquery_Storage_V1alpha2_FinalizeWriteStreamResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Number of rows in the finalized stream.
  public var rowCount: Int64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for `FlushRows`.
public struct Google_Cloud_Bigquery_Storage_V1alpha2_FlushRowsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The stream that is the target of the flush operation.
  public var writeStream: String = String()

  /// Ending offset of the flush operation. Rows before this offset(including
  /// this offset) will be flushed.
  public var offset: Int64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Respond message for `FlushRows`.
public struct Google_Cloud_Bigquery_Storage_V1alpha2_FlushRowsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The rows before this offset (including this offset) are flushed.
  public var offset: Int64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.storage.v1alpha2"

extension Google_Cloud_Bigquery_Storage_V1alpha2_CreateWriteStreamRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateWriteStreamRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .standard(proto: "write_stream"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._writeStream) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 1)
    }
    if let v = self._writeStream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_CreateWriteStreamRequest, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_CreateWriteStreamRequest) -> Bool {
    if lhs.parent != rhs.parent {return false}
    if lhs._writeStream != rhs._writeStream {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AppendRowsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "write_stream"),
    2: .same(proto: "offset"),
    4: .standard(proto: "proto_rows"),
    5: .standard(proto: "ignore_unknown_fields"),
  ]

  fileprivate class _StorageClass {
    var _writeStream: String = String()
    var _offset: SwiftProtobuf.Google_Protobuf_Int64Value? = nil
    var _rows: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.OneOf_Rows?
    var _ignoreUnknownFields: Bool = false

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _writeStream = source._writeStream
      _offset = source._offset
      _rows = source._rows
      _ignoreUnknownFields = source._ignoreUnknownFields
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public var isInitialized: Bool {
    return withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if let v = _storage._rows, !v.isInitialized {return false}
      return true
    }
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._writeStream) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._offset) }()
        case 4: try {
          var v: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.ProtoData?
          if let current = _storage._rows {
            try decoder.handleConflictingOneOf()
            if case .protoRows(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {_storage._rows = .protoRows(v)}
        }()
        case 5: try { try decoder.decodeSingularBoolField(value: &_storage._ignoreUnknownFields) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if !_storage._writeStream.isEmpty {
        try visitor.visitSingularStringField(value: _storage._writeStream, fieldNumber: 1)
      }
      if let v = _storage._offset {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if case .protoRows(let v)? = _storage._rows {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }
      if _storage._ignoreUnknownFields != false {
        try visitor.visitSingularBoolField(value: _storage._ignoreUnknownFields, fieldNumber: 5)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._writeStream != rhs_storage._writeStream {return false}
        if _storage._offset != rhs_storage._offset {return false}
        if _storage._rows != rhs_storage._rows {return false}
        if _storage._ignoreUnknownFields != rhs_storage._ignoreUnknownFields {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.ProtoData: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.protoMessageName + ".ProtoData"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "writer_schema"),
    2: .same(proto: "rows"),
  ]

  public var isInitialized: Bool {
    if let v = self._writerSchema, !v.isInitialized {return false}
    return true
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._writerSchema) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._rows) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._writerSchema {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._rows {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.ProtoData, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsRequest.ProtoData) -> Bool {
    if lhs._writerSchema != rhs._writerSchema {return false}
    if lhs._rows != rhs._rows {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AppendRowsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "offset"),
    2: .same(proto: "error"),
    3: .standard(proto: "updated_schema"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        if self.response != nil {try decoder.handleConflictingOneOf()}
        var v: Int64?
        try decoder.decodeSingularInt64Field(value: &v)
        if let v = v {self.response = .offset(v)}
      }()
      case 2: try {
        var v: Google_Rpc_Status?
        if let current = self.response {
          try decoder.handleConflictingOneOf()
          if case .error(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.response = .error(v)}
      }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._updatedSchema) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.response {
    case .offset?: try {
      guard case .offset(let v)? = self.response else { preconditionFailure() }
      try visitor.visitSingularInt64Field(value: v, fieldNumber: 1)
    }()
    case .error?: try {
      guard case .error(let v)? = self.response else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    if let v = self._updatedSchema {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsResponse, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_AppendRowsResponse) -> Bool {
    if lhs.response != rhs.response {return false}
    if lhs._updatedSchema != rhs._updatedSchema {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1alpha2_GetWriteStreamRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetWriteStreamRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_GetWriteStreamRequest, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_GetWriteStreamRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1alpha2_BatchCommitWriteStreamsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchCommitWriteStreamsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .standard(proto: "write_streams"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 2: try { try decoder.decodeRepeatedStringField(value: &self.writeStreams) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 1)
    }
    if !self.writeStreams.isEmpty {
      try visitor.visitRepeatedStringField(value: self.writeStreams, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_BatchCommitWriteStreamsRequest, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_BatchCommitWriteStreamsRequest) -> Bool {
    if lhs.parent != rhs.parent {return false}
    if lhs.writeStreams != rhs.writeStreams {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1alpha2_BatchCommitWriteStreamsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchCommitWriteStreamsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "commit_time"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._commitTime) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._commitTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_BatchCommitWriteStreamsResponse, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_BatchCommitWriteStreamsResponse) -> Bool {
    if lhs._commitTime != rhs._commitTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1alpha2_FinalizeWriteStreamRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FinalizeWriteStreamRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_FinalizeWriteStreamRequest, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_FinalizeWriteStreamRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1alpha2_FinalizeWriteStreamResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FinalizeWriteStreamResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "row_count"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.rowCount) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.rowCount != 0 {
      try visitor.visitSingularInt64Field(value: self.rowCount, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_FinalizeWriteStreamResponse, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_FinalizeWriteStreamResponse) -> Bool {
    if lhs.rowCount != rhs.rowCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1alpha2_FlushRowsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FlushRowsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "write_stream"),
    2: .same(proto: "offset"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.writeStream) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.offset) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.writeStream.isEmpty {
      try visitor.visitSingularStringField(value: self.writeStream, fieldNumber: 1)
    }
    if self.offset != 0 {
      try visitor.visitSingularInt64Field(value: self.offset, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_FlushRowsRequest, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_FlushRowsRequest) -> Bool {
    if lhs.writeStream != rhs.writeStream {return false}
    if lhs.offset != rhs.offset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1alpha2_FlushRowsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FlushRowsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "offset"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.offset) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.offset != 0 {
      try visitor.visitSingularInt64Field(value: self.offset, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1alpha2_FlushRowsResponse, rhs: Google_Cloud_Bigquery_Storage_V1alpha2_FlushRowsResponse) -> Bool {
    if lhs.offset != rhs.offset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
