// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/bigquery/storage/v1/storage.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2019 Google LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Request message for `CreateReadSession`.
public struct Google_Cloud_Bigquery_Storage_V1_CreateReadSessionRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The request project that owns the session, in the form of
  /// `projects/{project_id}`.
  public var parent: String = String()

  /// Required. Session to be created.
  public var readSession: Google_Cloud_Bigquery_Storage_V1_ReadSession {
    get {return _readSession ?? Google_Cloud_Bigquery_Storage_V1_ReadSession()}
    set {_readSession = newValue}
  }
  /// Returns true if `readSession` has been explicitly set.
  public var hasReadSession: Bool {return self._readSession != nil}
  /// Clears the value of `readSession`. Subsequent reads from it will return its default value.
  public mutating func clearReadSession() {self._readSession = nil}

  /// Max initial number of streams. If unset or zero, the server will
  /// provide a value of streams so as to produce reasonable throughput. Must be
  /// non-negative. The number of streams may be lower than the requested number,
  /// depending on the amount parallelism that is reasonable for the table. Error
  /// will be returned if the max count is greater than the current system
  /// max limit of 1,000.
  ///
  /// Streams must be read starting from offset 0.
  public var maxStreamCount: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _readSession: Google_Cloud_Bigquery_Storage_V1_ReadSession? = nil
}

/// Request message for `ReadRows`.
public struct Google_Cloud_Bigquery_Storage_V1_ReadRowsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Stream to read rows from.
  public var readStream: String = String()

  /// The offset requested must be less than the last row read from Read.
  /// Requesting a larger offset is undefined. If not specified, start reading
  /// from offset zero.
  public var offset: Int64 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Information on if the current connection is being throttled.
public struct Google_Cloud_Bigquery_Storage_V1_ThrottleState {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// How much this connection is being throttled. Zero means no throttling,
  /// 100 means fully throttled.
  public var throttlePercent: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Estimated stream statistics for a given Stream.
public struct Google_Cloud_Bigquery_Storage_V1_StreamStats {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Represents the progress of the current stream.
  public var progress: Google_Cloud_Bigquery_Storage_V1_StreamStats.Progress {
    get {return _progress ?? Google_Cloud_Bigquery_Storage_V1_StreamStats.Progress()}
    set {_progress = newValue}
  }
  /// Returns true if `progress` has been explicitly set.
  public var hasProgress: Bool {return self._progress != nil}
  /// Clears the value of `progress`. Subsequent reads from it will return its default value.
  public mutating func clearProgress() {self._progress = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public struct Progress {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// The fraction of rows assigned to the stream that have been processed by
    /// the server so far, not including the rows in the current response
    /// message.
    ///
    /// This value, along with `at_response_end`, can be used to interpolate
    /// the progress made as the rows in the message are being processed using
    /// the following formula: `at_response_start + (at_response_end -
    /// at_response_start) * rows_processed_from_response / rows_in_response`.
    ///
    /// Note that if a filter is provided, the `at_response_end` value of the
    /// previous response may not necessarily be equal to the
    /// `at_response_start` value of the current response.
    public var atResponseStart: Double = 0

    /// Similar to `at_response_start`, except that this value includes the
    /// rows in the current response.
    public var atResponseEnd: Double = 0

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}
  }

  public init() {}

  fileprivate var _progress: Google_Cloud_Bigquery_Storage_V1_StreamStats.Progress? = nil
}

/// Response from calling `ReadRows` may include row data, progress and
/// throttling information.
public struct Google_Cloud_Bigquery_Storage_V1_ReadRowsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Row data is returned in format specified during session creation.
  public var rows: Google_Cloud_Bigquery_Storage_V1_ReadRowsResponse.OneOf_Rows? = nil

  /// Serialized row data in AVRO format.
  public var avroRows: Google_Cloud_Bigquery_Storage_V1_AvroRows {
    get {
      if case .avroRows(let v)? = rows {return v}
      return Google_Cloud_Bigquery_Storage_V1_AvroRows()
    }
    set {rows = .avroRows(newValue)}
  }

  /// Serialized row data in Arrow RecordBatch format.
  public var arrowRecordBatch: Google_Cloud_Bigquery_Storage_V1_ArrowRecordBatch {
    get {
      if case .arrowRecordBatch(let v)? = rows {return v}
      return Google_Cloud_Bigquery_Storage_V1_ArrowRecordBatch()
    }
    set {rows = .arrowRecordBatch(newValue)}
  }

  /// Number of serialized rows in the rows block.
  public var rowCount: Int64 = 0

  /// Statistics for the stream.
  public var stats: Google_Cloud_Bigquery_Storage_V1_StreamStats {
    get {return _stats ?? Google_Cloud_Bigquery_Storage_V1_StreamStats()}
    set {_stats = newValue}
  }
  /// Returns true if `stats` has been explicitly set.
  public var hasStats: Bool {return self._stats != nil}
  /// Clears the value of `stats`. Subsequent reads from it will return its default value.
  public mutating func clearStats() {self._stats = nil}

  /// Throttling state. If unset, the latest response still describes
  /// the current throttling status.
  public var throttleState: Google_Cloud_Bigquery_Storage_V1_ThrottleState {
    get {return _throttleState ?? Google_Cloud_Bigquery_Storage_V1_ThrottleState()}
    set {_throttleState = newValue}
  }
  /// Returns true if `throttleState` has been explicitly set.
  public var hasThrottleState: Bool {return self._throttleState != nil}
  /// Clears the value of `throttleState`. Subsequent reads from it will return its default value.
  public mutating func clearThrottleState() {self._throttleState = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Row data is returned in format specified during session creation.
  public enum OneOf_Rows: Equatable {
    /// Serialized row data in AVRO format.
    case avroRows(Google_Cloud_Bigquery_Storage_V1_AvroRows)
    /// Serialized row data in Arrow RecordBatch format.
    case arrowRecordBatch(Google_Cloud_Bigquery_Storage_V1_ArrowRecordBatch)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_ReadRowsResponse.OneOf_Rows, rhs: Google_Cloud_Bigquery_Storage_V1_ReadRowsResponse.OneOf_Rows) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.avroRows, .avroRows): return {
        guard case .avroRows(let l) = lhs, case .avroRows(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.arrowRecordBatch, .arrowRecordBatch): return {
        guard case .arrowRecordBatch(let l) = lhs, case .arrowRecordBatch(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _stats: Google_Cloud_Bigquery_Storage_V1_StreamStats? = nil
  fileprivate var _throttleState: Google_Cloud_Bigquery_Storage_V1_ThrottleState? = nil
}

/// Request message for `SplitReadStream`.
public struct Google_Cloud_Bigquery_Storage_V1_SplitReadStreamRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Name of the stream to split.
  public var name: String = String()

  /// A value in the range (0.0, 1.0) that specifies the fractional point at
  /// which the original stream should be split. The actual split point is
  /// evaluated on pre-filtered rows, so if a filter is provided, then there is
  /// no guarantee that the division of the rows between the new child streams
  /// will be proportional to this fractional value. Additionally, because the
  /// server-side unit for assigning data is collections of rows, this fraction
  /// will always map to a data storage boundary on the server side.
  public var fraction: Double = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response message for `SplitReadStream`.
public struct Google_Cloud_Bigquery_Storage_V1_SplitReadStreamResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Primary stream, which contains the beginning portion of
  /// |original_stream|. An empty value indicates that the original stream can no
  /// longer be split.
  public var primaryStream: Google_Cloud_Bigquery_Storage_V1_ReadStream {
    get {return _primaryStream ?? Google_Cloud_Bigquery_Storage_V1_ReadStream()}
    set {_primaryStream = newValue}
  }
  /// Returns true if `primaryStream` has been explicitly set.
  public var hasPrimaryStream: Bool {return self._primaryStream != nil}
  /// Clears the value of `primaryStream`. Subsequent reads from it will return its default value.
  public mutating func clearPrimaryStream() {self._primaryStream = nil}

  /// Remainder stream, which contains the tail of |original_stream|. An empty
  /// value indicates that the original stream can no longer be split.
  public var remainderStream: Google_Cloud_Bigquery_Storage_V1_ReadStream {
    get {return _remainderStream ?? Google_Cloud_Bigquery_Storage_V1_ReadStream()}
    set {_remainderStream = newValue}
  }
  /// Returns true if `remainderStream` has been explicitly set.
  public var hasRemainderStream: Bool {return self._remainderStream != nil}
  /// Clears the value of `remainderStream`. Subsequent reads from it will return its default value.
  public mutating func clearRemainderStream() {self._remainderStream = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _primaryStream: Google_Cloud_Bigquery_Storage_V1_ReadStream? = nil
  fileprivate var _remainderStream: Google_Cloud_Bigquery_Storage_V1_ReadStream? = nil
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.bigquery.storage.v1"

extension Google_Cloud_Bigquery_Storage_V1_CreateReadSessionRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateReadSessionRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .standard(proto: "read_session"),
    3: .standard(proto: "max_stream_count"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._readSession) }()
      case 3: try { try decoder.decodeSingularInt32Field(value: &self.maxStreamCount) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 1)
    }
    if let v = self._readSession {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    if self.maxStreamCount != 0 {
      try visitor.visitSingularInt32Field(value: self.maxStreamCount, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_CreateReadSessionRequest, rhs: Google_Cloud_Bigquery_Storage_V1_CreateReadSessionRequest) -> Bool {
    if lhs.parent != rhs.parent {return false}
    if lhs._readSession != rhs._readSession {return false}
    if lhs.maxStreamCount != rhs.maxStreamCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1_ReadRowsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ReadRowsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "read_stream"),
    2: .same(proto: "offset"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.readStream) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self.offset) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.readStream.isEmpty {
      try visitor.visitSingularStringField(value: self.readStream, fieldNumber: 1)
    }
    if self.offset != 0 {
      try visitor.visitSingularInt64Field(value: self.offset, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_ReadRowsRequest, rhs: Google_Cloud_Bigquery_Storage_V1_ReadRowsRequest) -> Bool {
    if lhs.readStream != rhs.readStream {return false}
    if lhs.offset != rhs.offset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1_ThrottleState: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ThrottleState"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "throttle_percent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.throttlePercent) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.throttlePercent != 0 {
      try visitor.visitSingularInt32Field(value: self.throttlePercent, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_ThrottleState, rhs: Google_Cloud_Bigquery_Storage_V1_ThrottleState) -> Bool {
    if lhs.throttlePercent != rhs.throttlePercent {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1_StreamStats: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamStats"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .same(proto: "progress"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularMessageField(value: &self._progress) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._progress {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_StreamStats, rhs: Google_Cloud_Bigquery_Storage_V1_StreamStats) -> Bool {
    if lhs._progress != rhs._progress {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1_StreamStats.Progress: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Bigquery_Storage_V1_StreamStats.protoMessageName + ".Progress"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "at_response_start"),
    2: .standard(proto: "at_response_end"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularDoubleField(value: &self.atResponseStart) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.atResponseEnd) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.atResponseStart != 0 {
      try visitor.visitSingularDoubleField(value: self.atResponseStart, fieldNumber: 1)
    }
    if self.atResponseEnd != 0 {
      try visitor.visitSingularDoubleField(value: self.atResponseEnd, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_StreamStats.Progress, rhs: Google_Cloud_Bigquery_Storage_V1_StreamStats.Progress) -> Bool {
    if lhs.atResponseStart != rhs.atResponseStart {return false}
    if lhs.atResponseEnd != rhs.atResponseEnd {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1_ReadRowsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ReadRowsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    3: .standard(proto: "avro_rows"),
    4: .standard(proto: "arrow_record_batch"),
    6: .standard(proto: "row_count"),
    2: .same(proto: "stats"),
    5: .standard(proto: "throttle_state"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularMessageField(value: &self._stats) }()
      case 3: try {
        var v: Google_Cloud_Bigquery_Storage_V1_AvroRows?
        if let current = self.rows {
          try decoder.handleConflictingOneOf()
          if case .avroRows(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.rows = .avroRows(v)}
      }()
      case 4: try {
        var v: Google_Cloud_Bigquery_Storage_V1_ArrowRecordBatch?
        if let current = self.rows {
          try decoder.handleConflictingOneOf()
          if case .arrowRecordBatch(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {self.rows = .arrowRecordBatch(v)}
      }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._throttleState) }()
      case 6: try { try decoder.decodeSingularInt64Field(value: &self.rowCount) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._stats {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every case branch when no optimizations are
    // enabled. https://github.com/apple/swift-protobuf/issues/1034
    switch self.rows {
    case .avroRows?: try {
      guard case .avroRows(let v)? = self.rows else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .arrowRecordBatch?: try {
      guard case .arrowRecordBatch(let v)? = self.rows else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case nil: break
    }
    if let v = self._throttleState {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }
    if self.rowCount != 0 {
      try visitor.visitSingularInt64Field(value: self.rowCount, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_ReadRowsResponse, rhs: Google_Cloud_Bigquery_Storage_V1_ReadRowsResponse) -> Bool {
    if lhs.rows != rhs.rows {return false}
    if lhs.rowCount != rhs.rowCount {return false}
    if lhs._stats != rhs._stats {return false}
    if lhs._throttleState != rhs._throttleState {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1_SplitReadStreamRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SplitReadStreamRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "fraction"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularDoubleField(value: &self.fraction) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.fraction != 0 {
      try visitor.visitSingularDoubleField(value: self.fraction, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_SplitReadStreamRequest, rhs: Google_Cloud_Bigquery_Storage_V1_SplitReadStreamRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.fraction != rhs.fraction {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Bigquery_Storage_V1_SplitReadStreamResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SplitReadStreamResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "primary_stream"),
    2: .standard(proto: "remainder_stream"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._primaryStream) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._remainderStream) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if let v = self._primaryStream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }
    if let v = self._remainderStream {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Bigquery_Storage_V1_SplitReadStreamResponse, rhs: Google_Cloud_Bigquery_Storage_V1_SplitReadStreamResponse) -> Bool {
    if lhs._primaryStream != rhs._primaryStream {return false}
    if lhs._remainderStream != rhs._remainderStream {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
